"""
Syst√®me RAG (Retrieval-Augmented Generation) avanc√© avec support VLM et analyse RFP
==================================================================================

Ce module impl√©mente un syst√®me RAG intelligent pour l'analyse strat√©gique des RFP :

FONCTIONNALIT√âS CORE :
- PDFs texte standard (extraction PyPDF)
- PDFs scann√©s/images (extraction via VLM - Vision Language Model)
- Gestion intelligente des sources avec IDs uniques
- Filtrage par statut RFP (approuv√©/rejet√©)

ANALYSE STRAT√âGIQUE RFP :
- Identification de patterns r√©currents dans les exigences
- Analyse comparative approved vs rejected
- D√©tection des facteurs de succ√®s/√©chec
- Extraction des enseignements m√©tier
- Recommandations pour futures r√©ponses

Auteur: [Votre nom]
Date: Juillet 2025
Version: 3.1 (avec Judge Pipeline corrig√©)
"""

# ===============================================================================
# INSTALLATION DES D√âPENDANCES
# ===============================================================================
# Installer les d√©pendances n√©cessaires (√† lancer une seule fois)
# pip install langchain langchain-community together faiss-cpu PyPDF2 pypdf pdf2image pillow sentence-transformers
# pip install google-generativeai deepeval  # Pour le judge pipeline Gemini

# ===============================================================================
# IMPORTS ET CONFIGURATION
# ===============================================================================

# Imports syst√®me et utilitaires
import os                    # Gestion fichiers/dossiers
import re                    # Expressions r√©guli√®res pour extraction num√©ros projet
import json                  # Sauvegarde registre documents
import uuid                  # G√©n√©ration IDs uniques
import base64                # Encodage images pour VLM
from io import BytesIO       # Buffer m√©moire pour images
import sys                   # Redirection de sortie pour logging
from datetime import datetime # Horodatage des logs
import contextlib            # Gestion de contexte pour redirection

# Imports pour le traitement des documents avec fallbacks
try:
    from langchain_community.document_loaders import PyPDFDirectoryLoader  # Chargement PDFs
    from langchain.text_splitter import RecursiveCharacterTextSplitter      # D√©coupage en chunks
    from langchain_huggingface import HuggingFaceEmbeddings                 # Embeddings texte
    from langchain_community.vectorstores import FAISS                     # Base vectorielle
except ImportError:
    # Fallback pour anciennes versions de langchain
    try:
        from langchain.document_loaders import PyPDFDirectoryLoader
        from langchain.text_splitter import RecursiveCharacterTextSplitter
        from langchain_community.embeddings import HuggingFaceEmbeddings
        from langchain.vectorstores import FAISS
    except ImportError:
        print("‚ö†Ô∏è Modules LangChain non disponibles. Veuillez installer avec: pip install langchain langchain-community")
        PyPDFDirectoryLoader = None
        RecursiveCharacterTextSplitter = None
        HuggingFaceEmbeddings = None
        FAISS = None

# Imports pour traitement PDF et images
try:
    import PyPDF2                    # Analyse PDFs pour d√©tection scan
    from pdf2image import convert_from_path  # Conversion PDF ‚Üí images
    from PIL import Image           # Manipulation images
except ImportError:
    print("‚ö†Ô∏è Modules PDF/Image non disponibles. Fonctionnalit√©s VLM d√©sactiv√©es.")
    PyPDF2 = None
    convert_from_path = None
    Image = None

# API Together pour LLM + VLM
try:
    from together import Together                                           # API Together (LLM + VLM)
except ImportError:
    print("‚ö†Ô∏è Module Together non disponible. Fonctionnalit√©s LLM d√©sactiv√©es.")
    Together = None

# Judge Pipeline avec Gemini pour √©valuation de fid√©lit√©
try:
    import google.generativeai as genai
    from deepeval.models.base_model import DeepEvalBaseLLM
    from deepeval.metrics import FaithfulnessMetric
    from deepeval.test_case import LLMTestCase
    judge_available = True
except ImportError:
    print("‚ö†Ô∏è Modules Judge Pipeline non disponibles (google-generativeai, deepeval)")
    judge_available = False

# ===============================================================================
# CONFIGURATION GLOBALE
# ===============================================================================

# Initialiser le mod√®le d'embeddings (transforme le texte en vecteurs num√©riques)
# Mod√®le l√©ger et efficace pour la recherche s√©mantique
try:
    if HuggingFaceEmbeddings is not None:
        embedding_model = HuggingFaceEmbeddings(model_name="all-MiniLM-L6-v2")
    else:
        embedding_model = None
        print("‚ö†Ô∏è Mod√®le d'embeddings non disponible. Veuillez installer les d√©pendances.")
except Exception as e:
    embedding_model = None
    print(f"‚ö†Ô∏è Erreur lors du chargement du mod√®le d'embeddings: {e}")

# ===============================================================================
# VARIABLES GLOBALES POUR JUDGE PIPELINE
# ===============================================================================

# Variables globales pour stocker la derni√®re r√©ponse et les documents r√©cup√©r√©s
last_answer = None
last_retrieved_docs = None

# Variables globales simples pour le dernier score et raison (pour promptEnhancer.py)
last_evaluation_score = None
last_evaluation_reason = None
last_analysis_prompt = None  # Stocker le prompt utilis√© pour l'analyse compl√®te

# ===============================================================================
# SYST√àME DE LOGGING AUTOMATIQUE
# ===============================================================================

class ConsoleLogger:
    """
    Classe pour capturer et sauvegarder automatiquement tous les prints du syst√®me
    dans un fichier de log avec horodatage.
    """
    
    def __init__(self, log_filename=None):
        """
        Initialise le syst√®me de logging.
        
        Args:
            log_filename (str, optional): Nom du fichier de log. 
                                        Si None, g√©n√®re automatiquement avec timestamp.
        """
        if log_filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            log_filename = f"rfp_analysis_log_{timestamp}.txt"
        
        self.log_filename = log_filename
        self.original_stdout = sys.stdout
        self.log_file = None
        
    def start_logging(self):
        """D√©marre l'enregistrement des logs"""
        try:
            self.log_file = open(self.log_filename, 'w', encoding='utf-8')
            # Cr√©er un wrapper qui √©crit √† la fois dans le terminal ET dans le fichier
            sys.stdout = self.TeeOutput(self.original_stdout, self.log_file)
            
            # Message d'initialisation
            print("=" * 80)
            print("üöÄ D√âMARRAGE SYST√àME RAG STRAT√âGIQUE POUR ANALYSE RFP")
            print("=" * 80)
            print(f"üìÅ Logs sauvegard√©s dans: {self.log_filename}")
            print(f"üïê Session d√©marr√©e: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print("=" * 80)
            
        except Exception as e:
            print(f"‚ùå Erreur initialisation logging: {e}")
            
    def stop_logging(self):
        """Arr√™te l'enregistrement des logs"""
        if self.log_file:
            print("\n" + "=" * 80)
            print("üìÑ FIN DE SESSION - LOGS SAUVEGARD√âS")
            print("=" * 80)
            print(f"üìÅ Fichier de log: {self.log_filename}")
            print(f"üïê Session termin√©e: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
            print("üíæ Tous les r√©sultats ont √©t√© conserv√©s pour r√©f√©rence future")
            print("=" * 80)
            
            sys.stdout = self.original_stdout
            self.log_file.close()
            self.log_file = None
            
    class TeeOutput:
        """Classe pour √©crire simultan√©ment dans le terminal et le fichier"""
        
        def __init__(self, terminal, file):
            self.terminal = terminal
            self.file = file
            
        def write(self, message):
            self.terminal.write(message)  # Afficher dans le terminal
            self.file.write(message)      # Sauvegarder dans le fichier
            self.file.flush()             # Forcer l'√©criture imm√©diate
            
        def flush(self):
            self.terminal.flush()
            self.file.flush()

# Instance globale du logger
console_logger = ConsoleLogger()

# Configuration du Judge Pipeline Gemini
GOOGLE_API_KEY = "AIzaSyCEtBwwTcJitPxX6Vum92Bz6q5-Ga86hU4"
judge_llm = None
faith_metric = None

if judge_available and GOOGLE_API_KEY:
    try:
        os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY
        genai.configure(api_key=GOOGLE_API_KEY)
        
        class GeminiJudge(DeepEvalBaseLLM):
            def __init__(self, model_name="gemini-2.0-flash-exp"):
                super().__init__(model_name=model_name)
                self.model = genai.GenerativeModel(model_name)
                self.model_name = model_name
            def get_model_name(self): return self.model_name
            def load_model(self): return self
            def generate(self, prompt):
                return self.model.generate_content(prompt, safety_settings={'HARASSMENT':'BLOCK_NONE'}).text
            async def a_generate(self, prompt):
                return self.generate(prompt)
        
        judge_llm = GeminiJudge()
        faith_metric = FaithfulnessMetric(model=judge_llm, include_reason=True, threshold=0.7)
        print("‚úÖ Judge Pipeline Gemini configur√©")
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur configuration Judge Pipeline: {e}")
        judge_llm = None

# ===============================================================================
# FONCTIONS JUDGE PIPELINE POUR √âVALUATION AUTOMATIQUE
# ===============================================================================

def assess_faithfulness(question, answer, retrieved_docs, threshold=0.7):
    """
    √âvalue la fid√©lit√© d'une r√©ponse par rapport aux documents r√©cup√©r√©s.
    
    Args:
        question (str): Question pos√©e
        answer (str): R√©ponse g√©n√©r√©e par le RAG
        retrieved_docs (list): Documents r√©cup√©r√©s
        threshold (float): Seuil de fid√©lit√© (0.7 par d√©faut)
        
    Returns:
        dict: R√©sultat de l'√©valuation avec score, raison et recommandation
    """
    if not judge_llm or not faith_metric:
        return {
            "score": None,
            "reason": "Judge Pipeline non disponible",
            "needs_enhancement": False,
            "status": "disabled"
        }
    
    try:
        # Pr√©parer le contexte des documents r√©cup√©r√©s
        if isinstance(retrieved_docs, list):
            retrieval_context = [doc.page_content if hasattr(doc, 'page_content') else str(doc) for doc in retrieved_docs]
        else:
            retrieval_context = [str(retrieved_docs)]
        
        # Configurer le seuil
        faith_metric.threshold = threshold
        
        # Cr√©er le test case
        tc = LLMTestCase(
            input=question, 
            actual_output=answer, 
            retrieval_context=retrieval_context
        )
        
        # Mesurer la fid√©lit√©
        faith_metric.measure(tc)
        
        # Stocker dans les variables globales simples
        global last_evaluation_score, last_evaluation_reason
        last_evaluation_score = faith_metric.score
        last_evaluation_reason = faith_metric.reason
        
        return {
            "score": faith_metric.score,
            "reason": faith_metric.reason,
            "needs_enhancement": faith_metric.score < threshold,
            "status": "evaluated"
        }
    except Exception as e:
        return {
            "score": None,
            "reason": f"Erreur lors de l'√©valuation: {e}",
            "needs_enhancement": False,
            "status": "error"
        }

def evaluate_faithfulness_after_generation(question: str, answer: str, retrieved_docs: list):
    """
    NOUVELLE FONCTION : √âvalue la fid√©lit√© APR√àS g√©n√©ration de la r√©ponse.
    
    Cette fonction remplace l'ancienne logique qui tentait d'√©valuer avant.
    Elle doit √™tre appel√©e uniquement apr√®s que le LLM ait g√©n√©r√© sa r√©ponse.
    
    Args:
        question (str): Question pos√©e par l'utilisateur
        answer (str): R√©ponse R√âELLE g√©n√©r√©e par le LLM
        retrieved_docs (list): Documents R√âELS utilis√©s pour g√©n√©rer la r√©ponse
        
    Returns:
        dict: R√©sultat complet avec √©valuation
    """
    if not answer or not retrieved_docs:
        return {
            "question": question,
            "answer": answer or "Aucune r√©ponse disponible",
            "retrieved_count": len(retrieved_docs) if retrieved_docs else 0,
            "evaluation": {
                "score": None,
                "reason": "Donn√©es insuffisantes pour √©valuation",
                "needs_enhancement": False,
                "status": "insufficient_data"
            }
        }
    
    # √âvaluer la fid√©lit√© avec les vraies donn√©es
    evaluation = assess_faithfulness(question, answer, retrieved_docs)
    
    # Retourner le r√©sultat structur√©
    return {
        "question": question,
        "answer": answer,
        "retrieved_count": len(retrieved_docs),
        "evaluation": evaluation
    }

def print_judge_result(result):
    """
    Affiche le r√©sultat du judge pipeline de mani√®re lisible.
    
    Args:
        result (dict): R√©sultat du judge pipeline
    """
    print("\n" + "="*60)
    print("üîç √âVALUATION AUTOMATIQUE DE FID√âLIT√â")
    print("="*60)
    
    print(f"‚ùì Question: {result['question']}")
    print(f"üìÑ Documents utilis√©s: {result['retrieved_count']}")
    
    eval_data = result['evaluation']
    
    if eval_data['status'] == 'evaluated':
        score = eval_data['score']
        if score is not None:
            # Affichage color√© selon le score
            if score >= 0.8:
                print(f"‚úÖ Score de fid√©lit√©: {score:.2f} (Excellent)")
            elif score >= 0.7:
                print(f"üü° Score de fid√©lit√©: {score:.2f} (Acceptable)")
            else:
                print(f"‚ùå Score de fid√©lit√©: {score:.2f} (N√©cessite am√©lioration)")
            
            print(f"üìù Raison: {eval_data['reason']}")
            
            if eval_data['needs_enhancement']:
                print("‚ö†Ô∏è  RECOMMANDATION: Cette r√©ponse n√©cessite des am√©liorations")
            else:
                print("‚úÖ RECOMMANDATION: R√©ponse fid√®le aux sources")
        else:
            print("‚ùå Erreur dans l'√©valuation")
    else:
        print(f"‚ÑπÔ∏è  Statut: {eval_data['reason']}")

# ===============================================================================
# FONCTIONS DE D√âTECTION ET ANALYSE DES PDFs
# ===============================================================================

def is_pdf_scanned(pdf_path):
    """
    D√©termine si un PDF contient principalement des images scann√©es.
    
    Algorithme de d√©tection :
    1. Lit les 3 premi√®res pages du PDF
    2. Extrait le texte de chaque page
    3. Si moins de 100 caract√®res de texte ‚Üí consid√©r√© comme scann√©
    
    Args:
        pdf_path (str): Chemin vers le fichier PDF √† analyser
        
    Returns:
        bool: True si le PDF semble √™tre scann√©, False sinon
        
    Note:
        Cette m√©thode n'est pas parfaite mais fonctionne bien dans la plupart des cas.
        Un PDF avec tr√®s peu de texte peut √™tre class√© √† tort comme scann√©.
    """
    try:
        # Ouvrir le PDF en mode binaire pour lecture
        with open(pdf_path, 'rb') as file:
            pdf_reader = PyPDF2.PdfReader(file)
            total_text_length = 0
            
            # Limiter l'analyse aux 3 premi√®res pages pour optimiser les performances
            # (la plupart des PDFs ont un contenu homog√®ne)
            max_pages_to_check = min(3, len(pdf_reader.pages))
            
            # Parcourir chaque page et extraire le texte
            for page_num in range(max_pages_to_check):
                page = pdf_reader.pages[page_num]
                text = page.extract_text()
                total_text_length += len(text.strip())
            
            # Seuil de d√©cision : si moins de 100 caract√®res de texte extractible,
            # c'est probablement un PDF scann√© (images)
            return total_text_length < 100
            
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur lors de l'analyse de {pdf_path}: {e}")
        # En cas d'erreur, consid√©rer comme PDF standard par s√©curit√©
        return False

# ===============================================================================
# FONCTIONS DE TRAITEMENT D'IMAGES ET VLM
# ===============================================================================

def image_to_base64(image):
    """
    Convertit une image PIL en format base64 pour transmission √† l'API VLM.
    
    Le format base64 est requis par l'API Together pour envoyer des images
    dans les requ√™tes HTTP/JSON.
    
    Args:
        image (PIL.Image): Image PIL √† convertir
        
    Returns:
        str: Cha√Æne base64 repr√©sentant l'image
    """
    # Cr√©er un buffer m√©moire pour stocker l'image
    buffer = BytesIO()
    # Sauvegarder l'image en format PNG dans le buffer
    image.save(buffer, format="PNG")
    # Encoder le contenu du buffer en base64
    img_str = base64.b64encode(buffer.getvalue()).decode()
    return img_str

def extract_text_from_scanned_pdf(pdf_path, vlm_client):
    """
    Extrait le texte d'un PDF scann√© en utilisant un Vision Language Model (VLM).
    
    Processus :
    1. Convertit chaque page PDF en image (200 DPI pour qualit√© optimale)
    2. Encode chaque image en base64
    3. Envoie l'image au VLM avec un prompt d'extraction de texte
    4. Compile tous les textes extraits en un seul document
    
    Args:
        pdf_path (str): Chemin vers le PDF scann√©
        vlm_client (Together): Client API Together configur√©
        
    Returns:
        str: Texte extrait de toutes les pages, s√©par√© par des marqueurs de page
             Retourne cha√Æne vide en cas d'√©chec
    """
    try:
        print(f"üñºÔ∏è Traitement du PDF scann√©: {pdf_path}")
        
        # Convertir le PDF en images haute r√©solution
        # DPI=200 offre un bon compromis qualit√©/performance pour l'OCR
        images = convert_from_path(pdf_path, dpi=200)
        extracted_texts = []
        
        # Traiter chaque page individuellement
        for i, image in enumerate(images):
            print(f"  üìÑ Traitement de la page {i+1}/{len(images)}")
            
            # Convertir l'image au format requis par l'API
            img_base64 = image_to_base64(image)
            
            # Construire la requ√™te pour le VLM
            # Format sp√©cifique requis par l'API Together pour les images
            messages = [
                {
                    "role": "user", 
                    "content": [
                        {
                            "type": "text", 
                            # Prompt optimis√© pour l'extraction de texte pr√©cise
                            "text": "Extract all text from this image. Provide only the extracted text, no commentary."
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/png;base64,{img_base64}"
                            }
                        }
                    ]
                }
            ]
            
            # Appel au mod√®le VLM (Vision Language Model)
            # Llama-3.2-90B-Vision sp√©cialis√© dans l'analyse d'images et OCR
            response = vlm_client.chat.completions.create(
                model="meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo",
                messages=messages,
                stream=False  # Mode synchrone pour garantir l'ordre des pages
            )
            
            # Extraire le texte de la r√©ponse
            page_text = response.choices[0].message.content
            # Ajouter un marqueur de page pour la tra√ßabilit√©
            extracted_texts.append(f"--- Page {i+1} ---\n{page_text}")
        
        # Combiner tous les textes extraits avec s√©parateurs
        return "\n\n".join(extracted_texts)
        
    except Exception as e:
        print(f"‚ùå Erreur lors du traitement VLM de {pdf_path}: {e}")
        # Retourner cha√Æne vide en cas d'√©chec (permet le fallback)
        return ""

# ===============================================================================
# GESTION DES DOCUMENTS ET M√âTADONN√âES
# ===============================================================================

def create_document_with_id(content, metadata, doc_type="text"):
    """
    Cr√©e un document avec un ID unique et des m√©tadonn√©es enrichies.
    
    Cette fonction g√©n√®re un objet document compatible avec LangChain
    mais avec des m√©tadonn√©es suppl√©mentaires pour la tra√ßabilit√©.
    
    Args:
        content (str): Contenu textuel du document
        metadata (dict): M√©tadonn√©es existantes
        doc_type (str): Type de document ('text', 'vlm_extracted', etc.)
        
    Returns:
        DocumentWithId: Objet document avec ID unique et m√©tadonn√©es enrichies
    """
    # G√©n√©rer un UUID unique pour ce document
    doc_id = str(uuid.uuid4())
    
    # Cr√©er une classe document personnalis√©e compatible LangChain
    class DocumentWithId:
        """
        Classe document personnalis√©e avec support des IDs uniques.
        Compatible avec l'interface LangChain Document.
        """
        def __init__(self, page_content, metadata):
            self.page_content = page_content  # Contenu du document
            self.metadata = metadata          # M√©tadonn√©es
            # Enrichir les m√©tadonn√©es avec l'ID et le type
            self.metadata['doc_id'] = doc_id
            self.metadata['doc_type'] = doc_type
    
    return DocumentWithId(content, metadata)

# ===============================================================================
# FONCTIONS UTILITAIRES POUR RFP + R√âPONSES
# ===============================================================================

def extract_project_number(filename, doc_type):
    """
    Extrait le num√©ro de projet d'un nom de fichier RFP ou Response.
    
    Formats attendus :
    - rfp1.pdf, rfp2.pdf, rfp10.pdf ‚Üí 1, 2, 10
    - response1.pdf, response2.pdf, response10.pdf ‚Üí 1, 2, 10
    
    Args:
        filename (str): Nom du fichier (ex: "rfp5.pdf")
        doc_type (str): Type de document ("rfp" ou "response")
        
    Returns:
        str: Num√©ro de projet ou None si format non reconnu
    """
    # Pattern pour extraire le num√©ro selon le type
    if doc_type == "rfp":
        pattern = r'rfp(\d+)\.pdf'
    elif doc_type == "response":
        pattern = r'response(\d+)\.pdf'
    else:
        return None
    
    match = re.match(pattern, filename.lower())
    return match.group(1) if match else None

def process_single_pdf(folder, pdf_file, doc_category, rfp_status, project_number, vlm_client):
    """
    Traite un seul fichier PDF avec m√©tadonn√©es enrichies.
    
    Args:
        folder (str): Chemin du dossier contenant le PDF
        pdf_file (str): Nom du fichier PDF
        doc_category (str): "rfp" ou "response"
        rfp_status (str): "approved" ou "rejected"
        project_number (str): Num√©ro de projet
        vlm_client: Client VLM pour PDFs scann√©s
        
    Returns:
        list: Liste de documents cr√©√©s
    """
    pdf_path = os.path.join(folder, pdf_file)
    print(f"    üìÑ Analyse de {pdf_file} (Projet {project_number})...")
    
    documents = []
    
    # ===== D√âTECTION DU TYPE DE PDF =====
    if is_pdf_scanned(pdf_path):
        # ----- PDF SCANN√â D√âTECT√â -----
        print(f"    üñºÔ∏è PDF scann√© d√©tect√©: {pdf_file}")
        
        if vlm_client is None:
            # Fallback : pas de VLM disponible
            print(f"    ‚ö†Ô∏è VLM non disponible, passage en mode texte standard pour {pdf_file}")
            loader = PyPDFDirectoryLoader(folder)
            temp_docs = loader.load()
            documents = [doc for doc in temp_docs if pdf_file in doc.metadata.get('source', '')]
            doc_type = "text_fallback"
        else:
            # Traitement VLM optimal
            extracted_text = extract_text_from_scanned_pdf(pdf_path, vlm_client)
            
            if extracted_text:
                # Cr√©er un document avec le texte extrait par VLM
                metadata = {
                    'source': pdf_path,
                    'source_folder': folder,
                    'rfp_status': rfp_status,
                    'doc_category': doc_category,
                    'project_number': project_number,
                    'extraction_method': 'vlm',
                    'original_file': pdf_file
                }
                
                doc = create_document_with_id(extracted_text, metadata, "vlm_extracted")
                documents = [doc]
                doc_type = "vlm_extracted"
            else:
                print(f"    ‚ùå √âchec de l'extraction VLM pour {pdf_file}")
                return []
    else:
        # ----- PDF TEXTE STANDARD -----
        print(f"    üìù PDF texte standard: {pdf_file}")
        # Utiliser l'extraction texte classique (PyPDF)
        loader = PyPDFDirectoryLoader(folder)
        temp_docs = loader.load()
        
        # Filtrer pour ne garder que le fichier actuel
        documents = [doc for doc in temp_docs if pdf_file in doc.metadata.get('source', '')]
        doc_type = "text_standard"
    
    # ===== ENRICHISSEMENT DES M√âTADONN√âES =====
    for doc in documents:
        # Assurer la compatibilit√© des m√©tadonn√©es
        if not hasattr(doc.metadata, 'get'):
            doc.metadata = {}
        
        # Ajouter les m√©tadonn√©es standardis√©es
        doc.metadata['source_folder'] = folder
        doc.metadata['rfp_status'] = rfp_status
        doc.metadata['doc_category'] = doc_category
        doc.metadata['project_number'] = project_number
        doc.metadata['doc_type'] = doc_type
        doc.metadata['original_file'] = pdf_file
        
        # G√©n√©rer un ID unique si pas d√©j√† pr√©sent
        if 'doc_id' not in doc.metadata:
            doc.metadata['doc_id'] = str(uuid.uuid4())
    
    return documents

# ===============================================================================
# FONCTION PRINCIPALE DE CHARGEMENT ET TRAITEMENT DES DOCUMENTS RFP + R√âPONSES
# ===============================================================================

def load_and_chunk_documents(pdf_folders=["./approvedRfp/rfp", "./approvedRfp/ResponseRfp", "./rejectedRfp/rfp", "./rejectedRfp/ResponsRfp"], vlm_client=None):
    """
    Fonction principale de chargement et traitement des documents PDF RFP + R√©ponses.
    
    Args:
        pdf_folders (list): Liste des 4 dossiers sp√©cifiques √† traiter
        vlm_client (Together, optional): Client API pour le traitement VLM des scann√©s
        
    Returns:
        tuple: (chunks, document_registry, rfp_response_mapping)
    """
    print("üîÑ Chargement des documents RFP et R√©ponses depuis les 4 dossiers...")
    all_documents = []                # Stockage de tous les documents trait√©s
    document_registry = {}            # Registre pour la tra√ßabilit√©
    rfp_response_mapping = {}         # Correspondance RFP ‚Üî R√©ponse par projet

    # ===== MAPPING DES DOSSIERS AVEC LEURS CARACT√âRISTIQUES =====
    folder_mapping = {
        "./approvedRfp/rfp": {"rfp_status": "approved", "doc_category": "rfp"},
        "./approvedRfp/ResponseRfp": {"rfp_status": "approved", "doc_category": "response"}, 
        "./rejectedRfp/rfp": {"rfp_status": "rejected", "doc_category": "rfp"},
        "./rejectedRfp/ResponsRfp": {"rfp_status": "rejected", "doc_category": "response"}
    }

    # ===== TRAITEMENT DIRECT DE CHAQUE DOSSIER =====
    for folder_path in pdf_folders:
        if not os.path.exists(folder_path):
            print(f"‚ö†Ô∏è Le dossier {folder_path} n'existe pas")
            continue
            
        # R√©cup√©rer les caract√©ristiques du dossier
        folder_info = folder_mapping.get(folder_path, {"rfp_status": "unknown", "doc_category": "unknown"})
        rfp_status = folder_info["rfp_status"]
        doc_category = folder_info["doc_category"]
        
        print(f"üìÅ Traitement du dossier {folder_path} ({rfp_status.upper()} {doc_category.upper()})...")
        
        # Lister tous les fichiers PDF du dossier
        pdf_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.pdf')]
        
        for pdf_file in pdf_files:
            # Extraction du num√©ro de projet selon le type de document
            project_number = extract_project_number(pdf_file, doc_category)
            if project_number is None:
                print(f"    ‚ö†Ô∏è Format non reconnu pour {pdf_file}, traitement comme document isol√©")
                project_number = "unknown"
            
            # Traitement du document PDF
            docs = process_single_pdf(
                folder=folder_path, 
                pdf_file=pdf_file, 
                doc_category=doc_category,
                rfp_status=rfp_status,
                project_number=project_number,
                vlm_client=vlm_client
            )
            
            # Ajouter √† la collection et au registre
            all_documents.extend(docs)
            for doc in docs:
                document_registry[doc.metadata['doc_id']] = {
                    'file': pdf_file,
                    'folder': folder_path,
                    'type': doc.metadata['doc_type'],
                    'status': rfp_status,
                    'category': doc_category,
                    'project_number': project_number
                }
                
                # G√©rer le mapping RFP-R√©ponse
                if project_number not in rfp_response_mapping:
                    rfp_response_mapping[project_number] = {'rfp': None, 'response': None, 'status': rfp_status}
                
                # Assigner l'ID selon le type de document
                if doc_category == "rfp":
                    rfp_response_mapping[project_number]['rfp'] = doc.metadata['doc_id']
                elif doc_category == "response":
                    rfp_response_mapping[project_number]['response'] = doc.metadata['doc_id']
        
        print(f"‚úÖ Dossier {folder_path} termin√©")
    
    # ===== V√âRIFICATION ET VALIDATION =====
    if not all_documents:
        print("‚ö†Ô∏è Aucun document trouv√© dans les dossiers sp√©cifi√©s")
        return [], {}, {}

    # ===== AFFICHAGE STATISTIQUES =====
    print(f"\nüìä STATISTIQUES DE TRAITEMENT:")
    print(f"  üìÑ Total documents: {len(all_documents)}")
    print(f"  üîó Projets mapp√©s: {len(rfp_response_mapping)}")
    
    # Compter les paires compl√®tes RFP-R√©ponse
    complete_pairs = sum(1 for mapping in rfp_response_mapping.values() 
                        if mapping['rfp'] and mapping['response'])
    print(f"  ‚úÖ Paires RFP-R√©ponse compl√®tes: {complete_pairs}")

    # ===== D√âCOUPAGE EN CHUNKS =====
    print(f"üß© D√©coupage en chunks de {len(all_documents)} documents...")
    # Param√®tres optimis√©s pour la recherche s√©mantique
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1500,      # Taille optimale pour les embeddings
        chunk_overlap=200     # Chevauchement pour pr√©server le contexte
    )
    chunks = splitter.split_documents(all_documents)
    
    # ===== SAUVEGARDE DES REGISTRES =====
    # Sauvegarder le registre des documents
    with open("./document_registry.json", "w", encoding="utf-8") as f:
        json.dump(document_registry, f, indent=2, ensure_ascii=False)
    
    # Sauvegarder le mapping RFP-R√©ponse
    with open("./rfp_response_mapping.json", "w", encoding="utf-8") as f:
        json.dump(rfp_response_mapping, f, indent=2, ensure_ascii=False)
    
    print(f"üíæ Registres sauvegard√©s:")
    print(f"  üìã Documents: {len(document_registry)} entr√©es")
    print(f"  üîó Mapping RFP-R√©ponse: {len(rfp_response_mapping)} projets")
    
    return chunks, document_registry, rfp_response_mapping

# ===============================================================================
# FONCTIONS D'INDEXATION ET DE RECHERCHE VECTORIELLE
# ===============================================================================

def create_faiss_index(chunks, faiss_path="./faiss_index"):
    """
    Cr√©e un index FAISS pour la recherche vectorielle s√©mantique.
    
    FAISS (Facebook AI Similarity Search) permet une recherche rapide
    dans de grandes collections de vecteurs d'embeddings.
    
    Args:
        chunks (list): Liste des chunks de documents √† indexer
        faiss_path (str): Chemin de sauvegarde de l'index
        
    Returns:
        FAISS: Objet vectorstore FAISS pr√™t pour la recherche
    """
    print("üß† G√©n√©ration des embeddings et cr√©ation de l'index FAISS...")
    # Cr√©er l'index vectoriel √† partir des chunks et du mod√®le d'embeddings
    vectorstore = FAISS.from_documents(chunks, embedding_model)
    # Sauvegarder l'index sur disque pour r√©utilisation
    vectorstore.save_local(faiss_path)
    return vectorstore

def retrieve_similar_chunks(vectorstore, query, k=5):
    """
    Recherche simple de chunks similaires dans l'index vectoriel.
    
    Args:
        vectorstore (FAISS): Index vectoriel FAISS
        query (str): Requ√™te de recherche
        k (int): Nombre de chunks √† retourner
        
    Returns:
        list: Liste des k chunks les plus similaires
    """
    return vectorstore.similarity_search(query, k=k)

def retrieve_similar_chunks_with_filter(vectorstore, query, k=5, rfp_status=None):
    """
    Recherche de chunks similaires avec filtrage par statut RFP.
    
    Cette fonction permet de limiter la recherche aux RFP approuv√©s
    ou rejet√©s selon le besoin.
    
    Args:
        vectorstore (FAISS): Index vectoriel FAISS
        query (str): Requ√™te de recherche
        k (int): Nombre de chunks √† retourner
        rfp_status (str, optional): 'approved', 'rejected', ou None pour tous
        
    Returns:
        list: Liste des chunks filtr√©s et similaires
        
    Note:
        La strat√©gie de filtrage r√©cup√®re plus de documents que n√©cessaire
        puis filtre par m√©tadonn√©es pour garantir d'avoir assez de r√©sultats.
    """
    if rfp_status is None:
        # Pas de filtre : recherche normale
        return vectorstore.similarity_search(query, k=k)
    else:
        # Avec filtre : r√©cup√©rer plus de documents puis filtrer
        # Facteur 5 pour compenser les documents filtr√©s
        docs = vectorstore.similarity_search(query, k=k*5)
        # Filtrer par statut RFP dans les m√©tadonn√©es
        filtered_docs = [doc for doc in docs if doc.metadata.get('rfp_status') == rfp_status]
        # Retourner seulement les k premiers r√©sultats
        return filtered_docs[:k]

# ===============================================================================
# FONCTIONS D'ANALYSE STRAT√âGIQUE RFP
# ===============================================================================

def analyze_rfp_patterns(vectorstore, category="exigences techniques", k=10):
    """
    üß† RECONNAISSANCE INTELLIGENTE DE PATTERNS DANS LES RFP
    ======================================================
    
    Cette fonction est le c≈ìur de la valeur ajout√©e du syst√®me : elle identifie 
    automatiquement les patterns r√©currents dans les demandes clients pour une 
    cat√©gorie donn√©e.
    
    Args:
        vectorstore (FAISS): Index vectoriel FAISS pour la recherche s√©mantique
        category (str): Cat√©gorie √† analyser pour reconnaissance de patterns
        k (int): Nombre de documents √† analyser par statut (approved/rejected)
        
    Returns:
        dict: Analyse de patterns avec m√©triques de r√©currence et exemples concrets
    """
    print(f"üîç Analyse des patterns pour: {category}")
    
    # ===== RECHERCHE DANS LES RFP APPROUV√âS =====
    approved_docs = retrieve_similar_chunks_with_filter(
        vectorstore, category, k=k, rfp_status="approved"
    )
    
    # ===== RECHERCHE DANS LES RFP REJET√âS =====
    rejected_docs = retrieve_similar_chunks_with_filter(
        vectorstore, category, k=k, rfp_status="rejected"
    )
    
    # ===== CONSTRUCTION DE L'ANALYSE COMPARATIVE =====
    analysis = {
        "category": category,
        "approved_count": len(approved_docs),     
        "rejected_count": len(rejected_docs),     
        "approved_patterns": [doc.page_content[:200] + "..." for doc in approved_docs[:3]],
        "rejected_patterns": [doc.page_content[:200] + "..." for doc in rejected_docs[:3]],
        "total_analyzed": len(approved_docs) + len(rejected_docs)
    }
    
    return analysis

def compare_success_failure_factors(vectorstore, topic="m√©thodologie", k=5):
    """
    Compare les facteurs de succ√®s vs √©chec pour un sujet donn√©.
    
    Args:
        vectorstore (FAISS): Index vectoriel FAISS pour recherche s√©mantique
        topic (str): Sujet √† comparer (mots-cl√©s libres)
        k (int): Nombre de documents par cat√©gorie (approved/rejected)
        
    Returns:
        dict: Comparaison structur√©e avec success_factors et failure_factors
    """
    print(f"‚öñÔ∏è Comparaison succ√®s/√©chec pour: {topic}")
    
    # ===== ANALYSE DES FACTEURS DE SUCC√àS =====
    approved_docs = retrieve_similar_chunks_with_filter(
        vectorstore, topic, k=k, rfp_status="approved"
    )
    
    # ===== ANALYSE DES FACTEURS D'√âCHEC =====
    rejected_docs = retrieve_similar_chunks_with_filter(
        vectorstore, topic, k=k, rfp_status="rejected"
    )
    
    # ===== CONSTRUCTION DE LA COMPARAISON STRUCTUR√âE =====
    comparison = {
        "topic": topic,
        "success_factors": {
            "count": len(approved_docs),
            "sources": [doc.metadata.get('original_file', 'unknown') for doc in approved_docs],
            "key_elements": [doc.page_content[:300] for doc in approved_docs]
        },
        "failure_factors": {
            "count": len(rejected_docs),
            "sources": [doc.metadata.get('original_file', 'unknown') for doc in rejected_docs],
            "key_elements": [doc.page_content[:300] for doc in rejected_docs]
        }
    }
    
    return comparison

def extract_lessons_learned(vectorstore, focus_area="points faibles", k=8):
    """
    Extrait les enseignements cl√©s de nos r√©ponses pass√©es.
    
    Args:
        vectorstore (FAISS): Index vectoriel FAISS pour recherche s√©mantique
        focus_area (str): Zone d'analyse ("forces", "faiblesses", "am√©liorations", etc.)
        k (int): Nombre d'exemples √† analyser (multipli√© par 2 pour recherche large)
        
    Returns:
        dict: Enseignements structur√©s avec from_successes et from_failures
    """
    print(f"üìö Extraction des enseignements: {focus_area}")
    
    # ===== RECHERCHE LARGE POUR CAPTURE MAXIMALE =====
    all_docs = retrieve_similar_chunks(vectorstore, focus_area, k=k*2)
    
    # ===== S√âPARATION AUTOMATIQUE PAR STATUT =====
    approved_lessons = [doc for doc in all_docs if doc.metadata.get('rfp_status') == 'approved']
    rejected_lessons = [doc for doc in all_docs if doc.metadata.get('rfp_status') == 'rejected']
    
    # ===== STRUCTURATION DES ENSEIGNEMENTS =====
    lessons = {
        "focus_area": focus_area,
        "from_successes": {
            "count": len(approved_lessons),
            "insights": [doc.page_content[:250] for doc in approved_lessons[:3]]
        },
        "from_failures": {
            "count": len(rejected_lessons),
            "insights": [doc.page_content[:250] for doc in rejected_lessons[:3]]
        },
        "recommendations": f"Bas√© sur {len(all_docs)} documents analys√©s - "
                          f"Taux de succ√®s: {len(approved_lessons)}/{len(all_docs)} "
                          f"({len(approved_lessons)/len(all_docs)*100:.1f}%)"
    }
    
    return lessons

def identify_recurring_requirements(vectorstore, requirement_type="fonctionnalit√©s", k=15):
    """
    üîÑ D√âTECTION AVANC√âE DE PATTERNS R√âCURRENTS DANS LES EXIGENCES
    =============================================================
    
    Cette fonction sp√©cialis√©e applique des algorithmes de pattern recognition 
    pour identifier automatiquement les exigences qui se r√©p√®tent √† travers 
    l'historique des RFP.
    
    Args:
        vectorstore (FAISS): Index vectoriel FAISS pour recherche s√©mantique
        requirement_type (str): Type d'exigence √† analyser (mots-cl√©s libres)
        k (int): Nombre de documents √† examiner (recommand√©: 15+ pour statistiques)
        
    Returns:
        dict: Analyse de r√©currence avec in_approved_rfp et in_rejected_rfp
    """
    print(f"üîÑ Identification des exigences r√©currentes: {requirement_type}")
    
    # ===== RECHERCHE LARGE POUR CAPTURE EXHAUSTIVE =====
    docs = retrieve_similar_chunks(vectorstore, requirement_type, k=k)
    
    # ===== SEGMENTATION PAR R√âSULTAT =====
    approved_req = [doc for doc in docs if doc.metadata.get('rfp_status') == 'approved']
    rejected_req = [doc for doc in docs if doc.metadata.get('rfp_status') == 'rejected']
    
    # ===== ANALYSE DES SOURCES POUR VALIDATION =====
    approved_sources = list(set([doc.metadata.get('original_file', 'unknown') for doc in approved_req]))
    rejected_sources = list(set([doc.metadata.get('original_file', 'unknown') for doc in rejected_req]))
    
    # ===== CONSTRUCTION DE L'ANALYSE DE R√âCURRENCE =====
    analysis = {
        "requirement_type": requirement_type,
        "total_occurrences": len(docs),
        "in_approved_rfp": {
            "count": len(approved_req),
            "sources": approved_sources,
            "examples": [doc.page_content[:200] for doc in approved_req[:3]]
        },
        "in_rejected_rfp": {
            "count": len(rejected_req),
            "sources": rejected_sources,
            "examples": [doc.page_content[:200] for doc in rejected_req[:3]]
        },
        "recurrence_rate": f"{len(docs)} occurrences dans {len(set(approved_sources + rejected_sources))} projets "
                          f"(Succ√®s: {len(approved_sources)}, √âchecs: {len(rejected_sources)})"
    }
    
    return analysis

def generate_strategic_insights(vectorstore, business_question):
    """
    G√©n√®re des insights strat√©giques bas√©s sur une question m√©tier.
    
    Args:
        vectorstore (FAISS): Index vectoriel FAISS pour recherche s√©mantique
        business_question (str): Question strat√©gique m√©tier √† analyser
        
    Returns:
        str: Contexte structur√© pr√™t pour analyse LLM
    """
    print(f"üí° G√©n√©ration d'insights strat√©giques...")
    
    # ===== RECHERCHE CONTEXTUELLE LARGE =====
    relevant_docs = retrieve_similar_chunks(vectorstore, business_question, k=8)
    
    # ===== S√âPARATION POUR ANALYSE COMPARATIVE =====
    approved_context = [doc for doc in relevant_docs if doc.metadata.get('rfp_status') == 'approved']
    rejected_context = [doc for doc in relevant_docs if doc.metadata.get('rfp_status') == 'rejected']
    
    # ===== CONSTRUCTION DU CONTEXTE STRAT√âGIQUE =====
    strategic_context = f"""
CONTEXTE D'ANALYSE STRAT√âGIQUE RFP:

=== EXEMPLES DE R√âUSSITES ({len(approved_context)} cas) ===
{chr(10).join([f"- Projet: {doc.metadata.get('original_file', 'unknown')[:30]}... | "
               f"Extrait: {doc.page_content[:300]}" for doc in approved_context[:3]])}

=== EXEMPLES D'√âCHECS ({len(rejected_context)} cas) ===
{chr(10).join([f"- Projet: {doc.metadata.get('original_file', 'unknown')[:30]}... | "
               f"Extrait: {doc.page_content[:300]}" for doc in rejected_context[:3]])}

=== STATISTIQUES DE PERFORMANCE ===
- Total documents analys√©s: {len(relevant_docs)}
- R√©ussites: {len(approved_context)} cas ({len(approved_context)/len(relevant_docs)*100:.1f}%)
- √âchecs: {len(rejected_context)} cas ({len(rejected_context)/len(relevant_docs)*100:.1f}%)
- Taux de succ√®s sur ce sujet: {len(approved_context)}/{len(relevant_docs)}

=== M√âTADONN√âES D'ANALYSE ===
- Type de recherche: Analyse vectorielle s√©mantique
- Scope: Historique complet des RFP indexed
- M√©thode: Comparaison approved vs rejected
- Fiabilit√©: Bas√©e sur {len(relevant_docs)} √©chantillons r√©els

QUESTION M√âTIER √Ä ANALYSER: {business_question}
"""
    
    return strategic_context

def get_context_with_sources(docs):
    """
    Cr√©er un contexte enrichi avec les informations de source pour le LLM.
    
    Cette fonction format le contexte de mani√®re √† fournir au LLM
    toutes les informations n√©cessaires sur l'origine des donn√©es,
    permettant une tra√ßabilit√© compl√®te des r√©ponses.
    
    Args:
        docs (list): Liste des documents r√©cup√©r√©s par la recherche vectorielle
        
    Returns:
        str: Contexte format√© avec m√©tadonn√©es de source pour chaque document
    """
    context_parts = []
    
    for i, doc in enumerate(docs, 1):
        # Extraire les m√©tadonn√©es importantes de chaque document
        source_folder = doc.metadata.get('source_folder', 'unknown')
        rfp_status = doc.metadata.get('rfp_status', 'unknown')
        doc_type = doc.metadata.get('doc_type', 'unknown')
        doc_id = doc.metadata.get('doc_id', 'unknown')
        source_file = doc.metadata.get('source', 'unknown')
        
        # Formatter chaque source avec ses m√©tadonn√©es
        context_parts.append(
            f"[Source {i} - {rfp_status.upper()} RFP | Type: {doc_type} | ID: {doc_id[:8]}...]:\n"
            f"Fichier: {source_file}\n"
            f"{doc.page_content}\n"
        )
    
    # Joindre tous les contextes avec des s√©parateurs clairs
    return "\n\n".join(context_parts)

def load_document_registry():
    """
    Charge le registre des documents depuis le fichier JSON.
    
    Le registre contient la correspondance entre les IDs de documents
    et leurs m√©tadonn√©es (fichier, dossier, type, statut).
    
    Returns:
        dict: Registre des documents ou dictionnaire vide si le fichier n'existe pas
    """
    try:
        with open("./document_registry.json", "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        # Retourner un dictionnaire vide si le fichier n'existe pas encore
        return {}

def display_document_registry():
    """
    Affiche le registre des documents de mani√®re lisible.
    
    Utile pour le debugging et la v√©rification du contenu index√©.
    """
    registry = load_document_registry()
    if not registry:
        print("üìã Aucun registre de documents trouv√©")
        return
    
    print("\nüìã Registre des documents:")
    for doc_id, info in registry.items():
        # Afficher les informations essentielles de chaque document
        print(f"  üÜî {doc_id[:8]}... | {info['file']} | {info['type']} | {info['status']}")

# ===============================================================================
# NOUVELLES FONCTIONS D'ANALYSE RFP + R√âPONSES
# ===============================================================================

def retrieve_similar_chunks_with_category_filter(vectorstore, query, k=5, rfp_status=None, doc_category=None):
    """
    Recherche avanc√©e avec filtrage par statut ET cat√©gorie de document.
    
    Args:
        vectorstore (FAISS): Index vectoriel FAISS
        query (str): Requ√™te de recherche s√©mantique
        k (int): Nombre de chunks √† retourner
        rfp_status (str, optional): 'approved', 'rejected', ou None
        doc_category (str, optional): 'rfp', 'response', ou None
        
    Returns:
        list: Chunks filtr√©s selon les crit√®res demand√©s
    """
    # Recherche large pour avoir assez de r√©sultats apr√®s filtrage
    docs = vectorstore.similarity_search(query, k=k*4)
    
    # Appliquer les filtres demand√©s
    filtered_docs = docs
    
    if rfp_status:
        filtered_docs = [doc for doc in filtered_docs 
                        if doc.metadata.get('rfp_status') == rfp_status]
    
    if doc_category:
        filtered_docs = [doc for doc in filtered_docs 
                        if doc.metadata.get('doc_category') == doc_category]
    
    # Retourner les k premiers r√©sultats filtr√©s
    return filtered_docs[:k]

def analyze_rfp_vs_response_patterns(vectorstore, topic="architecture technique", k=8):
    """
    Compare les patterns dans les RFP (demandes) vs nos R√©ponses pour un sujet donn√©.
    
    Args:
        vectorstore (FAISS): Index vectoriel pour recherche s√©mantique
        topic (str): Sujet √† comparer entre RFP et R√©ponses
        k (int): Nombre de documents par cat√©gorie √† analyser
        
    Returns:
        dict: Analyse comparative structur√©e
    """
    print(f"üîÑ Analyse RFP vs R√©ponses pour: {topic}")
    
    # ===== ANALYSE DES DEMANDES CLIENTS (RFP) =====
    approved_rfp = retrieve_similar_chunks_with_category_filter(
        vectorstore, topic, k=k, rfp_status="approved", doc_category="rfp"
    )
    rejected_rfp = retrieve_similar_chunks_with_category_filter(
        vectorstore, topic, k=k, rfp_status="rejected", doc_category="rfp"
    )
    
    # ===== ANALYSE DE NOS R√âPONSES =====
    approved_responses = retrieve_similar_chunks_with_category_filter(
        vectorstore, topic, k=k, rfp_status="approved", doc_category="response"
    )
    rejected_responses = retrieve_similar_chunks_with_category_filter(
        vectorstore, topic, k=k, rfp_status="rejected", doc_category="response"
    )
    
    # ===== CONSTRUCTION DE L'ANALYSE COMPARATIVE =====
    analysis = {
        "topic": topic,
        "client_demands": {
            "approved_projects": {
                "count": len(approved_rfp),
                "patterns": [doc.page_content[:250] for doc in approved_rfp[:3]],
                "sources": [doc.metadata.get('project_number', 'unknown') for doc in approved_rfp]
            },
            "rejected_projects": {
                "count": len(rejected_rfp), 
                "patterns": [doc.page_content[:250] for doc in rejected_rfp[:3]],
                "sources": [doc.metadata.get('project_number', 'unknown') for doc in rejected_rfp]
            }
        },
        "our_responses": {
            "winning_responses": {
                "count": len(approved_responses),
                "patterns": [doc.page_content[:250] for doc in approved_responses[:3]],
                "sources": [doc.metadata.get('project_number', 'unknown') for doc in approved_responses]
            },
            "losing_responses": {
                "count": len(rejected_responses),
                "patterns": [doc.page_content[:250] for doc in rejected_responses[:3]],
                "sources": [doc.metadata.get('project_number', 'unknown') for doc in rejected_responses]
            }
        },
        "alignment_analysis": {
            "total_client_demands": len(approved_rfp) + len(rejected_rfp),
            "total_our_responses": len(approved_responses) + len(rejected_responses),
            "success_rate": f"{len(approved_responses)}/{len(approved_responses) + len(rejected_responses)}" 
                           if (len(approved_responses) + len(rejected_responses)) > 0 else "0/0"
        }
    }
    
    return analysis

def find_recurring_patterns_in_category(vectorstore, category="rfp", requirement_type="technologies", k=12):
    """
    üéØ RECONNAISSANCE SP√âCIALIS√âE DE PATTERNS PAR CAT√âGORIE
    =======================================================
    
    Cette fonction applique des techniques avanc√©es de pattern recognition pour 
    identifier les r√©currences sp√©cifiquement dans les RFP clients OU dans nos 
    R√©ponses techniques.
    
    Args:
        vectorstore (FAISS): Index vectoriel pour recherche s√©mantique
        category (str): "rfp" pour demandes clients, "response" pour nos r√©ponses
        requirement_type (str): Type d'exigence/sujet √† analyser
        k (int): Nombre de documents √† examiner (recommand√© 12+ pour stats)
        
    Returns:
        dict: Analyse de r√©currence avec approved_patterns et rejected_patterns
    """
    print(f"üîç Patterns r√©currents dans {category.upper()}: {requirement_type}")
    
    # ===== RECHERCHE DANS LA CAT√âGORIE SP√âCIFI√âE =====
    approved_docs = retrieve_similar_chunks_with_category_filter(
        vectorstore, requirement_type, k=k, rfp_status="approved", doc_category=category
    )
    rejected_docs = retrieve_similar_chunks_with_category_filter(
        vectorstore, requirement_type, k=k, rfp_status="rejected", doc_category=category
    )
    
    # ===== EXTRACTION DES PROJETS SOURCES =====
    approved_projects = list(set([doc.metadata.get('project_number', 'unknown') for doc in approved_docs]))
    rejected_projects = list(set([doc.metadata.get('project_number', 'unknown') for doc in rejected_docs]))
    
    # ===== CONSTRUCTION DE L'ANALYSE =====
    analysis = {
        "category": category,
        "requirement_type": requirement_type,
        "approved_patterns": {
            "count": len(approved_docs),
            "projects": approved_projects,
            "examples": [doc.page_content[:300] for doc in approved_docs[:4]],
            "success_rate": f"{len(approved_projects)} projets gagn√©s"
        },
        "rejected_patterns": {
            "count": len(rejected_docs),
            "projects": rejected_projects,
            "examples": [doc.page_content[:300] for doc in rejected_docs[:4]],
            "failure_rate": f"{len(rejected_projects)} projets perdus"
        },
        "recurrence_insights": {
            "total_occurrences": len(approved_docs) + len(rejected_docs),
            "total_projects": len(set(approved_projects + rejected_projects)),
            "success_ratio": f"{len(approved_docs)}/{len(approved_docs) + len(rejected_docs)}" 
                           if (len(approved_docs) + len(rejected_docs)) > 0 else "0/0",
            "pattern_strength": "Fort" if len(approved_docs) + len(rejected_docs) > 8 else "Mod√©r√©"
        }
    }
    
    return analysis

def load_rfp_response_mapping():
    """
    Charge le mapping RFP-R√©ponse depuis le fichier JSON.
    
    Returns:
        dict: Mapping des correspondances ou dictionnaire vide si inexistant
    """
    try:
        with open("./rfp_response_mapping.json", "r", encoding="utf-8") as f:
            return json.load(f)
    except FileNotFoundError:
        return {}

def display_rfp_response_mapping():
    """
    Affiche le mapping RFP-R√©ponse de mani√®re lisible.
    
    Utile pour v√©rifier les correspondances entre demandes et r√©ponses.
    """
    mapping = load_rfp_response_mapping()
    if not mapping:
        print("üîó Aucun mapping RFP-R√©ponse trouv√©")
        return
    
    print("\nüîó Mapping RFP ‚Üî R√©ponse:")
    for project_num, info in mapping.items():
        rfp_status = "‚úÖ" if info['rfp'] else "‚ùå"
        response_status = "‚úÖ" if info['response'] else "‚ùå"
        print(f"  üìÅ Projet {project_num} ({info['status']}) | RFP: {rfp_status} | R√©ponse: {response_status}")

# ===============================================================================
# CLASSE WRAPPER POUR LE MOD√àLE DE LANGAGE (LLM)
# ===============================================================================

class LLMWrapper:
    """
    Wrapper pour l'API Together et le mod√®le DeepSeek avec sp√©cialisation RFP.
    
    Cette classe encapsule l'interaction avec l'API Together pour
    simplifier les appels au mod√®le de langage et standardiser
    le format des requ√™tes avec des prompts sp√©cialis√©s pour l'analyse RFP.
    
    Attributes:
        client (Together): Client API Together configur√©
        model (str): Nom du mod√®le LLM √† utiliser
    """
    
    def __init__(self, api_key: str):
        """
        Initialise le wrapper LLM avec la cl√© API.
        
        Args:
            api_key (str): Cl√© API Together pour l'authentification
        """
        self.client = Together(api_key=api_key)
        # DeepSeek-V3 : mod√®le performant pour les t√¢ches de compr√©hension et g√©n√©ration
        self.model = "deepseek-ai/DeepSeek-V3"

    def invoke(self, question: str, context: str) -> str:
        """
        G√©n√®re une r√©ponse bas√©e sur le contexte fourni.
        
        Cette m√©thode construit un prompt optimis√© qui :
        1. Instruit le mod√®le sur son r√¥le et ses limites
        2. Fournit le contexte r√©cup√©r√© par la recherche vectorielle
        3. Pose la question de l'utilisateur
        4. Lance automatiquement l'√©valuation de fid√©lit√© APR√àS g√©n√©ration
        
        Args:
            question (str): Question de l'utilisateur
            context (str): Contexte r√©cup√©r√© avec m√©tadonn√©es de source
            
        Returns:
            str: R√©ponse g√©n√©r√©e par le mod√®le
        """
        # Construction du prompt avec instructions syst√®me et contexte
        messages = [
            {
                "role": "system", 
                "content": (
                    "You are an intelligent assistant that answers based on the context provided. "
                    "If the context doesn't contain the answer, say you don't know. "
                    "Pay attention to document IDs and types mentioned in the context. "
                    "Always cite your sources when possible.\n\n"
                    f"Context:\n{context}"
                )
            },
            {
                "role": "user", 
                "content": question
            }
        ]

        print("ü§ñ Appel au mod√®le DeepSeek...")
        # Appel synchrone √† l'API Together
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            stream=False  # Mode synchrone pour garantir la r√©ponse compl√®te
        )
        
        # Extraire le contenu de la r√©ponse
        answer = response.choices[0].message.content
        
        # Stocker dans les variables globales pour le judge pipeline
        global last_answer
        last_answer = answer
        
        # Retourner la r√©ponse (l'√©valuation se fera apr√®s dans le main)
        return answer

    def analyze_rfp_strategy(self, question: str, context: str) -> str:
        """
        G√©n√®re une analyse strat√©gique sp√©cialis√©e pour les RFP.
        
        Utilise un prompt sp√©cialis√© pour l'analyse comparative et strat√©gique.
        
        Args:
            question (str): Question strat√©gique
            context (str): Contexte d'analyse avec donn√©es approved/rejected
            
        Returns:
            str: Analyse strat√©gique d√©taill√©e
        """
        messages = [
            {
                "role": "system", 
                "content": (
                    "Tu es un consultant expert en analyse strat√©gique de RFP (Request for Proposal). "
                    "Ton r√¥le est d'analyser les donn√©es de r√©ponses pass√©es pour identifier :\n"
                    "- Les patterns de succ√®s et d'√©chec\n"
                    "- Les facteurs diff√©renciants dans les propositions gagnantes\n"
                    "- Les faiblesses r√©currentes dans les √©checs\n"
                    "- Des recommandations concr√®tes pour am√©liorer les futures r√©ponses\n\n"
                    "INSTRUCTIONS SP√âCIFIQUES :\n"
                    "- Compare syst√©matiquement les cas 'approved' vs 'rejected'\n"
                    "- Identifie les patterns r√©currents et les diff√©rences cl√©s\n"
                    "- Fournis des insights actionnables bas√©s sur les donn√©es\n"
                    "- Cite toujours tes sources avec les IDs de documents\n"
                    "- Structure ta r√©ponse avec des sections claires\n\n"
                    f"DONN√âES D'ANALYSE :\n{context}"
                )
            },
            {
                "role": "user", 
                "content": f"Analyse strat√©gique demand√©e : {question}"
            }
        ]

        print("üß† G√©n√©ration d'analyse strat√©gique RFP...")
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            stream=False
        )
        
        # Extraire le contenu de la r√©ponse
        answer = response.choices[0].message.content
        
        # Stocker dans les variables globales pour le judge pipeline
        global last_answer
        last_answer = answer
        
        # Retourner la r√©ponse (l'√©valuation se fera apr√®s dans le main)
        return answer

# ===============================================================================
# ANALYSE LLM INTELLIGENTE POUR PATTERNS STRAT√âGIQUES
# ===============================================================================

def analyze_strategic_patterns_with_llm(vectorstore, llm_client, category="m√©thodologie", k=10):
    """
    üß† ANALYSE LLM INTELLIGENTE POUR PATTERNS STRAT√âGIQUES
    ======================================================
    
    Cette fonction utilise un LLM pour analyser le contenu et g√©n√©rer des insights
    strat√©giques structur√©s, comme les patterns de succ√®s vs √©chec que vous voulez.
    
    Args:
        vectorstore (FAISS): Index vectoriel pour recherche
        llm_client (Together): Client LLM pour analyse intelligente
        category (str): Cat√©gorie √† analyser
        k (int): Nombre de documents √† analyser
        
    Returns:
        dict: Patterns strat√©giques structur√©s avec insights LLM
    """
    print(f"üß† Analyse LLM intelligente pour: {category}")
    
    # ===== COLLECTE DES DONN√âES =====
    approved_docs = retrieve_similar_chunks_with_filter(
        vectorstore, category, k=k, rfp_status="approved"
    )
    rejected_docs = retrieve_similar_chunks_with_filter(
        vectorstore, category, k=k, rfp_status="rejected"
    )
    
    # ===== PR√âPARATION DU CONTEXTE POUR LLM =====
    context = f"""
ANALYSE STRAT√âGIQUE DES PATTERNS RFP - CAT√âGORIE: {category.upper()}

=== DOCUMENTS DES PROJETS GAGN√âS (APPROVED) ===
{chr(10).join([f"Document {i+1}: {doc.page_content[:800]}" for i, doc in enumerate(approved_docs[:5])])}

=== DOCUMENTS DES PROJETS PERDUS (REJECTED) ===
{chr(10).join([f"Document {i+1}: {doc.page_content[:800]}" for i, doc in enumerate(rejected_docs[:5])])}

=== MISSION D'ANALYSE ===
Analysez ces documents pour identifier des patterns strat√©giques concrets et actionnables.
"""
    
    # ===== PROMPT SP√âCIALIS√â POUR PATTERN RECOGNITION =====
    prompt = f"""
Tu es un expert en analyse strat√©gique d'appels d'offres. Analyse les documents fournis pour identifier des patterns de succ√®s et d'√©chec.

CONTEXTE:
{context}

MISSION:
Identifie les patterns diff√©renciants entre les projets gagn√©s et perdus pour la cat√©gorie "{category}".

FORMAT DE SORTIE REQUIS:
‚úÖ PATTERNS DE SUCC√àS (ce qui marche):
- Pattern concret 1 (avec explication strat√©gique)
- Pattern concret 2 (avec explication strat√©gique)  
- Pattern concret 3 (avec explication strat√©gique)

‚ùå ANTI-PATTERNS (ce qui fait √©chouer):
- Anti-pattern 1 (avec explication des risques)
- Anti-pattern 2 (avec explication des risques)
- Anti-pattern 3 (avec explication des risques)

üéØ INSIGHTS STRAT√âGIQUES:
- Facteur diff√©renciant cl√©
- Recommandation actionnable
- Point d'attention critique

INSTRUCTIONS:
1. Sois concret et actionnable (pas de g√©n√©ralit√©s)
2. Base-toi sur les contenus r√©els des documents
3. Identifie les diff√©rences tangibles entre succ√®s et √©checs
4. Donne des recommendations pratiques pour gagner plus
5. Utilise un langage business et strat√©gique

R√âPONSE:
"""
    
    try:
        # ===== APPEL LLM POUR ANALYSE INTELLIGENTE =====
        response = llm_client.chat.completions.create(
            model="meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
            messages=[{"role": "user", "content": prompt}],
            stream=False,
            temperature=0.3  # Plus d√©terministe pour analyses strat√©giques
        )
        
        llm_analysis = response.choices[0].message.content
        
        # ===== CONSTRUCTION DU R√âSULTAT STRUCTUR√â =====
        result = {
            "category": category,
            "data_analyzed": {
                "approved_count": len(approved_docs),
                "rejected_count": len(rejected_docs),
                "total_documents": len(approved_docs) + len(rejected_docs)
            },
            "llm_strategic_analysis": llm_analysis,
            "methodology": "LLM Pattern Recognition + Semantic Search",
            "confidence": "High" if len(approved_docs) + len(rejected_docs) >= 8 else "Medium"
        }
        
        return result
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'analyse LLM: {e}")
        # Fallback vers analyse basique
        return {
            "category": category,
            "error": str(e),
            "fallback_analysis": {
                "approved_count": len(approved_docs),
                "rejected_count": len(rejected_docs),
                "raw_approved_samples": [doc.page_content[:200] for doc in approved_docs[:3]],
                "raw_rejected_samples": [doc.page_content[:200] for doc in rejected_docs[:3]]
            }
        }

def execute_complete_rfp_analysis(vectorstore, llm_client, domain):
    """
    üéØ ANALYSE STRAT√âGIQUE COMPL√àTE AUTOMATIS√âE
    ===========================================
    
    Ex√©cute automatiquement le prompt complet d'analyse RFP strat√©gique.
    
    Args:
        vectorstore (FAISS): Index vectoriel pour recherche
        llm_client: Client LLM pour analyses intelligentes
        domain (str): Domaine d'analyse (ex: "s√©curit√©", "cloud", "agile")
        
    Returns:
        dict: R√©sultats complets des 4 analyses avec insights actionnables
    """
    print(f"\nüöÄ ANALYSE STRAT√âGIQUE COMPL√àTE AUTOMATIS√âE - DOMAINE: {domain.upper()}")
    print("="*70)
    print("üìã Ex√©cution syst√©matique du framework d'analyse en 4 √©tapes...")
    print(f"üéØ PROMPT AUTOMATIS√â: Analyse strat√©gique compl√®te sur '{domain}'")
    
    results = {
        "domain": domain,
        "analysis_timestamp": "2025-01-23",
        "framework_steps": {},
        "prompt_executed": f"Analyse strat√©gique compl√®te sur {domain}"
    }
    
    try:
        # ===== √âTAPE 1: PATTERNS R√âCURRENTS =====
        print(f"\nüìà √âTAPE 1/4: PATTERNS R√âCURRENTS")
        print(f"üîç Commande: 'patterns: {domain}' - Identification exigences r√©currentes...")
        
        # patterns: [domaine] - Patterns de base
        basic_patterns = analyze_rfp_patterns(vectorstore, domain)
        print(f"   ‚úÖ patterns: {domain} ‚Üí {basic_patterns['total_analyzed']} documents analys√©s")
        
        print(f"üß† Commande: 'smart_patterns: {domain}' - Corr√©lations cach√©es avec IA...")
        # smart_patterns: [domaine] - Corr√©lations cach√©es avec LLM
        smart_patterns = analyze_strategic_patterns_with_llm(vectorstore, llm_client, domain)
        print(f"   ‚úÖ smart_patterns: {domain} ‚Üí Insights IA g√©n√©r√©s ({smart_patterns.get('confidence', 'Medium')} confiance)")
        
        results["framework_steps"]["step1_patterns_recurrents"] = {
            "patterns_command": f"patterns: {domain}",
            "smart_patterns_command": f"smart_patterns: {domain}",
            "basic_patterns": basic_patterns,
            "smart_patterns": smart_patterns
        }
        
        # ===== √âTAPE 2: HISTORIQUE FORCES/FAIBLESSES =====
        print(f"\nüìä √âTAPE 2/4: HISTORIQUE FORCES/FAIBLESSES")
        print(f"üíö Commande: 'approved: {domain}' - Analyse points forts r√©currents...")
        
        # approved: [domaine] - Points forts r√©currents
        approved_docs = retrieve_similar_chunks_with_filter(vectorstore, domain, k=8, rfp_status="approved")
        print(f"   ‚úÖ approved: {domain} ‚Üí {len(approved_docs)} cas de succ√®s analys√©s")
        
        print(f"üî¥ Commande: 'rejected: {domain}' - Analyse faiblesses syst√©matiques...")
        # rejected: [domaine] - Faiblesses syst√©matiques  
        rejected_docs = retrieve_similar_chunks_with_filter(vectorstore, domain, k=8, rfp_status="rejected")
        print(f"   ‚úÖ rejected: {domain} ‚Üí {len(rejected_docs)} cas d'√©chec analys√©s")
        
        results["framework_steps"]["step2_historique_forces_faiblesses"] = {
            "approved_command": f"approved: {domain}",
            "rejected_command": f"rejected: {domain}",
            "forces": {
                "count": len(approved_docs),
                "examples": [doc.page_content[:200] for doc in approved_docs[:3]]
            },
            "faiblesses": {
                "count": len(rejected_docs), 
                "examples": [doc.page_content[:200] for doc in rejected_docs[:3]]
            }
        }
        
        # ===== √âTAPE 3: FACTEURS VICTOIRE/D√âFAITE =====
        print(f"\n‚öñÔ∏è √âTAPE 3/4: FACTEURS VICTOIRE/D√âFAITE")
        print(f"üîÑ Commande: 'compare: {domain}' - Pourquoi nous gagnons/perdons...")
        
        # compare: [domaine] - Facteurs diff√©renciants
        comparison = compare_success_failure_factors(vectorstore, domain)
        print(f"   ‚úÖ compare: {domain} ‚Üí {comparison['success_factors']['count']} succ√®s vs {comparison['failure_factors']['count']} √©checs")
        
        print(f"üéØ Commande: 'strategy: pourquoi r√©ussissons-nous/√©chouons-nous sur {domain} ?' - Enseignements actionnables...")
        # strategy: pourquoi r√©ussissons-nous/√©chouons-nous sur [domaine] ?
        strategic_context = generate_strategic_insights(vectorstore, f"pourquoi r√©ussissons-nous/√©chouons-nous sur {domain}")
        strategy_question = f"pourquoi r√©ussissons-nous/√©chouons-nous sur {domain} ?"
        strategic_analysis = llm_client.analyze_rfp_strategy(strategy_question, strategic_context)
        print(f"   ‚úÖ strategy: pourquoi r√©ussissons-nous/√©chouons-nous sur {domain} ? ‚Üí Analyse strat√©gique g√©n√©r√©e")
        
        results["framework_steps"]["step3_facteurs_victoire_defaite"] = {
            "compare_command": f"compare: {domain}",
            "strategy_command": f"strategy: pourquoi r√©ussissons-nous/√©chouons-nous sur {domain} ?",
            "comparison": comparison,
            "strategic_insights": strategic_analysis
        }
        
        # ===== √âTAPE 4: COMPARAISON R√âUSSIS VS REJET√âS =====
        print(f"\nüîç √âTAPE 4/4: COMPARAISON R√âUSSIS VS REJET√âS")
        print(f"üîÑ Commande: 'rfp_vs_response: {domain}' - Divergences besoins clients vs propositions...")
        
        # rfp_vs_response: [domaine] - Divergences besoins/propositions
        rfp_response_analysis = analyze_rfp_vs_response_patterns(vectorstore, domain)
        print(f"   ‚úÖ rfp_vs_response: {domain} ‚Üí Taux succ√®s: {rfp_response_analysis['alignment_analysis']['success_rate']}")
        
        print(f"üèÜ Commande: 'competitive: {domain}' - Avantages/faiblesses concurrentielles...")
        # competitive: [domaine] - Intelligence concurrentielle
        competitive_analysis = analyze_competitive_intelligence(vectorstore, llm_client, domain)
        print(f"   ‚úÖ competitive: {domain} ‚Üí Intelligence concurrentielle g√©n√©r√©e")
        
        results["framework_steps"]["step4_comparaison_reussis_rejetes"] = {
            "rfp_vs_response_command": f"rfp_vs_response: {domain}",
            "competitive_command": f"competitive: {domain}",
            "rfp_vs_response": rfp_response_analysis,
            "competitive_intelligence": competitive_analysis
        }
        
        # ===== SYNTH√àSE FINALE DES INSIGHTS ACTIONNABLES =====
        print(f"\nüéØ SYNTH√àSE FINALE - INSIGHTS ACTIONNABLES POUR {domain.upper()}")
        print("="*70)
        print("üí° G√©n√©ration automatique des recommandations pour am√©liorer futures r√©ponses RFP...")
        
        total_docs = (len(approved_docs) + len(rejected_docs) + 
                     basic_patterns['total_analyzed'] + 
                     rfp_response_analysis['alignment_analysis']['total_client_demands'])
        
        # G√©n√©ration automatique des insights actionnables finaux
        final_prompt = f"""
Bas√© sur l'analyse strat√©gique compl√®te du domaine '{domain}', voici les √©l√©ments analys√©s :

PATTERNS R√âCURRENTS :
- {basic_patterns['total_analyzed']} documents analys√©s pour patterns de base
- Insights IA sur corr√©lations cach√©es g√©n√©r√©s

HISTORIQUE FORCES/FAIBLESSES :
- {len(approved_docs)} cas de succ√®s (points forts r√©currents)
- {len(rejected_docs)} cas d'√©chec (faiblesses syst√©matiques)

FACTEURS VICTOIRE/D√âFAITE :
- Comparaison {comparison['success_factors']['count']} succ√®s vs {comparison['failure_factors']['count']} √©checs
- Analyse strat√©gique sur pourquoi nous r√©ussissons/√©chouons

COMPARAISON R√âUSSIS VS REJET√âS :
- Taux de succ√®s: {rfp_response_analysis['alignment_analysis']['success_rate']}
- Intelligence concurrentielle g√©n√©r√©e

Fournissez 5 insights actionnables concrets pour am√©liorer nos futures r√©ponses RFP sur {domain}.
"""
        
        actionnable_insights = llm_client.analyze_rfp_strategy(
            f"Insights actionnables pour am√©liorer futures r√©ponses RFP sur {domain}", 
            final_prompt
        )
        
        results["synthesis"] = {
            "total_documents_analyzed": total_docs,
            "success_rate": rfp_response_analysis['alignment_analysis']['success_rate'],
            "commands_executed": [
                f"patterns: {domain}",
                f"smart_patterns: {domain}",
                f"approved: {domain}",
                f"rejected: {domain}",
                f"compare: {domain}",
                f"strategy: pourquoi r√©ussissons-nous/√©chouons-nous sur {domain} ?",
                f"rfp_vs_response: {domain}",
                f"competitive: {domain}"
            ],
            "actionnable_insights": actionnable_insights,
            "key_metrics": [
                f"Patterns analys√©s: {basic_patterns['total_analyzed']} documents",
                f"Forces identifi√©es: {len(approved_docs)} cas de succ√®s", 
                f"Faiblesses analys√©es: {len(rejected_docs)} cas d'√©chec",
                f"Taux de succ√®s global: {rfp_response_analysis['alignment_analysis']['success_rate']}",
                f"Intelligence concurrentielle: G√©n√©r√©e avec insights LLM"
            ]
        }
        
        print("‚úÖ ANALYSE STRAT√âGIQUE COMPL√àTE TERMIN√âE AVEC SUCC√àS!")
        print(f"üéØ 8 COMMANDES EX√âCUT√âES AUTOMATIQUEMENT pour '{domain}'")
        print("üíº Insights actionnables disponibles pour am√©lioration futures RFP")
        return results
        
    except Exception as e:
        print(f"‚ùå Erreur lors de l'analyse compl√®te: {e}")
        results["error"] = str(e)
        return results

def analyze_competitive_intelligence(vectorstore, llm_client, focus="facteurs de diff√©renciation", k=12):
    """
    üîç INTELLIGENCE CONCURRENTIELLE AVANC√âE
    =======================================
    
    Analyse sp√©cialis√©e pour identifier nos avantages concurrentiels
    et les raisons de nos victoires/d√©faites face √† la concurrence.
    
    Args:
        vectorstore (FAISS): Index vectoriel
        llm_client (Together): Client LLM pour analyse
        focus (str): Zone d'analyse concurrentielle
        k (int): Nombre de documents
        
    Returns:
        dict: Intelligence concurrentielle structur√©e
    """
    print(f"üîç Analyse concurrentielle: {focus}")
    
    # Recherche large sur tous les documents
    all_docs = retrieve_similar_chunks(vectorstore, focus, k=k*2)
    
    # S√©paration par r√©sultat
    wins = [doc for doc in all_docs if doc.metadata.get('rfp_status') == 'approved']
    losses = [doc for doc in all_docs if doc.metadata.get('rfp_status') == 'rejected']
    
    context = f"""
INTELLIGENCE CONCURRENTIELLE - FOCUS: {focus.upper()}

=== VICTOIRES CONCURRENTIELLES ({len(wins)} cas) ===
{chr(10).join([f"Victoire {i+1}: {doc.page_content[:600]}" for i, doc in enumerate(wins[:4])])}

=== D√âFAITES CONCURRENTIELLES ({len(losses)} cas) ===
{chr(10).join([f"D√©faite {i+1}: {doc.page_content[:600]}" for i, doc in enumerate(losses[:4])])}
"""
    
    prompt = f"""
Tu es un consultant en intelligence concurrentielle. Analyse ces donn√©es pour identifier pourquoi nous gagnons ou perdons face √† la concurrence.

{context}

ANALYSE DEMAND√âE - FOCUS: {focus}

FORMAT DE SORTIE:
üèÜ NOS AVANTAGES CONCURRENTIELS:
- Avantage diff√©renciant 1
- Avantage diff√©renciant 2  
- Avantage diff√©renciant 3

‚ö†Ô∏è NOS FAIBLESSES FACE √Ä LA CONCURRENCE:
- Faiblesse r√©currente 1
- Faiblesse r√©currente 2
- Faiblesse r√©currente 3

üéØ STRAT√âGIES POUR GAGNER PLUS:
- Recommandation strat√©gique 1
- Recommandation strat√©gique 2
- Recommandation strat√©gique 3

üìä INSIGHTS BUSINESS:
- Insight cl√© sur notre positionnement
- Analyse du march√© et tendances
- Pr√©diction pour futures comp√©titions

Sois sp√©cifique, actionnable et base-toi sur les vraies donn√©es des documents.
"""
    
    try:
        response = llm_client.chat.completions.create(
            model="meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo",
            messages=[{"role": "user", "content": prompt}],
            stream=False,
            temperature=0.2
        )
        
        return {
            "focus": focus,
            "competitive_intelligence": response.choices[0].message.content,
            "data_source": f"{len(wins)} victoires, {len(losses)} d√©faites analys√©es",
            "methodology": "Competitive Intelligence LLM Analysis"
        }
        
    except Exception as e:
        return {"error": f"Erreur analyse concurrentielle: {e}"}

# ===============================================================================
# FONCTION PRINCIPALE ET INTERFACE UTILISATEUR
# ===============================================================================

def main():
    """
    FONCTION PRINCIPALE D'ORCHESTRATION DU SYST√àME RAG STRAT√âGIQUE
    
    Point d'entr√©e principal du syst√®me d'analyse RFP.
    """
    # ===== D√âCLARATIONS GLOBALES =====
    global last_retrieved_docs, last_evaluation_score, last_evaluation_reason, last_analysis_prompt, console_logger
    
    # ===== D√âMARRAGE DU LOGGING AUTOMATIQUE =====
    console_logger.start_logging()
    
    # ===== PHASE 1: CONFIGURATION S√âCURIS√âE ET VALIDATION =====
    faiss_path = "./faiss_index"  
    api_key = "tgp_v1_vt3VH4DbcOSci1iOn0sfpUSjyjhfpivPZzpOTUmSkC4"

    # ===== VALIDATION AUTHENTIFICATION =====
    if api_key == "YOUR_TOGETHER_API_KEY":
        print("‚ö†Ô∏è ERREUR CONFIGURATION: Merci de remplacer 'YOUR_TOGETHER_API_KEY' par ta cl√© API valide.")
        print("üí° Guide: Obtenez votre cl√© sur https://together.ai/")
        console_logger.stop_logging()
        return

    # ===== PHASE 2: INITIALISATION DES MOTEURS IA =====
    print("üöÄ Initialisation du syst√®me RAG strat√©gique avec support VLM...")
    try:
        # Client VLM sp√©cialis√© pour traitement PDFs scann√©s
        vlm_client = Together(api_key=api_key)
        print("‚úÖ Client VLM configur√©: Llama-3.2-90B-Vision-Instruct-Turbo")
        
        # Wrapper LLM pour g√©n√©ration r√©ponses strategiques
        llm = LLMWrapper(api_key=api_key)
        print("‚úÖ Wrapper LLM configur√©: DeepSeek-V3 avec prompts RFP sp√©cialis√©s")
        
    except Exception as e:
        print(f"‚ùå Erreur initialisation IA: {e}")
        print("üîß V√©rifiez: connexion r√©seau, validit√© cl√© API, quotas Together.ai")
        return

    # ===== PHASE 3: GESTION INTELLIGENTE DE L'INDEX VECTORIEL =====
    if not os.path.exists(faiss_path):
        # ===== MODE CR√âATION INITIALE =====
        print("üîÑ CR√âATION INDEX INITIAL: Traitement complet documents avec VLM...")
        print("üìÅ Scanning: approvedRfp/ + rejectedRfp/ + documents scann√©s")
        
        try:
            # Chargement et chunking intelligent avec m√©tadonn√©es enrichies
            chunks, document_registry, rfp_response_mapping = load_and_chunk_documents(vlm_client=vlm_client)
            print(f"üìä Documents trait√©s: {len(document_registry)} fichiers")
            print(f"üß© Chunks g√©n√©r√©s: {len(chunks)} segments indexables")
            print(f"üîó Projets mapp√©s: {len(rfp_response_mapping)} correspondances RFP-R√©ponse")
            
            if chunks:
                # Cr√©ation index FAISS optimis√© avec embeddings s√©mantiques
                vectorstore = create_faiss_index(chunks, faiss_path)
                print("‚úÖ Index FAISS cr√©√© et sauvegard√© avec succ√®s")
            else:
                print("‚ùå ERREUR: Aucun chunk cr√©√© - v√©rifiez contenu dossiers RFP")
                console_logger.stop_logging()
                return
                
        except Exception as e:
            print(f"‚ùå Erreur cr√©ation index: {e}")
            console_logger.stop_logging()
            return
    else:
        # ===== MODE CHARGEMENT OPTIMIS√â =====
        print("üì¶ CHARGEMENT INDEX EXISTANT: Optimisation performance...")
        try:
            vectorstore = FAISS.load_local(
                faiss_path, 
                embedding_model,
                allow_dangerous_deserialization=True
            )
            # Restauration registres pour tra√ßabilit√©
            document_registry = load_document_registry()
            rfp_response_mapping = load_rfp_response_mapping()
            print("‚úÖ Index et registres charg√©s avec succ√®s")
            print(f"üìä Documents index√©s: {len(document_registry)}")
            print(f"üîó Mappings RFP-R√©ponse: {len(rfp_response_mapping)}")
            
        except Exception as e:
            print(f"‚ùå Erreur chargement index: {e}")
            print("üí° Solution: Supprimez ./faiss_index pour recr√©ation")
            console_logger.stop_logging()
            return

    # ===== PHASE 4: INTERFACE UTILISATEUR SIMPLIFI√âE =====
    print("\n" + "="*80)
    print("üß† SYST√àME D'ANALYSE RFP SIMPLIFI√â")
    print("üéØ Tapez simplement votre domaine d'analyse")
    print("="*80)
    
    print("\n‚ú® INTERFACE SIMPLIFI√âE:")
    print("  ‚ö° Tapez simplement un domaine ‚Üí Analyse automatique compl√®te")
    print("     üìä Exemples: 's√©curit√©', 'cloud', 'agile', 'architecture', 'ia'")
    print("     ü§ñ Le syst√®me fait automatiquement toute l'analyse pour vous!")
    
    print("\n‚öôÔ∏è COMMANDES SP√âCIALES:")
    print("  ÔøΩ 'registry' ‚Üí Voir documents index√©s")
    print("  ‚ùì 'help' ‚Üí Aide")
    print("  ÔøΩ 'quit' ‚Üí Quitter")
    print("  ‚öñÔ∏è 'compare: [sujet]' ‚Üí Comparaison facteurs succ√®s vs √©chec")
    print("  üìö 'lessons: [domaine]' ‚Üí Extraction enseignements historiques")
    print("  üéØ 'requirements: [type]' ‚Üí Cartographie exigences r√©currentes")
    print("  üöÄ 'strategy: [question m√©tier]' ‚Üí Analyse compl√®te executive")
    
    
    print(f"\nüìä √âTAT SYST√àME: {len(document_registry)} docs index√©s")
    print("üéÆ Pr√™t pour analyse...")
    
    # ===== PHASE 5: BOUCLE INTERACTION SIMPLIFI√âE =====
    while True:
        try:
            # ===== COLLECTE INPUT UTILISATEUR =====
            query = input("\n" + "="*50 + "\nüîé Entrez votre domaine d'analyse: ").strip()
            
            # ===== GESTION COMMANDES DE CONTR√îLE =====
            if query.lower() in ["quit", "exit", "q"]:
                print("\nüëã Session termin√©e!")
                break
                
            if not query:
                print("üí¨ Veuillez saisir un domaine...")
                continue
        
            # ===== COMMANDES UTILITAIRES SYST√àME =====
            
            # Affichage registre documentaire
            if query.lower() == "registry":
                print("\nüìë REGISTRE DOCUMENTAIRE:")
                print("-" * 50)
                display_document_registry()
                print(f"\nüìä R√©sum√©: {len(document_registry)} documents index√©s")
                continue
                
            # R√©affichage aide simplifi√©e
            if query.lower() == "help":
                print("\n" + "="*50)
                print("üß† AIDE - SYST√àME RAG SIMPLIFI√â")
                print("="*50)
                print("\n‚ú® UTILISATION:")
                print("  üîç Tapez simplement un domaine (ex: 's√©curit√©', 'cloud', 'agile')")
                print("  üìä Le syst√®me fait automatiquement l'analyse compl√®te")
                print("\n‚öôÔ∏è COMMANDES:")
                print("  üìë 'registry' ‚Üí Voir documents index√©s")
                print("  ‚ùì 'help' ‚Üí Cette aide")
                print("  üö™ 'quit' ‚Üí Quitter")
                continue
                
            # ===== INTERFACE SIMPLIFI√âE : JUSTE LE DOMAINE =====
            # L'utilisateur tape juste le domaine et on fait l'analyse automatique
            domain = query.strip()
            
            # Stocker le prompt d'analyse pour promptEnhancer.py
            last_analysis_prompt = f"Analyse strat√©gique compl√®te des RFP sur le domaine {domain}"
            
            print(f"\nüöÄ ANALYSE AUTOMATIQUE DU DOMAINE: '{domain.upper()}'")
            print("üìã Ex√©cution de l'analyse strat√©gique compl√®te...")
            
            try:
                # Ex√©cution du workflow complet automatis√©
                complete_analysis = execute_complete_rfp_analysis(vectorstore, llm, domain)
                
                print("\n" + "="*70)
                print("üìä RAPPORT D'ANALYSE STRAT√âGIQUE COMPL√àTE")
                print("="*70)
                
                # Affichage des r√©sultats de l'analyse automatique
                if "synthesis" in complete_analysis:
                    synthesis = complete_analysis["synthesis"]
                    
                    print(f"\nüìà M√âTRIQUES GLOBALES:")
                    for metric in synthesis["key_metrics"]:
                        print(f"   ‚Ä¢ {metric}")
                    
                    print(f"\nüí° INSIGHTS ACTIONNABLES POUR AM√âLIORER FUTURES RFP SUR {domain.upper()}:")
                    print("="*60)
                    print(synthesis["actionnable_insights"])
                    print("="*60)
                
                # ===== √âVALUATION AVEC VARIABLES SIMPLES =====
                if judge_llm and "synthesis" in complete_analysis and "actionnable_insights" in complete_analysis["synthesis"]:
                    print("\nüîç √âvaluation automatique de fid√©lit√©...")
                    
                    docs_for_evaluation = []
                    if "step1_patterns_recurrents" in complete_analysis["framework_steps"]:
                        basic_patterns = complete_analysis["framework_steps"]["step1_patterns_recurrents"]["basic_patterns"]
                        for pattern in basic_patterns.get("approved_patterns", [])[:2]:
                            docs_for_evaluation.append(pattern)
                    
                    evaluation_result = evaluate_faithfulness_after_generation(
                        question=f"Insights actionnables pour am√©liorer futures r√©ponses RFP sur {domain}",
                        answer=complete_analysis["synthesis"]["actionnable_insights"],
                        retrieved_docs=docs_for_evaluation if docs_for_evaluation else ["Analyse strat√©gique compl√®te effectu√©e"]
                    )
                    
                    print_judge_result(evaluation_result)
                
            except Exception as e:
                print(f"‚ùå Erreur analyse: {e}")
            continue
                
        except KeyboardInterrupt:
            # ===== GESTION INTERRUPTION PROPRE =====
            print("\n\n‚èπÔ∏è Session interrompue par l'utilisateur.")
            print("üíæ √âtat du syst√®me pr√©serv√© pour prochaine utilisation.")
            break
            
        except Exception as e:
            # ===== GESTION ERREURS ROBUSTE =====
            print(f"\n‚ùå Erreur syst√®me: {e}")
            print("üîÑ Le syst√®me reste op√©rationnel, continuez vos analyses...")
    
    # ===== FERMETURE PROPRE DU LOGGING √Ä LA FIN DE LA BOUCLE =====
    console_logger.stop_logging()

# ===============================================================================
# POINT D'ENTR√âE PRINCIPAL DU SYST√àME RAG STRAT√âGIQUE
# ===============================================================================

if __name__ == "__main__":
    """
    POINT D'ENTR√âE PRINCIPAL DU SYST√àME D'INTELLIGENCE RFP
    
    Cette condition assure que le script ne s'ex√©cute automatiquement 
    que s'il est lanc√© directement depuis la ligne de commande.
    """
    print("üöÄ D√âMARRAGE SYST√àME RAG STRAT√âGIQUE POUR ANALYSE RFP")
    print("=" * 70)
    print("üìä Module: Intelligence concurrentielle et analyse d'affaires")
    print("üéØ Objectif: Optimiser les taux de victoire sur appels d'offres")
    print("üîß Architecture: RAG + VLM + LLM + Analytics strat√©giques")
    print("=" * 70)
    
    try:
        main()
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")
        print("üõ†Ô∏è Consultez la documentation ou contactez le support technique")
    
    try:
        main()
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")
        print("ÔøΩÔ∏è Consultez la documentation ou contactez le support technique")
    
    print("\nüëã Session d'analyse RFP termin√©e")
    print("üíæ Merci d'avoir utilis√© le syst√®me d'intelligence strat√©gique")