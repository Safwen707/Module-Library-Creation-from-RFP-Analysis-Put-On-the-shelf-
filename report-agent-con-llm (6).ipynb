{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12600200,"sourceType":"datasetVersion","datasetId":7958376}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch transformers accelerate pandas numpy nltk scikit-learn reportlab PyPDF2 pdfplumber","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:44.516340Z","iopub.execute_input":"2025-07-29T15:48:44.517136Z","iopub.status.idle":"2025-07-29T15:48:47.979489Z","shell.execute_reply.started":"2025-07-29T15:48:44.517100Z","shell.execute_reply":"2025-07-29T15:48:47.978710Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: reportlab in /usr/local/lib/python3.11/dist-packages (4.4.3)\nRequirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\nRequirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.7)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from reportlab) (11.2.1)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from reportlab) (3.4.2)\nRequirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250506)\nRequirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.0)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (44.0.3)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n","output_type":"stream"}],"execution_count":169},{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\nfrom typing import Dict, List, Any, Optional\ntry:\n    from typing import Tuple\nexcept ImportError:\n    # For older Python versions\n    Tuple = tuple\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nimport re\nfrom collections import Counter, defaultdict\nimport numpy as np\nimport torch\n\n# PDF generation\nfrom reportlab.lib.pagesizes import letter, A4\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, KeepTogether\nfrom reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\nfrom reportlab.lib.units import inch\nfrom reportlab.lib import colors\nfrom reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY, TA_RIGHT\n\n# Natural Language Processing\nimport nltk\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# PDF reading\nimport PyPDF2\nimport pdfplumber\n\n# HuggingFace Transformers for LLM integration\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:47.981287Z","iopub.execute_input":"2025-07-29T15:48:47.981592Z","iopub.status.idle":"2025-07-29T15:48:47.989667Z","shell.execute_reply.started":"2025-07-29T15:48:47.981564Z","shell.execute_reply":"2025-07-29T15:48:47.988882Z"}},"outputs":[],"execution_count":170},{"cell_type":"code","source":"try:\n    nltk.data.find('tokenizers/punkt')\nexcept LookupError:\n    nltk.download('punkt')\n\ntry:\n    nltk.data.find('corpora/stopwords')\nexcept LookupError:\n    nltk.download('stopwords')\n\ntry:\n    nltk.data.find('vader_lexicon')\nexcept LookupError:\n    nltk.download('vader_lexicon')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:47.990473Z","iopub.execute_input":"2025-07-29T15:48:47.990687Z","iopub.status.idle":"2025-07-29T15:48:48.061523Z","shell.execute_reply.started":"2025-07-29T15:48:47.990662Z","shell.execute_reply":"2025-07-29T15:48:48.060722Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n","output_type":"stream"}],"execution_count":171},{"cell_type":"code","source":"@dataclass\nclass ModuleMapping:\n    module_name: str = \"\"\n    module_code: str = \"\"\n    required: bool = False\n    available: bool = False\n    coverage_percentage: float = 0.0\n    status: str = \"Unknown\"\n    notes: str = \"\"\n    client_priority: str = \"Medium\"\n    description: str = \"\"\n    components: str = \"\"\n    strengths: str = \"\"\n    alignment: str = \"\"\n\n@dataclass\nclass GapItem:\n    gap_type: str = \"Unknown\"\n    description: str = \"\"\n    severity: str = \"Medium\"\n    business_impact: str = \"\"\n    mitigation_strategy: str = \"\"\n    effort_required: str = \"2-4 weeks\"\n    cost_estimate: str = \"$10K-$25K\"\n    dependencies: List[str] = field(default_factory=list)\n    risk_if_unaddressed: str = \"\"\n\n@dataclass\nclass WinLossFactor:\n    factor_type: str = \"Unknown\"  # Win or Loss\n    description: str = \"\"\n    impact: str = \"Medium\"\n    confidence: float = 0.85\n    category: str = \"General\"\n\n@dataclass\nclass Requirement:\n    requirement_type: str = \"Functional\"\n    description: str = \"\"\n    priority: str = \"Should Have\"\n    our_capability: str = \"Partial\"\n    effort_to_meet: str = \"2-4 weeks\"\n\n@dataclass\nclass RiskAssessment:\n    risk_type: str = \"Technical\"\n    description: str = \"\"\n    probability: str = \"Medium\"\n    impact: str = \"Medium\"\n    mitigation_plan: str = \"\"\n\n@dataclass\nclass RFPFeasibilityAssessment:\n    can_respond: bool\n    confidence_score: float\n    win_probability: float\n    total_modules: int\n    available_modules: int\n    partial_modules: int\n    missing_modules: int\n    critical_gaps: List[GapItem]\n    all_gaps: List[GapItem]\n    strengths: List[str]\n    weaknesses: List[str]\n    opportunities: List[str]\n    threats: List[str]\n    required_actions: List[tuple]\n    risks: List[RiskAssessment]\n    investment_required: str\n    timeline_estimate: str\n    resource_requirements: str\n    executive_summary: str = \"\"\n    detailed_rationale: str = \"\"\n    competitive_positioning: str = \"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:48.063301Z","iopub.execute_input":"2025-07-29T15:48:48.063530Z","iopub.status.idle":"2025-07-29T15:48:48.076460Z","shell.execute_reply.started":"2025-07-29T15:48:48.063512Z","shell.execute_reply":"2025-07-29T15:48:48.075880Z"}},"outputs":[],"execution_count":172},{"cell_type":"code","source":"@dataclass\nclass TechnicalProposal:\n    solution_overview: str = \"\"\n    technical_architecture: str = \"\"\n    implementation_approach: str = \"\"\n    integration_strategy: str = \"\"\n    security_framework: str = \"\"\n    performance_specifications: str = \"\"\n    testing_methodology: str = \"\"\n    deployment_strategy: str = \"\"\n    \n@dataclass\nclass FinancialProposal:\n    total_cost: str = \"$0\"\n    cost_breakdown: Dict[str, str] = field(default_factory=dict)\n    payment_schedule: str = \"\"\n    roi_analysis: str = \"\"\n    cost_justification: str = \"\"\n    pricing_model: str = \"\"\n    maintenance_costs: str = \"\"\n    optional_services: Dict[str, str] = field(default_factory=dict)\n\n@dataclass\nclass RFPResponse:\n    executive_summary: str = \"\"\n    technical_proposal: TechnicalProposal = field(default_factory=TechnicalProposal)\n    financial_proposal: FinancialProposal = field(default_factory=FinancialProposal)\n    project_timeline: str = \"\"\n    risk_mitigation: str = \"\"\n    team_composition: str = \"\"\n    compliance_statement: str = \"\"\n    references_case_studies: str = \"\"\n    assumptions_dependencies: str = \"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:48.077126Z","iopub.execute_input":"2025-07-29T15:48:48.077336Z","iopub.status.idle":"2025-07-29T15:48:48.096244Z","shell.execute_reply.started":"2025-07-29T15:48:48.077313Z","shell.execute_reply":"2025-07-29T15:48:48.095528Z"}},"outputs":[],"execution_count":173},{"cell_type":"code","source":"class LLMProcessor:\n    def __init__(self):\n        self.model_name = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n        try:\n            from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n            import torch\n            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n            self.model = AutoModelForCausalLM.from_pretrained(self.model_name)\n            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n            self.model.to(self.device)\n            self.pipeline = pipeline(\n                \"text-generation\",\n                model=self.model,\n                tokenizer=self.tokenizer,\n                device=0 if self.device == \"cuda\" else -1\n            )\n            print(f\"Initialized LLMProcessor with {self.model_name} on {self.device}\")\n        except Exception as e:\n            print(f\"Error initializing TinyLlama: {e}\")\n            raise RuntimeError(\"Failed to initialize LLMProcessor\")\n\n    def _generate_text(self, prompt: str, max_length: int = 500) -> str:\n        try:\n            # Encode input to check token count\n            input_tokens = self.tokenizer.encode(prompt, return_tensors=\"pt\")\n            input_length = len(input_tokens[0])\n            \n            # Set reasonable limits\n            max_input_tokens = 800  # Reduced from 1500\n            min_output_tokens = 50   # Minimum tokens to generate\n            \n            # Truncate input if too long\n            if input_length > max_input_tokens:\n                truncated_tokens = input_tokens[0][:max_input_tokens]\n                prompt = self.tokenizer.decode(truncated_tokens, skip_special_tokens=True)\n                input_length = max_input_tokens\n                print(f\"Input prompt truncated to {input_length} tokens\")\n            \n            # Calculate available tokens for generation\n            max_new_tokens = max(min_output_tokens, max_length - input_length)\n            \n            # If still not enough tokens, use a shorter prompt\n            if max_new_tokens < min_output_tokens:\n                # Take only the last part of the prompt to keep context\n                words = prompt.split()\n                shortened_prompt = \" \".join(words[-100:])  # Last 100 words\n                input_tokens = self.tokenizer.encode(shortened_prompt, return_tensors=\"pt\")\n                input_length = len(input_tokens[0])\n                max_new_tokens = max(min_output_tokens, max_length - input_length)\n                prompt = shortened_prompt\n                print(f\"Prompt further shortened to {input_length} tokens\")\n            \n            # Ensure we have positive tokens for generation\n            if max_new_tokens <= 0:\n                print(f\"Cannot generate text: insufficient tokens. Input: {input_length}, Available: {max_new_tokens}\")\n                return \"\"\n            \n            outputs = self.pipeline(\n                prompt,\n                max_new_tokens=max_new_tokens,\n                temperature=0.7,\n                top_p=0.9,\n                do_sample=True,\n                return_full_text=False,\n                pad_token_id=self.tokenizer.eos_token_id,\n                no_repeat_ngram_size=3\n                # Removed early_stopping - not valid for this model\n            )[0][\"generated_text\"].strip()\n            \n            # Clean up output\n            outputs = re.sub(r'^You are an expert.*?[\\n\\s]*', '', outputs, flags=re.DOTALL)\n            return outputs\n            \n        except Exception as e:\n            print(f\"Error generating text: {e}\")\n            return \"\"\n\n    def analyze_module_coverage(self, modules: List[ModuleMapping]) -> str:\n        module_summary = \"\\n\".join([f\"- {m.module_name}: {m.status} (Coverage: {m.coverage_percentage}%)\" for m in modules])\n        prompt = f\"\"\"\n        You are an expert RFP analyst. Analyze the following module coverage data:\n        {module_summary}\n        Provide a concise analysis (max 100 words) of the module coverage, highlighting strengths and weaknesses.\n        \"\"\"\n        return self._generate_text(prompt, max_length=200) or \"Module coverage analysis unavailable.\"\n\n    def analyze_gaps_impact(self, gaps: List[GapItem]) -> str:\n        gap_summary = \"\\n\".join([f\"- {g.description} (Type: {g.gap_type}, Severity: {g.severity})\" for g in gaps])\n        prompt = f\"\"\"\n        You are an expert RFP analyst. Analyze the following gaps:\n        {gap_summary}\n        Provide a concise analysis (max 100 words) of the impact of these gaps, focusing on critical gaps and mitigation potential.\n        \"\"\"\n        return self._generate_text(prompt, max_length=200) or \"Gap impact analysis unavailable.\"\n\n    def analyze_win_loss_patterns(self, win_loss_factors: List[WinLossFactor]) -> str:\n        factor_summary = \"\\n\".join([f\"- {f.description} (Type: {f.factor_type}, Impact: {f.impact})\" for f in win_loss_factors])\n        prompt = f\"\"\"\n        You are an expert RFP analyst. Analyze the following win/loss factors:\n        {factor_summary}\n        Provide a concise analysis (max 100 words) of patterns in wins and losses, identifying opportunities.\n        \"\"\"\n        return self._generate_text(prompt, max_length=200) or \"Win/loss pattern analysis unavailable.\"\n\n    def generate_executive_recommendation(self, assessment: RFPFeasibilityAssessment) -> str:\n        prompt = f\"\"\"\n        You are an expert RFP analyst. Based on the following assessment:\n        - Can Respond: {assessment.can_respond}\n        - Confidence Score: {assessment.confidence_score:.1f}%\n        - Win Probability: {assessment.win_probability:.1f}%\n        - Module Coverage: {assessment.available_modules}/{assessment.total_modules}\n        - Critical Gaps: {len(assessment.critical_gaps)}\n        Provide a concise executive recommendation (max 100 words) for whether to proceed with the RFP response.\n        \"\"\"\n        return self._generate_text(prompt, max_length=200) or \"Recommendation: Proceed if gaps can be addressed.\"\n\n    def analyze_competitive_positioning(self, modules: List[ModuleMapping], gaps: List[GapItem], win_loss_factors: List[WinLossFactor]) -> str:\n        module_summary = \"\\n\".join([f\"- {m.module_name}: {m.status}\" for m in modules])\n        gap_summary = \"\\n\".join([f\"- {g.description} (Severity: {g.severity})\" for g in gaps])\n        factor_summary = \"\\n\".join([f\"- {f.description} (Type: {f.factor_type})\" for f in win_loss_factors])\n        prompt = f\"\"\"\n        You are an expert RFP analyst. Analyze the competitive positioning based on:\n        Modules:\n        {module_summary}\n        Gaps:\n        {gap_summary}\n        Win/Loss Factors:\n        {factor_summary}\n        Provide a concise competitive analysis (max 150 words).\n        \"\"\"\n        return self._generate_text(prompt, max_length=300) or \"Competitive positioning analysis unavailable.\"\n\n    def generate_action_plan(self, gaps: List[GapItem], missing_modules: List[ModuleMapping], timeline: str, investment: str) -> str:\n        gap_summary = \"\\n\".join([f\"- {g.description} (Severity: {g.severity})\" for g in gaps])\n        module_summary = \"\\n\".join([f\"- {m.module_name}\" for m in missing_modules])\n        prompt = f\"\"\"\n        You are an expert RFP analyst. Generate an action plan to address:\n        Gaps:\n        {gap_summary}\n        Missing Modules:\n        {module_summary}\n        Timeline: {timeline}\n        Investment: {investment}\n        Provide a concise action plan (max 150 words).\n        \"\"\"\n        return self._generate_text(prompt, max_length=300) or \"Action plan: Address critical gaps and develop missing modules.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:48.097674Z","iopub.execute_input":"2025-07-29T15:48:48.098284Z","iopub.status.idle":"2025-07-29T15:48:48.117176Z","shell.execute_reply.started":"2025-07-29T15:48:48.098267Z","shell.execute_reply":"2025-07-29T15:48:48.116461Z"}},"outputs":[],"execution_count":174},{"cell_type":"code","source":"class DocumentProcessor:\n    def __init__(self):\n        self.llm_processor = LLMProcessor()  \n        \n    def extract_text_from_pdf(self, file_path: str) -> str:\n        \"\"\"Enhanced PDF text extraction with multiple fallback methods\"\"\"\n        try:\n            # Primary method: pdfplumber\n            import pdfplumber\n            with pdfplumber.open(file_path) as pdf:\n                text = \"\"\n                for page in pdf.pages:\n                    page_text = page.extract_text()\n                    if page_text:\n                        text += page_text + \"\\n\"\n                \n                # If pdfplumber fails, try PyPDF2 as fallback\n                if not text.strip():\n                    import PyPDF2\n                    with open(file_path, 'rb') as file:\n                        pdf_reader = PyPDF2.PdfReader(file)\n                        for page in pdf_reader.pages:\n                            text += page.extract_text() + \"\\n\"\n                \n                return text.strip()\n        except Exception as e:\n            print(f\"Error extracting text from {file_path}: {e}\")\n            return \"\"\n\n    def parse_modules_enhanced(self, text: str) -> List[ModuleMapping]:\n        \"\"\"Significantly improved module parsing with advanced pattern recognition\"\"\"\n        modules = []\n        \n        # Strategy 1: Advanced structured format parsing\n        modules.extend(self._parse_structured_modules_v2(text))\n        \n        # Strategy 2: Table-based module extraction\n        if not modules:\n            modules.extend(self._parse_table_modules(text))\n        \n        # Strategy 3: Section-based module parsing\n        if len(modules) < 3:\n            modules.extend(self._parse_section_modules(text))\n        \n        # Strategy 4: Context-aware module detection\n        if len(modules) < 2:\n            modules.extend(self._parse_context_modules(text))\n        \n        # Strategy 5: NLP-based module extraction\n        if len(modules) < 1:\n            modules.extend(self._parse_nlp_modules(text))\n        \n        # Remove duplicates and validate\n        modules = self._deduplicate_modules(modules)\n        \n        # Enhance with LLM analysis\n        if self.llm_processor and modules:\n            modules = self._enhance_modules_with_llm_v2(modules, text)\n        \n        return modules if modules else self._create_default_modules()\n    \n    def _parse_structured_modules_v2(self, text: str) -> List[ModuleMapping]:\n        \"\"\"Advanced structured module parsing with multiple patterns\"\"\"\n        modules = []\n        \n        # Enhanced patterns for different document formats\n        patterns = [\n            # Pattern 1: Full module specification\n            r'(?:Module|Component|System)\\s*(?:#|:)?\\s*([^:\\n]+?)(?:\\s*[-–—]\\s*)?(?:Description|Overview|Details?):\\s*(.*?)(?:[-–—]\\s*(?:Components?|Features?|Capabilities?):\\s*(.*?))?(?:[-–—]\\s*(?:Status|Alignment|Coverage?):\\s*(.*?))?(?=(?:Module|Component|System)|$)',\n            \n            # Pattern 2: Bullet-style modules with details\n            r'[•\\-\\*]\\s*([^:\\n]+?)\\s*(?:Module|System|Component)[:\\s]*(.*?)(?=\\n[•\\-\\*]|\\n\\n|$)',\n            \n            # Pattern 3: Numbered modules\n            r'(\\d+\\.?\\s+)([^:\\n]+?)(?:\\s*[-–—]\\s*)?(.*?)(?=\\d+\\.|\\n\\n|$)',\n            \n            # Pattern 4: Header-style modules\n            r'^([A-Z][A-Za-z\\s]+(?:Module|System|Component|Service))\\s*\\n(.*?)(?=^[A-Z][A-Za-z\\s]+(?:Module|System|Component|Service)|\\Z)',\n            \n            # Pattern 5: Table-row style\n            r'([A-Za-z\\s]+(?:Module|System|Component))\\s*\\|\\s*([^|]+)\\s*\\|\\s*([^|]+)\\s*\\|\\s*([^|\\n]+)'\n        ]\n        \n        for pattern in patterns:\n            matches = re.findall(pattern, text, re.MULTILINE | re.DOTALL | re.IGNORECASE)\n            \n            for match in matches:\n                if isinstance(match, tuple) and len(match) >= 2:\n                    module_name = self._clean_module_name(match[0] if not match[0].isdigit() else match[1])\n                    description = self._clean_description(match[1] if not match[0].isdigit() else match[2] if len(match) > 2 else \"\")\n                    \n                    if len(module_name) > 3 and len(description) > 20:\n                        # Enhanced status determination\n                        status, coverage = self._advanced_status_analysis(description, text)\n                        priority = self._advanced_priority_analysis(module_name, description)\n                        \n                        modules.append(ModuleMapping(\n                            module_name=module_name,\n                            module_code=self._generate_module_code(module_name),\n                            status=status,\n                            coverage_percentage=coverage,\n                            client_priority=priority,\n                            description=description[:500],  # Limit description length\n                            components=self._extract_components(description),\n                            strengths=self._extract_strengths(description),\n                            alignment=self._extract_alignment(description),\n                            notes=f\"Advanced structured parsing - Pattern matched\",\n                            required=True,\n                            available=status in [\"Available\", \"Partial\"]\n                        ))\n        \n        return modules\n    \n    def _parse_table_modules(self, text: str) -> List[ModuleMapping]:\n        \"\"\"Parse modules from table-like structures\"\"\"\n        modules = []\n        \n        # Look for table headers and data\n        table_patterns = [\n            r'Module\\s*\\|\\s*Status\\s*\\|\\s*Description.*?\\n((?:.*?\\|.*?\\|.*?\\n?)+)',\n            r'Component\\s*\\|\\s*Coverage\\s*\\|\\s*Notes.*?\\n((?:.*?\\|.*?\\|.*?\\n?)+)',\n            r'System\\s*Status\\s*Description.*?\\n((?:.*?\\s+.*?\\s+.*?\\n?)+)'\n        ]\n        \n        for pattern in table_patterns:\n            match = re.search(pattern, text, re.MULTILINE | re.IGNORECASE)\n            if match:\n                table_data = match.group(1)\n                rows = [row.strip() for row in table_data.split('\\n') if row.strip()]\n                \n                for row in rows:\n                    if '|' in row:\n                        parts = [part.strip() for part in row.split('|')]\n                        if len(parts) >= 3:\n                            module_name = self._clean_module_name(parts[0])\n                            status_text = parts[1] if len(parts) > 1 else \"\"\n                            description = parts[2] if len(parts) > 2 else \"\"\n                            \n                            if len(module_name) > 3:\n                                status, coverage = self._parse_status_from_text(status_text)\n                                \n                                modules.append(ModuleMapping(\n                                    module_name=module_name,\n                                    module_code=self._generate_module_code(module_name),\n                                    status=status,\n                                    coverage_percentage=coverage,\n                                    description=description,\n                                    notes=\"Extracted from table structure\",\n                                    required=True,\n                                    available=status in [\"Available\", \"Partial\"]\n                                ))\n        \n        return modules\n    \n    def _parse_section_modules(self, text: str) -> List[ModuleMapping]:\n        \"\"\"Parse modules from document sections\"\"\"\n        modules = []\n        \n        # Split text into sections based on common delimiters\n        sections = re.split(r'\\n(?=\\d+\\.|\\n[A-Z][A-Za-z\\s]+:|\\n#{1,3}\\s)', text)\n        \n        for section in sections:\n            if len(section) > 100:  # Substantial section\n                # Look for module indicators\n                if any(indicator in section.lower() for indicator in ['module', 'component', 'system', 'service']):\n                    # Extract module information from section\n                    lines = section.split('\\n')\n                    potential_name = \"\"\n                    description_lines = []\n                    \n                    for line in lines:\n                        line = line.strip()\n                        if not line:\n                            continue\n                            \n                        # Check if line contains module name\n                        if any(indicator in line.lower() for indicator in ['module', 'component', 'system']):\n                            if not potential_name or len(line) < len(potential_name):\n                                potential_name = self._clean_module_name(line)\n                        else:\n                            description_lines.append(line)\n                    \n                    if potential_name and description_lines:\n                        description = ' '.join(description_lines[:5])  # First 5 lines\n                        if len(description) > 30:\n                            status, coverage = self._advanced_status_analysis(description, section)\n                            \n                            modules.append(ModuleMapping(\n                                module_name=potential_name,\n                                module_code=self._generate_module_code(potential_name),\n                                status=status,\n                                coverage_percentage=coverage,\n                                description=description[:400],\n                                notes=\"Extracted from section analysis\",\n                                required=True,\n                                available=status in [\"Available\", \"Partial\"]\n                            ))\n        \n        return modules\n    \n    def _parse_context_modules(self, text: str) -> List[ModuleMapping]:\n        \"\"\"Context-aware module parsing using surrounding text analysis\"\"\"\n        modules = []\n        \n        # Common module categories with related keywords\n        module_categories = {\n            \"Data Management\": [\"database\", \"storage\", \"data\", \"repository\", \"warehouse\"],\n            \"User Interface\": [\"ui\", \"interface\", \"frontend\", \"dashboard\", \"portal\"],\n            \"Integration\": [\"api\", \"integration\", \"connector\", \"interface\", \"bridge\"],\n            \"Security\": [\"security\", \"authentication\", \"authorization\", \"encryption\", \"access\"],\n            \"Analytics\": [\"analytics\", \"reporting\", \"intelligence\", \"metrics\", \"dashboard\"],\n            \"Workflow\": [\"workflow\", \"process\", \"automation\", \"orchestration\", \"pipeline\"],\n            \"Communication\": [\"notification\", \"messaging\", \"alert\", \"communication\", \"email\"],\n            \"Mobile\": [\"mobile\", \"app\", \"responsive\", \"tablet\", \"smartphone\"]\n        }\n        \n        for category, keywords in module_categories.items():\n            # Check if this category is relevant to the document\n            keyword_matches = sum(1 for keyword in keywords if keyword.lower() in text.lower())\n            \n            if keyword_matches >= 2:  # At least 2 keywords found\n                # Extract relevant context\n                context_sections = []\n                sentences = sent_tokenize(text)\n                \n                for sentence in sentences:\n                    if any(keyword in sentence.lower() for keyword in keywords):\n                        context_sections.append(sentence)\n                \n                if context_sections:\n                    description = ' '.join(context_sections[:3])  # Combine first 3 relevant sentences\n                    status, coverage = self._advanced_status_analysis(description, text)\n                    \n                    modules.append(ModuleMapping(\n                        module_name=f\"{category} Module\",\n                        module_code=self._generate_module_code(category),\n                        status=status,\n                        coverage_percentage=coverage,\n                        description=description[:400],\n                        components=', '.join(keywords[:3]),\n                        notes=\"Context-aware extraction\",\n                        required=True,\n                        available=status in [\"Available\", \"Partial\"]\n                    ))\n        \n        return modules\n    \n    def _parse_nlp_modules(self, text: str) -> List[ModuleMapping]:\n        \"\"\"NLP-based module extraction using advanced text analysis\"\"\"\n        modules = []\n        \n        try:\n            # Use TF-IDF to find important terms\n            from sklearn.feature_extraction.text import TfidfVectorizer\n            \n            sentences = sent_tokenize(text)\n            if len(sentences) < 5:\n                return modules\n            \n            # Create TF-IDF vectors\n            vectorizer = TfidfVectorizer(\n                max_features=50,\n                stop_words='english',\n                ngram_range=(1, 3),\n                min_df=2\n            )\n            \n            tfidf_matrix = vectorizer.fit_transform(sentences)\n            feature_names = vectorizer.get_feature_names_out()\n            \n            # Get top terms\n            mean_scores = tfidf_matrix.mean(axis=0).A1\n            top_indices = mean_scores.argsort()[-10:][::-1]\n            top_terms = [feature_names[i] for i in top_indices]\n            \n            # Filter terms that could be modules\n            module_terms = []\n            for term in top_terms:\n                if any(indicator in term.lower() for indicator in ['system', 'module', 'service', 'platform', 'engine']):\n                    module_terms.append(term)\n                elif len(term.split()) > 1 and term.lower() not in ['user interface', 'data management']:\n                    # Multi-word technical terms\n                    module_terms.append(term)\n            \n            # Create modules from identified terms\n            for term in module_terms[:5]:  # Limit to top 5\n                # Find sentences containing this term\n                relevant_sentences = [s for s in sentences if term.lower() in s.lower()]\n                if relevant_sentences:\n                    description = ' '.join(relevant_sentences[:2])\n                    status, coverage = self._advanced_status_analysis(description, text)\n                    \n                    modules.append(ModuleMapping(\n                        module_name=term.title(),\n                        module_code=self._generate_module_code(term),\n                        status=status,\n                        coverage_percentage=coverage,\n                        description=description[:400],\n                        notes=\"NLP-based extraction using TF-IDF\",\n                        required=True,\n                        available=status in [\"Available\", \"Partial\"]\n                    ))\n        \n        except Exception as e:\n            print(f\"NLP module extraction failed: {e}\")\n        \n        return modules\n    \n    def _clean_module_name(self, name: str) -> str:\n        \"\"\"Clean and standardize module names\"\"\"\n        if not name:\n            return \"\"\n        \n        # Remove common prefixes/suffixes\n        name = re.sub(r'^(\\d+\\.?\\s*|[•\\-\\*]\\s*)', '', name.strip())\n        name = re.sub(r'\\s*(module|component|system|service)\\s*$', '', name, flags=re.IGNORECASE)\n        \n        # Clean special characters but keep meaningful ones\n        name = re.sub(r'[^\\w\\s\\-&/()]', '', name)\n        \n        # Normalize whitespace\n        name = ' '.join(name.split())\n        \n        # Capitalize properly\n        if name:\n            name = ' '.join(word.capitalize() for word in name.split())\n        \n        return name.strip()\n    \n    def _clean_description(self, description: str) -> str:\n        \"\"\"Clean and standardize descriptions\"\"\"\n        if not description:\n            return \"\"\n        \n        # Remove excessive whitespace and clean up\n        description = ' '.join(description.split())\n        \n        # Remove common artifacts\n        description = re.sub(r'^[-–—:\\s]+', '', description)\n        description = re.sub(r'[-–—:\\s]+$', '', description)\n        \n        return description.strip()\n    \n    def _generate_module_code(self, module_name: str) -> str:\n        \"\"\"Generate standardized module codes\"\"\"\n        if not module_name:\n            return \"UNKNOWN\"\n        \n        # Take first letter of each significant word\n        words = [word for word in module_name.split() if len(word) > 2]\n        if len(words) >= 2:\n            code = ''.join(word[0].upper() for word in words[:3])\n        else:\n            code = module_name[:6].upper()\n        \n        # Ensure minimum length\n        if len(code) < 3:\n            code += \"MOD\"\n        \n        return code[:8]  # Maximum 8 characters\n    \n    def _advanced_status_analysis(self, description: str, context: str = \"\") -> Tuple[str, float]:\n        \"\"\"Advanced status analysis using multiple indicators\"\"\"\n        desc_lower = description.lower()\n        context_lower = context.lower()\n        combined_text = f\"{desc_lower} {context_lower}\"\n        \n        # Strong positive indicators\n        strong_positive = [\n            \"fully implemented\", \"complete\", \"production ready\", \"deployed\", \n            \"operational\", \"live\", \"active\", \"functional\", \"working\",\n            \"100%\", \"fully meets\", \"exceeds requirements\", \"proven\"\n        ]\n        \n        # Positive indicators\n        positive = [\n            \"implemented\", \"available\", \"supports\", \"provides\", \"includes\", \n            \"features\", \"capable\", \"ready\", \"existing\", \"current\"\n        ]\n        \n        # Partial indicators\n        partial = [\n            \"partially\", \"limited\", \"basic\", \"some\", \"minimal\", \"developing\",\n            \"in progress\", \"under development\", \"customization needed\",\n            \"requires modification\", \"adaptation required\"\n        ]\n        \n        # Negative indicators\n        negative = [\n            \"missing\", \"lacking\", \"not available\", \"unavailable\", \"planned\",\n            \"future\", \"to be developed\", \"not implemented\", \"gap\",\n            \"requires development\", \"needs creation\"\n        ]\n        \n        # Calculate scores\n        strong_pos_score = sum(2 for indicator in strong_positive if indicator in combined_text)\n        pos_score = sum(1 for indicator in positive if indicator in combined_text)\n        partial_score = sum(1 for indicator in partial if indicator in combined_text)\n        neg_score = sum(1 for indicator in negative if indicator in combined_text)\n        \n        total_positive = strong_pos_score + pos_score\n        \n        # Determine status and coverage\n        if strong_pos_score > 0 or (total_positive > neg_score and total_positive > partial_score):\n            if strong_pos_score > 0:\n                return \"Available\", 95.0\n            else:\n                return \"Available\", 85.0\n        elif partial_score > 0 or (total_positive > 0 and neg_score <= total_positive):\n            coverage = max(40.0, min(75.0, 60.0 + (total_positive - neg_score) * 10))\n            return \"Partial\", coverage\n        elif neg_score > total_positive:\n            return \"Missing\", 10.0\n        else:\n            # Default case - assume partial availability\n            return \"Partial\", 65.0\n    \n    def _advanced_priority_analysis(self, module_name: str, description: str) -> str:\n        \"\"\"Advanced priority analysis\"\"\"\n        combined_text = f\"{module_name} {description}\".lower()\n        \n        # High priority indicators\n        high_priority = [\n            \"critical\", \"essential\", \"core\", \"primary\", \"key\", \"vital\", \n            \"mandatory\", \"required\", \"must have\", \"fundamental\", \"basic\",\n            \"security\", \"authentication\", \"database\", \"integration\"\n        ]\n        \n        # Medium priority indicators\n        medium_priority = [\n            \"important\", \"significant\", \"recommended\", \"should have\",\n            \"useful\", \"beneficial\", \"standard\", \"common\"\n        ]\n        \n        high_score = sum(1 for indicator in high_priority if indicator in combined_text)\n        medium_score = sum(1 for indicator in medium_priority if indicator in combined_text)\n        \n        if high_score > medium_score and high_score > 0:\n            return \"High\"\n        elif medium_score > 0:\n            return \"Medium\"\n        else:\n            return \"Medium\"  # Default\n    \n    def _extract_components(self, description: str) -> str:\n        \"\"\"Extract component information from description\"\"\"\n        # Look for component-related keywords\n        component_patterns = [\n            r\"components?[:\\s]+([^.]+)\",\n            r\"includes?[:\\s]+([^.]+)\",\n            r\"features?[:\\s]+([^.]+)\",\n            r\"consists? of[:\\s]+([^.]+)\"\n        ]\n        \n        for pattern in component_patterns:\n            match = re.search(pattern, description, re.IGNORECASE)\n            if match:\n                return match.group(1).strip()[:200]\n        \n        return \"Components to be defined during detailed analysis\"\n    \n    def _extract_strengths(self, description: str) -> str:\n        \"\"\"Extract strength information from description\"\"\"\n        strength_keywords = [\n            \"strength\", \"advantage\", \"benefit\", \"proven\", \"reliable\",\n            \"robust\", \"scalable\", \"efficient\", \"secure\", \"flexible\"\n        ]\n        \n        sentences = sent_tokenize(description)\n        strength_sentences = []\n        \n        for sentence in sentences:\n            if any(keyword in sentence.lower() for keyword in strength_keywords):\n                strength_sentences.append(sentence.strip())\n        \n        if strength_sentences:\n            return ' '.join(strength_sentences[:2])[:200]\n        \n        return \"Strengths to be evaluated during detailed assessment\"\n    \n    def _extract_alignment(self, description: str) -> str:\n        \"\"\"Extract alignment information from description\"\"\"\n        alignment_patterns = [\n            r\"aligns? with[:\\s]+([^.]+)\",\n            r\"meets?[:\\s]+([^.]+)\",\n            r\"supports?[:\\s]+([^.]+)\",\n            r\"compatible with[:\\s]+([^.]+)\"\n        ]\n        \n        for pattern in alignment_patterns:\n            match = re.search(pattern, description, re.IGNORECASE)\n            if match:\n                return match.group(1).strip()[:200]\n        \n        return \"Alignment assessment pending detailed requirements review\"\n    \n    def _deduplicate_modules(self, modules: List[ModuleMapping]) -> List[ModuleMapping]:\n        \"\"\"Remove duplicate modules based on similarity\"\"\"\n        if not modules:\n            return modules\n        \n        unique_modules = []\n        seen_names = set()\n        \n        for module in modules:\n            # Create a normalized name for comparison\n            normalized_name = re.sub(r'[^\\w]', '', module.module_name.lower())\n            \n            # Check for exact or very similar matches\n            is_duplicate = False\n            for seen_name in seen_names:\n                similarity = self._calculate_string_similarity(normalized_name, seen_name)\n                if similarity > 0.8:  # 80% similarity threshold\n                    is_duplicate = True\n                    break\n            \n            if not is_duplicate:\n                unique_modules.append(module)\n                seen_names.add(normalized_name)\n        \n        return unique_modules\n    \n    def _calculate_string_similarity(self, str1: str, str2: str) -> float:\n        \"\"\"Calculate similarity between two strings\"\"\"\n        if not str1 or not str2:\n            return 0.0\n        \n        # Simple Jaccard similarity\n        set1 = set(str1.split())\n        set2 = set(str2.split())\n        \n        if not set1 and not set2:\n            return 1.0\n        \n        intersection = len(set1.intersection(set2))\n        union = len(set1.union(set2))\n        \n        return intersection / union if union > 0 else 0.0\n    \n    def _enhance_modules_with_llm_v2(self, modules: List[ModuleMapping], text: str) -> List[ModuleMapping]:\n        \"\"\"Enhanced LLM-based module analysis\"\"\"\n        if not self.llm_processor or len(modules) == 0:\n            return modules\n        \n        try:\n            # Prepare enhanced context for LLM\n            module_context = []\n            for i, module in enumerate(modules, 1):\n                context = f\"{i}. {module.module_name}\\n   Description: {module.description[:150]}\\n   Current Status: {module.status}\"\n                module_context.append(context)\n            \n            context_text = '\\n'.join(module_context)\n            \n            prompt = f\"\"\"\n            As an expert RFP analyst, review these extracted modules and provide enhanced analysis:\n            \n            {context_text}\n            \n            For each module, provide:\n            1. Refined status (Available/Partial/Missing)\n            2. Realistic coverage percentage (0-100%)\n            3. Business priority (High/Medium/Low)\n            4. Brief improvement suggestion\n            \n            Format: \"Module X: Status=Available|Coverage=85%|Priority=High|Suggestion=Ready for deployment\"\n            \"\"\"\n            \n            llm_response = self.llm_processor._generate_text(prompt, 800)\n            \n            # Parse LLM response and update modules\n            response_lines = [line.strip() for line in llm_response.split('\\n') if line.strip()]\n            \n            for line in response_lines:\n                if 'Module' in line and '=' in line:\n                    try:\n                        # Extract module reference\n                        module_ref_match = re.search(r'Module (\\d+)', line)\n                        if module_ref_match:\n                            module_idx = int(module_ref_match.group(1)) - 1\n                            \n                            if 0 <= module_idx < len(modules):\n                                # Parse enhancements\n                                if 'Status=' in line:\n                                    status_match = re.search(r'Status=([^|]+)', line)\n                                    if status_match:\n                                        new_status = status_match.group(1).strip()\n                                        if new_status in ['Available', 'Partial', 'Missing']:\n                                            modules[module_idx].status = new_status\n                                \n                                if 'Coverage=' in line:\n                                    coverage_match = re.search(r'Coverage=(\\d+)%', line)\n                                    if coverage_match:\n                                        coverage = float(coverage_match.group(1))\n                                        if 0 <= coverage <= 100:\n                                            modules[module_idx].coverage_percentage = coverage\n                                \n                                if 'Priority=' in line:\n                                    priority_match = re.search(r'Priority=([^|]+)', line)\n                                    if priority_match:\n                                        priority = priority_match.group(1).strip()\n                                        if priority in ['High', 'Medium', 'Low']:\n                                            modules[module_idx].client_priority = priority\n                                \n                                if 'Suggestion=' in line:\n                                    suggestion_match = re.search(r'Suggestion=(.+)', line)\n                                    if suggestion_match:\n                                        suggestion = suggestion_match.group(1).strip()\n                                        modules[module_idx].notes += f\" | LLM Insight: {suggestion}\"\n                    \n                    except (ValueError, IndexError) as e:\n                        continue  # Skip invalid lines\n        \n        except Exception as e:\n            print(f\"Enhanced LLM module analysis failed: {e}\")\n        \n        return modules\n    \n    def _create_default_modules(self) -> List[ModuleMapping]:\n        \"\"\"Create comprehensive default modules when parsing fails\"\"\"\n        return [\n            ModuleMapping(\n                module_name=\"Core System Architecture\",\n                module_code=\"COREARCH\",\n                status=\"Partial\",\n                coverage_percentage=70.0,\n                client_priority=\"High\",\n                description=\"Foundational system architecture and framework components requiring analysis and customization for client-specific requirements.\",\n                components=\"Database layer, API framework, security foundation, user management\",\n                strengths=\"Proven architecture, scalable design, industry standards compliance\",\n                alignment=\"Aligns with enterprise architecture patterns and best practices\",\n                notes=\"Default module - requires detailed requirements analysis\",\n                required=True,\n                available=True\n            ),\n            ModuleMapping(\n                module_name=\"Data Management System\",\n                module_code=\"DATAMGMT\",\n                status=\"Available\",\n                coverage_percentage=85.0,\n                client_priority=\"High\",\n                description=\"Comprehensive data management capabilities including storage, processing, and governance features.\",\n                components=\"Data storage, ETL processes, data quality, backup and recovery\",\n                strengths=\"Robust data handling, high performance, compliance ready\",\n                alignment=\"Meets standard data management requirements\",\n                notes=\"Default module - well-established capabilities\",\n                required=True,\n                available=True\n            ),\n            ModuleMapping(\n                module_name=\"User Interface Platform\",\n                module_code=\"UIPLATF\",\n                status=\"Partial\",\n                coverage_percentage=60.0,\n                client_priority=\"Medium\",\n                description=\"User interface and experience platform requiring customization for specific client workflows and branding.\",\n                components=\"Web interface, responsive design, accessibility features, theming\",\n                strengths=\"Modern UI frameworks, responsive design, accessibility compliance\",\n                alignment=\"Requires customization for client-specific user experience\",\n                notes=\"Default module - needs UI/UX customization\",\n                required=True,\n                available=True\n            )\n        ]\n\n    # ========== GAP ANALYSIS METHODS ==========\n    \n    def parse_gaps_enhanced(self, text: str) -> List[GapItem]:\n        \"\"\"Enhanced gap parsing with advanced pattern recognition\"\"\"\n        gaps = []\n        \n        # Strategy 1: Advanced structured gap patterns\n        gaps.extend(self._parse_structured_gaps_v2(text))\n        \n        # Strategy 2: Problem-solution gap analysis\n        if len(gaps) < 3:\n            gaps.extend(self._parse_problem_solution_gaps(text))\n        \n        # Strategy 3: Requirement vs capability gaps\n        if len(gaps) < 2:\n            gaps.extend(self._parse_requirement_capability_gaps(text))\n        \n        # Strategy 4: Risk-based gap identification\n        if len(gaps) < 1:\n            gaps.extend(self._parse_risk_based_gaps(text))\n        \n        # Remove duplicates and enhance with LLM\n        gaps = self._deduplicate_gaps(gaps)\n        \n        if self.llm_processor and gaps:\n            gaps = self._enhance_gaps_with_llm_v2(gaps, text)\n        \n        return gaps if gaps else self._create_default_gaps()\n    \n    def _parse_structured_gaps_v2(self, text: str) -> List[GapItem]:\n        \"\"\"Advanced structured gap parsing\"\"\"\n        gaps = []\n        \n        # Enhanced patterns for gap identification\n        gap_patterns = [\n            # Pattern 1: Direct gap statements\n            r'(?:Gap|Issue|Problem|Challenge|Deficiency)[:\\s]+([^.]+?)(?:\\.|$)',\n            \n            # Pattern 2: Missing/lacking statements\n            r'(?:Missing|Lacking|Absent|Not available|Unavailable)[:\\s]+([^.]+?)(?:\\.|$)',\n            \n            # Pattern 3: Requirements not met\n            r'(?:Does not meet|Cannot support|Unable to|Fails to)[:\\s]+([^.]+?)(?:\\.|$)',\n            \n            # Pattern 4: Needs/requires statements\n            r'(?:Needs|Requires|Must develop|Must implement|Must create)[:\\s]+([^.]+?)(?:\\.|$)',\n            \n            # Pattern 5: Limitation statements\n            r'(?:Limited|Restricted|Constrained|Insufficient)[:\\s]+([^.]+?)(?:\\.|$)'\n        ]\n        \n        for pattern in gap_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n            \n            for match in matches:\n                if isinstance(match, str) and len(match.strip()) > 20:\n                    gap_description = match.strip()\n                    \n                    # Classify gap type and severity\n                    gap_type = self._classify_gap_type_advanced(gap_description)\n                    severity = self._determine_gap_severity_advanced(gap_description, text)\n                    \n                    gaps.append(GapItem(\n                        gap_type=gap_type,\n                        description=gap_description[:300],\n                        severity=severity,\n                        business_impact=self._calculate_business_impact(gap_description, severity),\n                        mitigation_strategy=self._generate_mitigation_strategy_advanced(gap_type, gap_description),\n                        effort_required=self._estimate_effort_advanced(severity, gap_description),\n                        cost_estimate=self._estimate_cost_advanced(severity, gap_description),\n                        dependencies=self._identify_dependencies(gap_description),\n                        risk_if_unaddressed=self._assess_risk_if_unaddressed(gap_description, severity)\n                    ))\n        \n        return gaps\n    \n    def _parse_problem_solution_gaps(self, text: str) -> List[GapItem]:\n        \"\"\"Parse gaps from problem-solution analysis\"\"\"\n        gaps = []\n        \n        # Look for problem indicators\n        problem_keywords = [\n            \"problem\", \"issue\", \"challenge\", \"concern\", \"difficulty\",\n            \"obstacle\", \"barrier\", \"bottleneck\", \"weakness\", \"shortcoming\"\n        ]\n        \n        sentences = sent_tokenize(text)\n        \n        for sentence in sentences:\n            sentence_lower = sentence.lower()\n            \n            # Check if sentence describes a problem\n            if any(keyword in sentence_lower for keyword in problem_keywords):\n                if len(sentence) > 30:  # Substantial description\n                    \n                    # Determine if this is a capability gap\n                    if any(indicator in sentence_lower for indicator in \n                           [\"capability\", \"feature\", \"functionality\", \"ability\", \"support\"]):\n                        \n                        gap_type = self._classify_gap_type_advanced(sentence)\n                        severity = self._determine_gap_severity_advanced(sentence, text)\n                        \n                        gaps.append(GapItem(\n                            gap_type=gap_type,\n                            description=f\"Problem identified: {sentence[:250]}\",\n                            severity=severity,\n                            business_impact=self._calculate_business_impact(sentence, severity),\n                            mitigation_strategy=self._generate_mitigation_strategy_advanced(gap_type, sentence),\n                            effort_required=self._estimate_effort_advanced(severity, sentence),\n                            cost_estimate=self._estimate_cost_advanced(severity, sentence),\n                            risk_if_unaddressed=f\"Problem may escalate if not addressed: {severity} impact expected\"\n                        ))\n        \n        return gaps[:5]  # Limit to top 5\n    \n    def _parse_requirement_capability_gaps(self, text: str) -> List[GapItem]:\n        \"\"\"Parse gaps by comparing requirements against capabilities\"\"\"\n        gaps = []\n        \n        # Find requirement statements\n        requirement_patterns = [\n            r'(?:Required|Must have|Mandatory|Essential)[:\\s]+([^.]+)',\n            r'(?:Client needs|Customer requires|Specification calls for)[:\\s]+([^.]+)',\n            r'(?:System must|Solution should|Platform needs to)[:\\s]+([^.]+)'\n        ]\n        \n        # Find capability statements\n        capability_patterns = [\n            r'(?:Currently supports|Available|Can provide|Existing)[:\\s]+([^.]+)',\n            r'(?:Our system|Platform|Solution)[:\\s]+([^.]+)',\n            r'(?:Implemented|In place|Operational)[:\\s]+([^.]+)'\n        ]\n        \n        requirements = []\n        capabilities = []\n        \n        # Extract requirements\n        for pattern in requirement_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE)\n            requirements.extend([match.strip() for match in matches if len(match.strip()) > 15])\n        \n        # Extract capabilities\n        for pattern in capability_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE)\n            capabilities.extend([match.strip() for match in matches if len(match.strip()) > 15])\n        \n        # Identify gaps by comparing requirements to capabilities\n        for requirement in requirements[:5]:  # Limit processing\n            # Check if requirement is addressed by any capability\n            is_covered = False\n            coverage_score = 0\n            \n            for capability in capabilities:\n                similarity = self._calculate_text_similarity(requirement, capability)\n                if similarity > 0.3:  # 30% similarity threshold\n                    is_covered = True\n                    coverage_score = max(coverage_score, similarity)\n            \n            # If requirement is not well covered, it's a gap\n            if not is_covered or coverage_score < 0.6:\n                gap_type = self._classify_gap_type_advanced(requirement)\n                severity = \"High\" if not is_covered else \"Medium\"\n                \n                gaps.append(GapItem(\n                    gap_type=gap_type,\n                    description=f\"Requirement gap: {requirement[:200]}\",\n                    severity=severity,\n                    business_impact=f\"Client requirement may not be fully met (Coverage: {coverage_score*100:.0f}%)\",\n                    mitigation_strategy=f\"Develop capability to address: {requirement[:100]}\",\n                    effort_required=\"2-4 weeks\" if severity == \"Medium\" else \"4-6 weeks\",\n                    cost_estimate=\"$15K-$35K\" if severity == \"Medium\" else \"$25K-$50K\",\n                    risk_if_unaddressed=\"Client dissatisfaction and potential project failure\"\n                ))\n        \n        return gaps\n    \n    def _parse_risk_based_gaps(self, text: str) -> List[GapItem]:\n        \"\"\"Parse gaps based on risk indicators\"\"\"\n        gaps = []\n        \n        risk_indicators = [\n            \"risk\", \"concern\", \"uncertainty\", \"potential issue\", \"may impact\",\n            \"could affect\", \"might cause\", \"possibility of\", \"danger of\"\n        ]\n        \n        sentences = sent_tokenize(text)\n        \n        for sentence in sentences:\n            if any(indicator in sentence.lower() for indicator in risk_indicators):\n                if len(sentence) > 25:\n                    gap_type = self._classify_gap_type_advanced(sentence)\n                    \n                    gaps.append(GapItem(\n                        gap_type=\"Risk\",\n                        description=f\"Risk-based gap: {sentence[:200]}\",\n                        severity=\"Medium\",\n                        business_impact=\"Potential negative impact on project success\",\n                        mitigation_strategy=\"Develop risk mitigation plan and monitoring procedures\",\n                        effort_required=\"1-3 weeks\",\n                        cost_estimate=\"$10K-$25K\",\n                        risk_if_unaddressed=\"Risk may materialize causing project delays or failures\"\n                    ))\n        \n        return gaps[:3]  # Limit to top 3\n    \n    def _classify_gap_type_advanced(self, description: str) -> str:\n        \"\"\"Advanced gap type classification\"\"\"\n        desc_lower = description.lower()\n        \n        # Technical gaps\n        if any(word in desc_lower for word in \n               [\"technical\", \"technology\", \"system\", \"software\", \"hardware\", \"infrastructure\",\n                \"architecture\", \"platform\", \"framework\", \"api\", \"database\"]):\n            return \"Technical\"\n        \n        # Functional gaps\n        elif any(word in desc_lower for word in \n                 [\"function\", \"feature\", \"capability\", \"workflow\", \"process\", \"business logic\",\n                  \"user story\", \"requirement\", \"specification\"]):\n            return \"Functional\"\n        \n        # Security gaps\n        elif any(word in desc_lower for word in \n                 [\"security\", \"authentication\", \"authorization\", \"encryption\", \"access control\",\n                  \"privacy\", \"compliance\", \"audit\", \"vulnerability\"]):\n            return \"Security\"\n        \n        # Performance gaps\n        elif any(word in desc_lower for word in \n                 [\"performance\", \"speed\", \"latency\", \"throughput\", \"scalability\", \"load\",\n                  \"response time\", \"efficiency\", \"optimization\"]):\n            return \"Performance\"\n        \n        # Integration gaps\n        elif any(word in desc_lower for word in \n                 [\"integration\", \"interface\", \"connectivity\", \"interoperability\", \"compatibility\",\n                  \"data exchange\", \"communication\", \"protocol\"]):\n            return \"Integration\"\n        \n        # Compliance gaps\n        elif any(word in desc_lower for word in \n                 [\"compliance\", \"regulation\", \"standard\", \"policy\", \"governance\", \"regulatory\",\n                  \"legal\", \"certification\", \"accreditation\"]):\n            return \"Compliance\"\n        \n        # Operational gaps\n        elif any(word in desc_lower for word in \n                 [\"operational\", \"maintenance\", \"support\", \"monitoring\", \"backup\", \"recovery\",\n                  \"deployment\", \"configuration\", \"administration\"]):\n            return \"Operational\"\n        \n        else:\n            return \"General\"\n    \n    def _determine_gap_severity_advanced(self, description: str, context: str = \"\") -> str:\n        \"\"\"Advanced gap severity determination\"\"\"\n        desc_lower = description.lower()\n        context_lower = context.lower()\n        combined = f\"{desc_lower} {context_lower}\"\n        \n        # Critical severity indicators\n        critical_indicators = [\n            \"critical\", \"severe\", \"major\", \"blocking\", \"showstopper\", \"fatal\",\n            \"cannot proceed\", \"project killer\", \"must have\", \"essential\", \"vital\"\n        ]\n        \n        # High severity indicators\n        high_indicators = [\n            \"high\", \"important\", \"significant\", \"serious\", \"substantial\", \"key\",\n            \"primary\", \"core\", \"fundamental\", \"required\", \"necessary\"\n        ]\n        \n        # Medium severity indicators\n        medium_indicators = [\n            \"medium\", \"moderate\", \"intermediate\", \"standard\", \"normal\", \"typical\",\n            \"should have\", \"recommended\", \"preferred\", \"beneficial\"\n        ]\n        \n        # Low severity indicators\n        low_indicators = [\n            \"low\", \"minor\", \"small\", \"trivial\", \"cosmetic\", \"nice to have\",\n            \"optional\", \"enhancement\", \"improvement\", \"could have\"\n        ]\n        \n        # Count indicators\n        critical_count = sum(1 for indicator in critical_indicators if indicator in combined)\n        high_count = sum(1 for indicator in high_indicators if indicator in combined)\n        medium_count = sum(1 for indicator in medium_indicators if indicator in combined)\n        low_count = sum(1 for indicator in low_indicators if indicator in combined)\n        \n        # Determine severity based on counts and context\n        if critical_count > 0:\n            return \"Critical\"\n        elif high_count > medium_count and high_count > low_count:\n            return \"High\"\n        elif low_count > 0 and low_count > high_count:\n            return \"Low\"\n        else:\n            return \"Medium\"  # Default\n    \n    def _calculate_business_impact(self, description: str, severity: str) -> str:\n        \"\"\"Calculate business impact based on description and severity\"\"\"\n        impact_templates = {\n            \"Critical\": \"Severe business impact: Project delivery at risk, potential client relationship damage, significant financial implications\",\n            \"High\": \"High business impact: Major delays likely, client satisfaction at risk, substantial additional costs expected\",\n            \"Medium\": \"Moderate business impact: Some delays possible, manageable client communication needed, moderate cost implications\",\n            \"Low\": \"Low business impact: Minor inconvenience, minimal client communication needed, low cost to address\"\n        }\n        \n        base_impact = impact_templates.get(severity, impact_templates[\"Medium\"])\n        \n        # Add specific context based on description\n        desc_lower = description.lower()\n        if \"security\" in desc_lower:\n            base_impact += \" | Security implications may affect compliance and trust\"\n        elif \"performance\" in desc_lower:\n            base_impact += \" | Performance issues may affect user adoption and satisfaction\"\n        elif \"integration\" in desc_lower:\n            base_impact += \" | Integration challenges may delay go-live and affect functionality\"\n        \n        return base_impact\n    \n    def _generate_mitigation_strategy_advanced(self, gap_type: str, description: str) -> str:\n        \"\"\"Generate advanced mitigation strategies\"\"\"\n        base_strategies = {\n            \"Technical\": \"Develop technical solution through architecture review, technology evaluation, and implementation planning\",\n            \"Functional\": \"Design alternative workflow, enhance existing functionality, or develop new features\",\n            \"Security\": \"Implement additional security controls, conduct security assessment, and establish compliance procedures\",\n            \"Performance\": \"Optimize system performance through code review, infrastructure enhancement, and load testing\",\n            \"Integration\": \"Develop integration layer, create API connectors, and establish data synchronization processes\",\n            \"Compliance\": \"Implement compliance framework, establish audit procedures, and create documentation\",\n            \"Operational\": \"Develop operational procedures, create monitoring systems, and establish support processes\",\n            \"General\": \"Conduct detailed analysis, develop action plan, and implement solution with stakeholder approval\"\n        }\n        \n        base_strategy = base_strategies.get(gap_type, base_strategies[\"General\"])\n        \n        # Add specific recommendations based on description content\n        desc_lower = description.lower()\n        \n        if \"data\" in desc_lower:\n            base_strategy += \" | Focus on data quality, governance, and migration strategies\"\n        elif \"user\" in desc_lower:\n            base_strategy += \" | Prioritize user experience design and training programs\"\n        elif \"system\" in desc_lower:\n            base_strategy += \" | Emphasize system integration testing and deployment procedures\"\n        \n        return base_strategy\n    \n    def _estimate_effort_advanced(self, severity: str, description: str) -> str:\n        \"\"\"Advanced effort estimation\"\"\"\n        base_efforts = {\n            \"Critical\": \"6-12 weeks\",\n            \"High\": \"3-6 weeks\",\n            \"Medium\": \"2-4 weeks\", \n            \"Low\": \"1-2 weeks\"\n        }\n        \n        base_effort = base_efforts.get(severity, \"2-4 weeks\")\n        \n        # Adjust based on complexity indicators\n        desc_lower = description.lower()\n        complexity_indicators = [\"complex\", \"multiple\", \"various\", \"several\", \"many\", \"extensive\"]\n        \n        if any(indicator in desc_lower for indicator in complexity_indicators):\n            # Increase effort estimate\n            if severity == \"Critical\":\n                base_effort = \"8-16 weeks\"\n            elif severity == \"High\":\n                base_effort = \"4-8 weeks\"\n            elif severity == \"Medium\":\n                base_effort = \"3-5 weeks\"\n        \n        return base_effort\n    \n    def _estimate_cost_advanced(self, severity: str, description: str) -> str:\n        \"\"\"Advanced cost estimation\"\"\"\n        base_costs = {\n            \"Critical\": \"$75K-$150K\",\n            \"High\": \"$35K-$75K\",\n            \"Medium\": \"$15K-$35K\",\n            \"Low\": \"$5K-$15K\"\n        }\n        \n        base_cost = base_costs.get(severity, \"$15K-$35K\")\n        \n        # Adjust based on resource requirements\n        desc_lower = description.lower()\n        \n        if any(word in desc_lower for word in [\"infrastructure\", \"hardware\", \"license\", \"third-party\"]):\n            # Add infrastructure costs\n            if severity in [\"Critical\", \"High\"]:\n                base_cost += \" + Infrastructure costs\"\n        \n        return base_cost\n    \n    def _identify_dependencies(self, description: str) -> List[str]:\n        \"\"\"Identify dependencies from gap description\"\"\"\n        dependencies = []\n        desc_lower = description.lower()\n        \n        # Common dependency indicators\n        if \"integration\" in desc_lower:\n            dependencies.append(\"Third-party system availability\")\n        if \"data\" in desc_lower:\n            dependencies.append(\"Data source access and quality\")\n        if \"security\" in desc_lower:\n            dependencies.append(\"Security team approval and testing\")\n        if \"compliance\" in desc_lower:\n            dependencies.append(\"Legal and compliance review\")\n        if \"performance\" in desc_lower:\n            dependencies.append(\"Infrastructure capacity and testing environment\")\n        \n        # Default dependencies\n        if not dependencies:\n            dependencies = [\"Stakeholder approval\", \"Resource allocation\", \"Timeline coordination\"]\n        \n        return dependencies\n    \n    def _assess_risk_if_unaddressed(self, description: str, severity: str) -> str:\n        \"\"\"Assess risk if gap is not addressed\"\"\"\n        risk_templates = {\n            \"Critical\": \"Project failure risk: High probability of project cancellation or major scope reduction\",\n            \"High\": \"Delivery risk: Significant delays and client dissatisfaction likely\",\n            \"Medium\": \"Quality risk: Reduced functionality and potential rework required\",\n            \"Low\": \"Minor risk: Small impact on project success and client satisfaction\"\n        }\n        \n        base_risk = risk_templates.get(severity, risk_templates[\"Medium\"])\n        \n        # Add specific risk context\n        desc_lower = description.lower()\n        if \"security\" in desc_lower:\n            base_risk += \" | Security breach potential increases\"\n        elif \"compliance\" in desc_lower:\n            base_risk += \" | Regulatory non-compliance risk\"\n        elif \"performance\" in desc_lower:\n            base_risk += \" | System performance degradation and user complaints\"\n        \n        return base_risk\n    \n    def _calculate_text_similarity(self, text1: str, text2: str) -> float:\n        \"\"\"Calculate similarity between two text strings\"\"\"\n        if not text1 or not text2:\n            return 0.0\n        \n        # Convert to lowercase and split into words\n        words1 = set(text1.lower().split())\n        words2 = set(text2.lower().split())\n        \n        if not words1 and not words2:\n            return 1.0\n        \n        # Calculate Jaccard similarity\n        intersection = len(words1.intersection(words2))\n        union = len(words1.union(words2))\n        \n        return intersection / union if union > 0 else 0.0\n    \n    def _deduplicate_gaps(self, gaps: List[GapItem]) -> List[GapItem]:\n        \"\"\"Remove duplicate gaps\"\"\"\n        if not gaps:\n            return gaps\n        \n        unique_gaps = []\n        seen_descriptions = []\n        \n        for gap in gaps:\n            # Check for similarity with existing gaps\n            is_duplicate = False\n            for seen_desc in seen_descriptions:\n                similarity = self._calculate_text_similarity(gap.description, seen_desc)\n                if similarity > 0.7:  # 70% similarity threshold\n                    is_duplicate = True\n                    break\n            \n            if not is_duplicate:\n                unique_gaps.append(gap)\n                seen_descriptions.append(gap.description)\n        \n        return unique_gaps\n    \n    def _enhance_gaps_with_llm_v2(self, gaps: List[GapItem], text: str) -> List[GapItem]:\n        \"\"\"Enhanced LLM-based gap analysis\"\"\"\n        if not self.llm_processor or not gaps:\n            return gaps\n        \n        try:\n            gap_context = []\n            for i, gap in enumerate(gaps, 1):\n                context = f\"{i}. {gap.gap_type} Gap: {gap.description[:100]}\\n   Current Severity: {gap.severity}\"\n                gap_context.append(context)\n            \n            context_text = '\\n'.join(gap_context)\n            \n            prompt = f\"\"\"\n            As an expert RFP analyst, review these identified gaps and provide enhanced analysis:\n            \n            {context_text}\n            \n            For each gap, provide:\n            1. Validated severity (Critical/High/Medium/Low)\n            2. Refined gap type if needed\n            3. Business priority (Immediate/Short-term/Long-term)\n            4. Key mitigation approach\n            \n            Format: \"Gap X: Severity=High|Type=Technical|Priority=Immediate|Approach=Develop custom solution\"\n            \"\"\"\n            \n            llm_response = self.llm_processor._generate_text(prompt, 600)\n            \n            # Parse and apply enhancements\n            response_lines = [line.strip() for line in llm_response.split('\\n') if line.strip()]\n            \n            for line in response_lines:\n                if 'Gap' in line and '=' in line:\n                    try:\n                        gap_ref_match = re.search(r'Gap (\\d+)', line)\n                        if gap_ref_match:\n                            gap_idx = int(gap_ref_match.group(1)) - 1\n                            \n                            if 0 <= gap_idx < len(gaps):\n                                # Apply enhancements\n                                if 'Severity=' in line:\n                                    severity_match = re.search(r'Severity=([^|]+)', line)\n                                    if severity_match:\n                                        new_severity = severity_match.group(1).strip()\n                                        if new_severity in ['Critical', 'High', 'Medium', 'Low']:\n                                            gaps[gap_idx].severity = new_severity\n                                \n                                if 'Type=' in line:\n                                    type_match = re.search(r'Type=([^|]+)', line)\n                                    if type_match:\n                                        new_type = type_match.group(1).strip()\n                                        gaps[gap_idx].gap_type = new_type\n                                \n                                if 'Approach=' in line:\n                                    approach_match = re.search(r'Approach=(.+)', line)\n                                    if approach_match:\n                                        approach = approach_match.group(1).strip()\n                                        gaps[gap_idx].mitigation_strategy = f\"LLM Enhanced: {approach}\"\n                    \n                    except (ValueError, IndexError):\n                        continue\n        \n        except Exception as e:\n            print(f\"Enhanced LLM gap analysis failed: {e}\")\n        \n        return gaps\n    \n    def _create_default_gaps(self) -> List[GapItem]:\n        \"\"\"Create default gaps when parsing fails\"\"\"\n        return [\n            GapItem(\n                gap_type=\"Analysis\",\n                description=\"Comprehensive gap analysis required - detailed review needed to identify specific capability gaps against client requirements\",\n                severity=\"Medium\",\n                business_impact=\"Analysis phase needed to determine actual gaps and their business impact\",\n                mitigation_strategy=\"Conduct detailed requirements workshop with client stakeholders and technical team\",\n                effort_required=\"2-3 weeks\",\n                cost_estimate=\"$15K-$25K\",\n                dependencies=[\"Client availability\", \"Requirements documentation\", \"Technical team allocation\"],\n                risk_if_unaddressed=\"May miss critical gaps leading to project scope creep and client dissatisfaction\"\n            ),\n            GapItem(\n                gap_type=\"Documentation\",\n                description=\"Complete technical documentation and specification gaps need to be addressed for comprehensive understanding\",\n                severity=\"Low\",\n                business_impact=\"Documentation gaps may slow development and increase communication overhead\",\n                mitigation_strategy=\"Create comprehensive technical documentation and specification review process\",\n                effort_required=\"1-2 weeks\",\n                cost_estimate=\"$8K-$15K\",\n                dependencies=[\"Technical team input\", \"Client specification review\"],\n                risk_if_unaddressed=\"Development delays and increased rework due to unclear requirements\"\n            )\n        ]\n\n    # ========== WIN/LOSS ANALYSIS METHODS ==========\n    \n    def parse_win_loss_enhanced(self, text: str) -> List[WinLossFactor]:\n        \"\"\"Enhanced win/loss factor parsing with comprehensive analysis\"\"\"\n        factors = []\n        \n        # Strategy 1: Advanced structured win/loss patterns\n        factors.extend(self._parse_structured_win_loss_v2(text))\n        \n        # Strategy 2: Historical performance analysis\n        if len(factors) < 3:\n            factors.extend(self._parse_historical_performance(text))\n        \n        # Strategy 3: Competitive advantage/disadvantage analysis\n        if len(factors) < 2:\n            factors.extend(self._parse_competitive_analysis(text))\n        \n        # Strategy 4: Client feedback and testimonial analysis\n        if len(factors) < 1:\n            factors.extend(self._parse_client_feedback_analysis(text))\n        \n        # Enhance with LLM and remove duplicates\n        factors = self._deduplicate_win_loss_factors(factors)\n        \n        if self.llm_processor and factors:\n            factors = self._enhance_win_loss_with_llm_v2(factors, text)\n        \n        return factors if factors else self._create_default_win_loss_factors()\n    \n    def _parse_structured_win_loss_v2(self, text: str) -> List[WinLossFactor]:\n        \"\"\"Advanced structured win/loss factor parsing\"\"\"\n        factors = []\n        \n        # Enhanced win patterns\n        win_patterns = [\n            r'(?:Win|Success|Victory|Achievement|Strength|Advantage)[:\\s]+(.*?)(?=(?:Loss|Win|Success|$))',\n            r'(?:Successful|Won|Achieved|Delivered|Exceeded)[:\\s]+(.*?)(?=(?:Failed|Lost|$))',\n            r'(?:Key strength|Competitive advantage|Success factor)[:\\s]+(.*?)(?=(?:Weakness|Challenge|$))',\n            r'(?:Why we won|Success story|Positive outcome)[:\\s]+(.*?)(?:\\n\\n|$)',\n            r'(?:Client praised|Recognized for|Commended)[:\\s]+(.*?)(?:\\n|$)'\n        ]\n        \n        # Enhanced loss patterns\n        loss_patterns = [\n            r'(?:Loss|Failure|Defeat|Challenge|Weakness|Disadvantage)[:\\s]+(.*?)(?=(?:Win|Success|$))',\n            r'(?:Failed|Lost|Missed|Delayed|Cancelled)[:\\s]+(.*?)(?=(?:Won|Succeeded|$))',\n            r'(?:Key weakness|Competitive disadvantage|Failure factor)[:\\s]+(.*?)(?=(?:Strength|Success|$))',\n            r'(?:Why we lost|Failure story|Negative outcome)[:\\s]+(.*?)(?:\\n\\n|$)',\n            r'(?:Client complained|Criticized for|Issues with)[:\\s]+(.*?)(?:\\n|$)'\n        ]\n        \n        # Process win patterns\n        for pattern in win_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE | re.DOTALL)\n            for match in matches:\n                if isinstance(match, str) and len(match.strip()) > 25:\n                    description = match.strip()[:300]\n                    \n                    factors.append(WinLossFactor(\n                        factor_type=\"Win\",\n                        description=description,\n                        impact=self._determine_factor_impact_advanced(description),\n                        confidence=self._calculate_confidence_score(description, text),\n                        category=self._categorize_factor_advanced(description)\n                    ))\n        \n        # Process loss patterns\n        for pattern in loss_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE | re.DOTALL)\n            for match in matches:\n                if isinstance(match, str) and len(match.strip()) > 25:\n                    description = match.strip()[:300]\n                    \n                    factors.append(WinLossFactor(\n                        factor_type=\"Loss\",\n                        description=description,\n                        impact=self._determine_factor_impact_advanced(description),\n                        confidence=self._calculate_confidence_score(description, text),\n                        category=self._categorize_factor_advanced(description)\n                    ))\n        \n        return factors\n    \n    def _parse_historical_performance(self, text: str) -> List[WinLossFactor]:\n        \"\"\"Parse historical performance indicators\"\"\"\n        factors = []\n        \n        # Performance indicators\n        performance_keywords = {\n            \"positive\": [\"exceeded\", \"surpassed\", \"outperformed\", \"delivered ahead\", \"under budget\", \n                        \"client satisfaction\", \"repeat business\", \"referral\", \"testimonial\"],\n            \"negative\": [\"over budget\", \"delayed\", \"missed deadline\", \"client dissatisfaction\", \n                        \"scope creep\", \"quality issues\", \"performance problems\", \"cancelled\"]\n        }\n        \n        sentences = sent_tokenize(text)\n        \n        for sentence in sentences:\n            sentence_lower = sentence.lower()\n            \n            # Check for positive performance indicators\n            positive_matches = sum(1 for keyword in performance_keywords[\"positive\"] if keyword in sentence_lower)\n            negative_matches = sum(1 for keyword in performance_keywords[\"negative\"] if keyword in sentence_lower)\n            \n            if positive_matches > 0 and len(sentence) > 30:\n                factors.append(WinLossFactor(\n                    factor_type=\"Win\",\n                    description=f\"Historical success: {sentence[:250]}\",\n                    impact=self._determine_factor_impact_advanced(sentence),\n                    confidence=0.8 + (positive_matches * 0.05),  # Higher confidence with more indicators\n                    category=self._categorize_factor_advanced(sentence)\n                ))\n            \n            elif negative_matches > 0 and len(sentence) > 30:\n                factors.append(WinLossFactor(\n                    factor_type=\"Loss\",\n                    description=f\"Historical challenge: {sentence[:250]}\",\n                    impact=self._determine_factor_impact_advanced(sentence),\n                    confidence=0.8 + (negative_matches * 0.05),\n                    category=self._categorize_factor_advanced(sentence)\n                ))\n        \n        return factors[:8]  # Limit to top 8\n    \n    def _parse_competitive_analysis(self, text: str) -> List[WinLossFactor]:\n        \"\"\"Parse competitive advantages and disadvantages\"\"\"\n        factors = []\n        \n        competitive_patterns = [\n            # Advantage patterns\n            (r'(?:competitive advantage|market leader|industry leader|best in class)[:\\s]+(.*?)(?:\\n|$)', \"Win\"),\n            (r'(?:outperform|superior to|better than|ahead of)[:\\s]+(.*?)(?:\\n|$)', \"Win\"),\n            (r'(?:unique capability|proprietary|exclusive|patented)[:\\s]+(.*?)(?:\\n|$)', \"Win\"),\n            \n            # Disadvantage patterns\n            (r'(?:competitive disadvantage|behind competitors|lagging)[:\\s]+(.*?)(?:\\n|$)', \"Loss\"),\n            (r'(?:competitors offer|others provide|market expects)[:\\s]+(.*?)(?:\\n|$)', \"Loss\"),\n            (r'(?:catching up|need to match|industry standard)[:\\s]+(.*?)(?:\\n|$)', \"Loss\")\n        ]\n        \n        for pattern, factor_type in competitive_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n            for match in matches:\n                if len(match.strip()) > 20:\n                    factors.append(WinLossFactor(\n                        factor_type=factor_type,\n                        description=f\"Competitive analysis: {match.strip()[:250]}\",\n                        impact=self._determine_factor_impact_advanced(match),\n                        confidence=0.85,\n                        category=\"Competitive\"\n                    ))\n        \n        return factors\n    \n    def _parse_client_feedback_analysis(self, text: str) -> List[WinLossFactor]:\n        \"\"\"Parse client feedback and testimonials\"\"\"\n        factors = []\n        \n        # Client feedback patterns\n        feedback_patterns = [\n            # Positive feedback\n            (r'(?:client said|customer feedback|testimonial)[:\\s]+[\"\\']([^\"\\']+)[\"\\']', \"Win\"),\n            (r'(?:praised for|commended|recognized|awarded)[:\\s]+(.*?)(?:\\n|$)', \"Win\"),\n            (r'(?:client satisfaction|positive feedback|happy with)[:\\s]+(.*?)(?:\\n|$)', \"Win\"),\n            \n            # Negative feedback\n            (r'(?:client complained|customer concerns|feedback issues)[:\\s]+(.*?)(?:\\n|$)', \"Loss\"),\n            (r'(?:criticized for|concerns about|problems with)[:\\s]+(.*?)(?:\\n|$)', \"Loss\"),\n            (r'(?:client dissatisfaction|negative feedback|unhappy)[:\\s]+(.*?)(?:\\n|$)', \"Loss\")\n        ]\n        \n        for pattern, factor_type in feedback_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n            for match in matches:\n                if len(match.strip()) > 15:\n                    factors.append(WinLossFactor(\n                        factor_type=factor_type,\n                        description=f\"Client feedback: {match.strip()[:250]}\",\n                        impact=self._determine_factor_impact_advanced(match),\n                        confidence=0.9,  # High confidence for direct client feedback\n                        category=\"Client Relationship\"\n                    ))\n        \n        return factors\n    \n    def _determine_factor_impact_advanced(self, description: str) -> str:\n        \"\"\"Advanced impact determination\"\"\"\n        desc_lower = description.lower()\n        \n        # High impact indicators\n        high_impact = [\n            \"critical\", \"major\", \"significant\", \"substantial\", \"dramatic\", \"transformative\",\n            \"game changer\", \"breakthrough\", \"revolutionary\", \"market leading\", \"industry first\"\n        ]\n        \n        # Medium impact indicators\n        medium_impact = [\n            \"important\", \"notable\", \"considerable\", \"meaningful\", \"valuable\", \"beneficial\",\n            \"improvement\", \"enhancement\", \"advantage\", \"positive\", \"good\"\n        ]\n        \n        # Low impact indicators\n        low_impact = [\n            \"minor\", \"small\", \"slight\", \"modest\", \"limited\", \"marginal\", \"incremental\",\n            \"basic\", \"standard\", \"routine\", \"normal\", \"typical\"\n        ]\n        \n        high_count = sum(1 for indicator in high_impact if indicator in desc_lower)\n        medium_count = sum(1 for indicator in medium_impact if indicator in desc_lower)\n        low_count = sum(1 for indicator in low_impact if indicator in desc_lower)\n        \n        if high_count > 0:\n            return \"High\"\n        elif low_count > medium_count and low_count > 0:\n            return \"Low\"\n        else:\n            return \"Medium\"\n    \n    def _calculate_confidence_score(self, description: str, context: str) -> float:\n        \"\"\"Calculate confidence score for win/loss factor\"\"\"\n        base_confidence = 0.7\n        \n        # Increase confidence for specific indicators\n        desc_lower = description.lower()\n        \n        # Quantitative data increases confidence\n        if any(indicator in desc_lower for indicator in \n               [\"percent\", \"%\", \"million\", \"thousand\", \"dollars\", \"$\", \"days\", \"weeks\", \"months\"]):\n            base_confidence += 0.1\n        \n        # Specific examples increase confidence\n        if any(indicator in desc_lower for indicator in \n               [\"project\", \"client\", \"implementation\", \"specific\", \"example\", \"case study\"]):\n            base_confidence += 0.05\n        \n        # Recent timeframes increase confidence\n        if any(indicator in desc_lower for indicator in \n               [\"recent\", \"last year\", \"2024\", \"2023\", \"this year\", \"currently\"]):\n            base_confidence += 0.08\n        \n        # Cap at 0.95\n        return min(0.95, base_confidence)\n    \n    def _categorize_factor_advanced(self, description: str) -> str:\n        \"\"\"Advanced factor categorization\"\"\"\n        desc_lower = description.lower()\n        \n        # Technical category\n        if any(word in desc_lower for word in \n               [\"technical\", \"technology\", \"system\", \"platform\", \"architecture\", \"software\", \n                \"development\", \"coding\", \"integration\", \"api\", \"database\"]):\n            return \"Technical\"\n        \n        # Team/Resource category\n        elif any(word in desc_lower for word in \n                 [\"team\", \"staff\", \"resource\", \"skill\", \"expertise\", \"experience\", \"talent\",\n                  \"developer\", \"engineer\", \"consultant\", \"project manager\"]):\n            return \"Team\"\n        \n        # Financial category\n        elif any(word in desc_lower for word in \n                 [\"cost\", \"budget\", \"price\", \"financial\", \"money\", \"dollar\", \"investment\",\n                  \"roi\", \"savings\", \"expensive\", \"cheap\"]):\n            return \"Financial\"\n        \n        # Timeline category\n        elif any(word in desc_lower for word in \n                 [\"time\", \"schedule\", \"deadline\", \"delivery\", \"fast\", \"quick\", \"slow\",\n                  \"delayed\", \"ahead\", \"behind\", \"timeline\"]):\n            return \"Timeline\"\n        \n        # Client relationship category\n        elif any(word in desc_lower for word in \n                 [\"client\", \"customer\", \"stakeholder\", \"relationship\", \"communication\",\n                  \"feedback\", \"satisfaction\", \"trust\", \"partnership\"]):\n            return \"Client\"\n        \n        # Quality category\n        elif any(word in desc_lower for word in \n                 [\"quality\", \"reliability\", \"performance\", \"stability\", \"robust\",\n                  \"bug\", \"error\", \"testing\", \"qa\"]):\n            return \"Quality\"\n        \n        # Process category\n        elif any(word in desc_lower for word in \n                 [\"process\", \"methodology\", \"approach\", \"workflow\", \"procedure\",\n                  \"agile\", \"waterfall\", \"management\"]):\n            return \"Process\"\n        \n        # Market/Business category\n        elif any(word in desc_lower for word in \n                 [\"market\", \"business\", \"strategy\", \"competitive\", \"industry\",\n                  \"opportunity\", \"growth\", \"expansion\"]):\n            return \"Business\"\n        \n        else:\n            return \"General\"\n    \n    def _deduplicate_win_loss_factors(self, factors: List[WinLossFactor]) -> List[WinLossFactor]:\n        \"\"\"Remove duplicate win/loss factors\"\"\"\n        if not factors:\n            return factors\n        \n        unique_factors = []\n        seen_descriptions = []\n        \n        for factor in factors:\n            # Check for similarity with existing factors\n            is_duplicate = False\n            for seen_desc in seen_descriptions:\n                similarity = self._calculate_text_similarity(factor.description, seen_desc)\n                if similarity > 0.75:  # 75% similarity threshold\n                    is_duplicate = True\n                    break\n            \n            if not is_duplicate:\n                unique_factors.append(factor)\n                seen_descriptions.append(factor.description)\n        \n        return unique_factors\n    \n    def _enhance_win_loss_with_llm_v2(self, factors: List[WinLossFactor], text: str) -> List[WinLossFactor]:\n        \"\"\"Enhanced LLM-based win/loss factor analysis\"\"\"\n        if not self.llm_processor or not factors:\n            return factors\n        \n        try:\n            factor_context = []\n            for i, factor in enumerate(factors, 1):\n                context = f\"{i}. {factor.factor_type}: {factor.description[:120]}\\n   Category: {factor.category}, Impact: {factor.impact}\"\n                factor_context.append(context)\n            \n            context_text = '\\n'.join(factor_context[:10])  # Limit to first 10 factors\n            \n            prompt = f\"\"\"\n            As an expert RFP analyst, review these win/loss factors and provide strategic insights:\n            \n            {context_text}\n            \n            For each factor, provide:\n            1. Strategic importance (Critical/High/Medium/Low)\n            2. Actionability (Immediate/Short-term/Long-term/Monitor)\n            3. Market relevance (High/Medium/Low)\n            4. Brief strategic recommendation\n            \n            Format: \"Factor X: Importance=High|Action=Immediate|Market=High|Rec=Leverage in proposals\"\n            \"\"\"\n            \n            llm_response = self.llm_processor._generate_text(prompt, 700)\n            \n            # Parse and apply enhancements\n            response_lines = [line.strip() for line in llm_response.split('\\n') if line.strip()]\n            \n            for line in response_lines:\n                if 'Factor' in line and '=' in line:\n                    try:\n                        factor_ref_match = re.search(r'Factor (\\d+)', line)\n                        if factor_ref_match:\n                            factor_idx = int(factor_ref_match.group(1)) - 1\n                            \n                            if 0 <= factor_idx < len(factors):\n                                # Extract strategic insights\n                                if 'Importance=' in line:\n                                    importance_match = re.search(r'Importance=([^|]+)', line)\n                                    if importance_match:\n                                        importance = importance_match.group(1).strip()\n                                        # Map to impact levels\n                                        if importance in ['Critical', 'High']:\n                                            factors[factor_idx].impact = \"High\"\n                                        elif importance == 'Medium':\n                                            factors[factor_idx].impact = \"Medium\"\n                                        else:\n                                            factors[factor_idx].impact = \"Low\"\n                                \n                                if 'Rec=' in line:\n                                    rec_match = re.search(r'Rec=(.+)', line)\n                                    if rec_match:\n                                        recommendation = rec_match.group(1).strip()\n                                        # Add recommendation to description\n                                        original_desc = factors[factor_idx].description\n                                        factors[factor_idx].description = f\"{original_desc} | Strategic insight: {recommendation}\"\n                    \n                    except (ValueError, IndexError):\n                        continue\n        \n        except Exception as e:\n            print(f\"Enhanced LLM win/loss analysis failed: {e}\")\n        \n        return factors\n    \n    def _create_default_win_loss_factors(self) -> List[WinLossFactor]:\n        \"\"\"Create default win/loss factors when parsing fails\"\"\"\n        return [\n            WinLossFactor(\n                factor_type=\"Win\",\n                description=\"Proven technical expertise and successful project delivery track record in similar implementations\",\n                impact=\"High\",\n                confidence=0.85,\n                category=\"Technical\"\n            ),\n            WinLossFactor(\n                factor_type=\"Win\",\n                description=\"Strong client relationships and high satisfaction scores from previous engagements\",\n                impact=\"High\",\n                confidence=0.80,\n                category=\"Client\"\n            ),\n            WinLossFactor(\n                factor_type=\"Win\",\n                description=\"Competitive pricing model with fixed-cost approach reducing client financial risk\",\n                impact=\"Medium\",\n                confidence=0.75,\n                category=\"Financial\"\n            ),\n            WinLossFactor(\n                factor_type=\"Loss\",\n                description=\"Limited historical data available - requires analysis of specific win/loss patterns for this market segment\",\n                impact=\"Medium\",\n                confidence=0.60,\n                category=\"General\"\n            ),\n            WinLossFactor(\n                factor_type=\"Unknown\",\n                description=\"Comprehensive win/loss analysis needed to identify specific success factors and areas for improvement\",\n                impact=\"Medium\",\n                confidence=0.50,\n                category=\"Analysis\"\n            )\n        ]\n\n    # ========== REQUIREMENTS ANALYSIS METHODS ==========\n    \n    def parse_requirements_enhanced(self, text: str) -> List[Requirement]:\n        \"\"\"Enhanced requirements parsing with comprehensive analysis\"\"\"\n        requirements = []\n        \n        # Strategy 1: Advanced structured requirement patterns\n        requirements.extend(self._parse_structured_requirements_v2(text))\n        \n        # Strategy 2: MoSCoW method parsing (Must/Should/Could/Won't)\n        if len(requirements) < 3:\n            requirements.extend(self._parse_moscow_requirements(text))\n        \n        # Strategy 3: User story and use case parsing\n        if len(requirements) < 2:\n            requirements.extend(self._parse_user_stories(text))\n        \n        # Strategy 4: Compliance and regulatory requirements\n        if len(requirements) < 1:\n            requirements.extend(self._parse_compliance_requirements(text))\n        \n        # Remove duplicates and enhance\n        requirements = self._deduplicate_requirements(requirements)\n        \n        if self.llm_processor and requirements:\n            requirements = self._enhance_requirements_with_llm(requirements, text)\n        \n        return requirements if requirements else self._create_default_requirements()\n    \n    def _parse_structured_requirements_v2(self, text: str) -> List[Requirement]:\n        \"\"\"Advanced structured requirements parsing\"\"\"\n        requirements = []\n        \n        # Enhanced requirement patterns\n        requirement_patterns = [\n            # Functional requirements\n            (r'(?:Functional requirement|FR-?\\d*)[:\\s]+(.*?)(?=(?:Non-functional|Technical|Performance|$))', \"Functional\"),\n            (r'(?:The system shall|The solution must|The platform should)[:\\s]+(.*?)(?:\\.|$)', \"Functional\"),\n            (r'(?:User must be able to|System must support|Application shall)[:\\s]+(.*?)(?:\\.|$)', \"Functional\"),\n            \n            # Non-functional requirements\n            (r'(?:Non-functional requirement|NFR-?\\d*|Performance requirement)[:\\s]+(.*?)(?=(?:Functional|Technical|$))', \"Performance\"),\n            (r'(?:Performance|Scalability|Availability|Reliability)[:\\s]+(.*?)(?:\\.|$)', \"Performance\"),\n            (r'(?:System must handle|Response time|Throughput)[:\\s]+(.*?)(?:\\.|$)', \"Performance\"),\n            \n            # Technical requirements\n            (r'(?:Technical requirement|TR-?\\d*)[:\\s]+(.*?)(?=(?:Functional|Performance|$))', \"Technical\"),\n            (r'(?:Technology stack|Platform|Infrastructure)[:\\s]+(.*?)(?:\\.|$)', \"Technical\"),\n            (r'(?:Integration with|API|Database)[:\\s]+(.*?)(?:\\.|$)', \"Integration\"),\n            \n            # Security requirements\n            (r'(?:Security requirement|Authentication|Authorization|Encryption)[:\\s]+(.*?)(?:\\.|$)', \"Security\"),\n            (r'(?:Access control|Data protection|Privacy)[:\\s]+(.*?)(?:\\.|$)', \"Security\"),\n            \n            # Compliance requirements\n            (r'(?:Compliance|Regulatory|Standards?)[:\\s]+(.*?)(?:\\.|$)', \"Compliance\"),\n            (r'(?:Must comply with|According to|As per)[:\\s]+(.*?)(?:\\.|$)', \"Compliance\")\n        ]\n        \n        for pattern, req_type in requirement_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE | re.DOTALL)\n            \n            for match in matches:\n                if isinstance(match, str) and len(match.strip()) > 20:\n                    description = match.strip()[:400]\n                    \n                    # Determine priority and capability\n                    priority = self._determine_requirement_priority_advanced(description)\n                    capability = self._assess_our_capability_advanced(description, text)\n                    effort = self._calculate_requirement_effort(capability, req_type)\n                    \n                    requirements.append(Requirement(\n                        requirement_type=req_type,\n                        description=description,\n                        priority=priority,\n                        our_capability=capability,\n                        effort_to_meet=effort\n                    ))\n        \n        return requirements\n    \n    def _parse_moscow_requirements(self, text: str) -> List[Requirement]:\n        \"\"\"Parse requirements using MoSCoW method\"\"\"\n        requirements = []\n        \n        moscow_patterns = [\n            (r'(?:Must have|Mandatory|Required|Essential|Critical)[:\\s]+(.*?)(?=(?:Should have|Could have|Won\\'t have|$))', \"Must Have\"),\n            (r'(?:Should have|Important|Recommended|Preferred)[:\\s]+(.*?)(?=(?:Must have|Could have|Won\\'t have|$))', \"Should Have\"),\n            (r'(?:Could have|Nice to have|Optional|If time permits)[:\\s]+(.*?)(?=(?:Must have|Should have|Won\\'t have|$))', \"Could Have\"),\n            (r'(?:Won\\'t have|Out of scope|Future|Next phase)[:\\s]+(.*?)(?=(?:Must have|Should have|Could have|$))', \"Won't Have\")\n        ]\n        \n        for pattern, priority in moscow_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE | re.DOTALL)\n            \n            for match in matches:\n                if len(match.strip()) > 25:\n                    description = match.strip()[:400]\n                    req_type = self._classify_requirement_type_advanced(description)\n                    capability = self._assess_our_capability_advanced(description, text)\n                    \n                    if priority != \"Won't Have\":  # Skip out-of-scope requirements\n                        requirements.append(Requirement(\n                            requirement_type=req_type,\n                            description=description,\n                            priority=priority,\n                            our_capability=capability,\n                            effort_to_meet=self._calculate_requirement_effort(capability, req_type)\n                        ))\n        \n        return requirements\n    \n    def _parse_user_stories(self, text: str) -> List[Requirement]:\n        \"\"\"Parse user stories and use cases\"\"\"\n        requirements = []\n        \n        # User story patterns\n        user_story_patterns = [\n            r'(?:As a|As an)\\s+([^,]+),\\s*I want\\s+([^,]+),?\\s*(?:so that|in order to)?\\s*(.*?)(?:\\.|$)',\n            r'(?:User story|Story)[:\\s]*([^.]+?)(?:\\.|$)',\n            r'(?:Use case|UC-?\\d*)[:\\s]+(.*?)(?=(?:Use case|User story|$))'\n        ]\n        \n        for pattern in user_story_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n            \n            for match in matches:\n                if isinstance(match, tuple):\n                    # Full user story format\n                    if len(match) == 3:\n                        user_role, action, benefit = match\n                        description = f\"As a {user_role}, I want {action} so that {benefit}\"\n                    else:\n                        description = ' '.join(match)\n                else:\n                    description = match\n                \n                if len(description.strip()) > 30:\n                    req_type = self._classify_requirement_type_advanced(description)\n                    priority = self._determine_requirement_priority_advanced(description)\n                    capability = self._assess_our_capability_advanced(description, text)\n                    \n                    requirements.append(Requirement(\n                        requirement_type=\"Functional\",  # User stories are typically functional\n                        description=description[:400],\n                        priority=priority,\n                        our_capability=capability,\n                        effort_to_meet=self._calculate_requirement_effort(capability, \"Functional\")\n                    ))\n        \n        return requirements[:10]  # Limit to top 10 user stories\n    \n    def _parse_compliance_requirements(self, text: str) -> List[Requirement]:\n        \"\"\"Parse compliance and regulatory requirements\"\"\"\n        requirements = []\n        \n        # Compliance indicators\n        compliance_keywords = [\n            \"GDPR\", \"HIPAA\", \"SOX\", \"PCI DSS\", \"ISO 27001\", \"SOC 2\",\n            \"compliance\", \"regulatory\", \"audit\", \"certification\",\n            \"data protection\", \"privacy\", \"security standards\"\n        ]\n        \n        sentences = sent_tokenize(text)\n        \n        for sentence in sentences:\n            sentence_lower = sentence.lower()\n            \n            # Check if sentence mentions compliance\n            compliance_matches = sum(1 for keyword in compliance_keywords if keyword.lower() in sentence_lower)\n            \n            if compliance_matches > 0 and len(sentence) > 30:\n                priority = \"Must Have\" if any(keyword in sentence_lower for keyword in \n                                            [\"mandatory\", \"required\", \"must\", \"shall\"]) else \"Should Have\"\n                \n                capability = self._assess_our_capability_advanced(sentence, text)\n                \n                requirements.append(Requirement(\n                    requirement_type=\"Compliance\",\n                    description=f\"Compliance requirement: {sentence[:350]}\",\n                    priority=priority,\n                    our_capability=capability,\n                    effort_to_meet=self._calculate_requirement_effort(capability, \"Compliance\")\n                ))\n        \n        return requirements[:5]  # Limit to top 5 compliance requirements\n    \n    def _classify_requirement_type_advanced(self, description: str) -> str:\n        \"\"\"Advanced requirement type classification\"\"\"\n        desc_lower = description.lower()\n        \n        # Security requirements\n        if any(word in desc_lower for word in \n               [\"security\", \"authentication\", \"authorization\", \"encryption\", \"access control\",\n                \"privacy\", \"confidential\", \"secure\", \"login\", \"password\"]):\n            return \"Security\"\n        \n        # Performance requirements\n        elif any(word in desc_lower for word in \n                 [\"performance\", \"speed\", \"response time\", \"latency\", \"throughput\", \"load\",\n                  \"scalability\", \"concurrent\", \"users\", \"transactions\"]):\n            return \"Performance\"\n        \n        # Integration requirements\n        elif any(word in desc_lower for word in \n                 [\"integration\", \"interface\", \"api\", \"connect\", \"sync\", \"import\", \"export\",\n                  \"third party\", \"external\", \"web service\"]):\n            return \"Integration\"\n        \n        # Data requirements\n        elif any(word in desc_lower for word in \n                 [\"data\", \"database\", \"storage\", \"backup\", \"recovery\", \"migration\",\n                  \"format\", \"structure\", \"schema\"]):\n            return \"Data\"\n        \n        # UI/UX requirements\n        elif any(word in desc_lower for word in \n                 [\"user interface\", \"ui\", \"ux\", \"usability\", \"accessibility\", \"responsive\",\n                  \"mobile\", \"design\", \"layout\", \"navigation\"]):\n            return \"UI/UX\"\n        \n        # Compliance requirements\n        elif any(word in desc_lower for word in \n                 [\"compliance\", \"regulatory\", \"audit\", \"standard\", \"certification\",\n                  \"gdpr\", \"hipaa\", \"sox\", \"pci\"]):\n            return \"Compliance\"\n        \n        # Functional requirements (default)\n        else:\n            return \"Functional\"\n    \n    def _determine_requirement_priority_advanced(self, description: str) -> str:\n        \"\"\"Advanced requirement priority determination\"\"\"\n        desc_lower = description.lower()\n        \n        # Must have indicators\n        must_have = [\n            \"must\", \"mandatory\", \"required\", \"essential\", \"critical\", \"vital\",\n            \"shall\", \"needed\", \"necessary\", \"cannot work without\", \"blocker\"\n        ]\n        \n        # Should have indicators\n        should_have = [\n            \"should\", \"important\", \"significant\", \"recommended\", \"preferred\",\n            \"expected\", \"standard\", \"typical\", \"normal practice\"\n        ]\n        \n        # Could have indicators\n        could_have = [\n            \"could\", \"nice to have\", \"optional\", \"if possible\", \"desirable\",\n            \"enhancement\", \"improvement\", \"future\", \"phase 2\"\n        ]\n        \n        must_count = sum(1 for indicator in must_have if indicator in desc_lower)\n        should_count = sum(1 for indicator in should_have if indicator in desc_lower)\n        could_count = sum(1 for indicator in could_have if indicator in desc_lower)\n        \n        if must_count > 0:\n            return \"Must Have\"\n        elif could_count > should_count and could_count > 0:\n            return \"Could Have\"\n        elif should_count > 0:\n            return \"Should Have\"\n        else:\n            # Default based on requirement type keywords\n            if any(word in desc_lower for word in [\"security\", \"compliance\", \"data\"]):\n                return \"Must Have\"\n            else:\n                return \"Should Have\"\n    \n    def _assess_our_capability_advanced(self, description: str, context: str = \"\") -> str:\n        \"\"\"Advanced capability assessment\"\"\"\n        desc_lower = description.lower()\n        context_lower = context.lower()\n        combined = f\"{desc_lower} {context_lower}\"\n        \n        # Full capability indicators\n        full_indicators = [\n            \"fully support\", \"complete\", \"available\", \"implemented\", \"existing\",\n            \"current\", \"in place\", \"operational\", \"ready\", \"proven\"\n        ]\n        \n        # Partial capability indicators\n        partial_indicators = [\n            \"partially\", \"limited\", \"basic\", \"some\", \"customization needed\",\n            \"modification required\", \"enhancement needed\", \"adaptation\"\n        ]\n        \n        # No capability indicators\n        none_indicators = [\n            \"missing\", \"not available\", \"not supported\", \"requires development\",\n            \"needs to be built\", \"custom development\", \"new feature\"\n        ]\n        \n        full_count = sum(1 for indicator in full_indicators if indicator in combined)\n        partial_count = sum(1 for indicator in partial_indicators if indicator in combined)\n        none_count = sum(1 for indicator in none_indicators if indicator in combined)\n        \n        if full_count > partial_count and full_count > none_count:\n            return \"Full\"\n        elif none_count > partial_count and none_count > 0:\n            return \"None\"\n        else:\n            return \"Partial\"\n    \n    def _calculate_requirement_effort(self, capability: str, req_type: str) -> str:\n        \"\"\"Calculate effort required based on capability and requirement type\"\"\"\n        base_efforts = {\n            (\"Full\", \"Functional\"): \"None\",\n            (\"Full\", \"Technical\"): \"1 week\",\n            (\"Full\", \"Performance\"): \"1-2 weeks\",\n            (\"Full\", \"Security\"): \"1-2 weeks\",\n            (\"Full\", \"Integration\"): \"2-3 weeks\",\n            (\"Full\", \"Compliance\"): \"2-4 weeks\",\n            (\"Full\", \"Data\"): \"1-2 weeks\",\n            (\"Full\", \"UI/UX\"): \"1-3 weeks\",\n            \n            (\"Partial\", \"Functional\"): \"2-4 weeks\",\n            (\"Partial\", \"Technical\"): \"3-5 weeks\",\n            (\"Partial\", \"Performance\"): \"4-6 weeks\",\n            (\"Partial\", \"Security\"): \"4-8 weeks\",\n            (\"Partial\", \"Integration\"): \"4-8 weeks\",\n            (\"Partial\", \"Compliance\"): \"6-10 weeks\",\n            (\"Partial\", \"Data\"): \"3-6 weeks\",\n            (\"Partial\", \"UI/UX\"): \"4-8 weeks\",\n            \n            (\"None\", \"Functional\"): \"6-12 weeks\",\n            (\"None\", \"Technical\"): \"8-16 weeks\",\n            (\"None\", \"Performance\"): \"10-20 weeks\",\n            (\"None\", \"Security\"): \"12-24 weeks\",\n            (\"None\", \"Integration\"): \"8-16 weeks\",\n            (\"None\", \"Compliance\"): \"16-32 weeks\",\n            (\"None\", \"Data\"): \"8-16 weeks\",\n            (\"None\", \"UI/UX\"): \"10-20 weeks\"\n        }\n        \n        return base_efforts.get((capability, req_type), \"4-8 weeks\")\n    \n    def _deduplicate_requirements(self, requirements: List[Requirement]) -> List[Requirement]:\n        \"\"\"Remove duplicate requirements\"\"\"\n        if not requirements:\n            return requirements\n        \n        unique_requirements = []\n        seen_descriptions = []\n        \n        for req in requirements:\n            # Check for similarity with existing requirements\n            is_duplicate = False\n            for seen_desc in seen_descriptions:\n                similarity = self._calculate_text_similarity(req.description, seen_desc)\n                if similarity > 0.7:  # 70% similarity threshold\n                    is_duplicate = True\n                    break\n            \n            if not is_duplicate:\n                unique_requirements.append(req)\n                seen_descriptions.append(req.description)\n        \n        return unique_requirements\n    \n    def _enhance_requirements_with_llm(self, requirements: List[Requirement], text: str) -> List[Requirement]:\n        \"\"\"Enhanced LLM-based requirements analysis\"\"\"\n        if not self.llm_processor or not requirements:\n            return requirements\n        \n        try:\n            req_context = []\n            for i, req in enumerate(requirements, 1):\n                context = f\"{i}. {req.requirement_type}: {req.description[:100]}\\n   Priority: {req.priority}, Capability: {req.our_capability}\"\n                req_context.append(context)\n            \n            context_text = '\\n'.join(req_context[:8])  # Limit to first 8 requirements\n            \n            prompt = f\"\"\"\n            As an expert RFP analyst, review these requirements and provide enhanced analysis:\n            \n            {context_text}\n            \n            For each requirement, provide:\n            1. Business criticality (Critical/High/Medium/Low)\n            2. Implementation complexity (Complex/Moderate/Simple)\n            3. Risk level (High/Medium/Low)\n            4. Brief implementation note\n            \n            Format: \"Req X: Criticality=High|Complexity=Moderate|Risk=Low|Note=Standard feature\"\n            \"\"\"\n            \n            llm_response = self.llm_processor._generate_text(prompt, 600)\n            \n            # Parse and apply enhancements\n            response_lines = [line.strip() for line in llm_response.split('\\n') if line.strip()]\n            \n            for line in response_lines:\n                if 'Req' in line and '=' in line:\n                    try:\n                        req_ref_match = re.search(r'Req (\\d+)', line)\n                        if req_ref_match:\n                            req_idx = int(req_ref_match.group(1)) - 1\n                            \n                            if 0 <= req_idx < len(requirements):\n                                # Apply enhancements\n                                if 'Criticality=' in line:\n                                    criticality_match = re.search(r'Criticality=([^|]+)', line)\n                                    if criticality_match:\n                                        criticality = criticality_match.group(1).strip()\n                                        # Map to priority\n                                        if criticality in ['Critical', 'High']:\n                                            requirements[req_idx].priority = \"Must Have\"\n                                        elif criticality == 'Medium':\n                                            requirements[req_idx].priority = \"Should Have\"\n                                        else:\n                                            requirements[req_idx].priority = \"Could Have\"\n                                \n                                if 'Complexity=' in line:\n                                    complexity_match = re.search(r'Complexity=([^|]+)', line)\n                                    if complexity_match:\n                                        complexity = complexity_match.group(1).strip()\n                                        # Adjust effort based on complexity\n                                        current_effort = requirements[req_idx].effort_to_meet\n                                        if complexity == 'Complex' and 'weeks' in current_effort:\n                                            # Increase effort by 50%\n                                            requirements[req_idx].effort_to_meet = f\"Extended: {current_effort}\"\n                                \n                                if 'Note=' in line:\n                                    note_match = re.search(r'Note=(.+)', line)\n                                    if note_match:\n                                        note = note_match.group(1).strip()\n                                        # Add note to description\n                                        original_desc = requirements[req_idx].description\n                                        requirements[req_idx].description = f\"{original_desc} | Analysis: {note}\"\n                    \n                    except (ValueError, IndexError):\n                        continue\n        \n        except Exception as e:\n            print(f\"Enhanced LLM requirements analysis failed: {e}\")\n        \n        return requirements\n    \n    def _create_default_requirements(self) -> List[Requirement]:\n        \"\"\"Create default requirements when parsing fails\"\"\"\n        return [\n            Requirement(\n                requirement_type=\"Functional\",\n                description=\"Core system functionality as specified in client requirements document - comprehensive analysis needed to define specific functional capabilities\",\n                priority=\"Must Have\",\n                our_capability=\"Partial\",\n                effort_to_meet=\"4-8 weeks\"\n            ),\n            Requirement(\n                requirement_type=\"Performance\",\n                description=\"System performance requirements including response times, throughput, and scalability to handle expected user load and data volumes\",\n                priority=\"Must Have\",\n                our_capability=\"Partial\",\n                effort_to_meet=\"3-6 weeks\"\n            ),\n            Requirement(\n                requirement_type=\"Security\",\n                description=\"Security and access control requirements including authentication, authorization, data encryption, and compliance with industry standards\",\n                priority=\"Must Have\",\n                our_capability=\"Full\",\n                effort_to_meet=\"2-4 weeks\"\n            ),\n            Requirement(\n                requirement_type=\"Integration\",\n                description=\"Integration requirements with existing client systems, third-party services, and data sources as specified in the RFP\",\n                priority=\"Should Have\",\n                our_capability=\"Partial\",\n                effort_to_meet=\"4-8 weeks\"\n            ),\n            Requirement(\n                requirement_type=\"UI/UX\",\n                description=\"User interface and user experience requirements including accessibility, responsiveness, and usability standards\",\n                priority=\"Should Have\",\n                our_capability=\"Partial\",\n                effort_to_meet=\"6-10 weeks\"\n            )\n        ]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:48.118699Z","iopub.execute_input":"2025-07-29T15:48:48.118871Z","iopub.status.idle":"2025-07-29T15:48:48.270072Z","shell.execute_reply.started":"2025-07-29T15:48:48.118859Z","shell.execute_reply":"2025-07-29T15:48:48.269345Z"}},"outputs":[],"execution_count":175},{"cell_type":"code","source":"class RFPFeasibilityAnalyzer:\n    \"\"\"Main analyzer that determines if we can respond to the RFP\"\"\"\n    \n    def __init__(self):\n        self.processor = DocumentProcessor()\n        self.modules = []\n        self.gaps = []\n        self.win_loss_factors = []\n        self.requirements = []\n        self.document_summaries = {}\n        \n    def _parse_llm_text_output(self, text: str, doc_type: str) -> Dict[str, Any]:\n        \"\"\"Parse plain text output from LLM into summary, confidence, and key points\"\"\"\n        try:\n            # Initialize default values\n            result = {\n                'llm_analysis': f\"Summary of {doc_type}: [Text not available]\",\n                'confidence': 0.85,\n                'key_points': [\n                    f\"Key insight 1 for {doc_type}\",\n                    f\"Key insight 2 for {doc_type}\",\n                    f\"Key insight 3 for {doc_type}\"\n                ]\n            }\n            \n            # Extract summary\n            summary_match = re.search(r'Summary: (.*?)(?=\\nConfidence:|\\Z)', text, re.DOTALL)\n            if summary_match:\n                result['llm_analysis'] = summary_match.group(1).strip()\n            \n            # Extract confidence\n            confidence_match = re.search(r'Confidence: (\\d*\\.?\\d*)', text)\n            if confidence_match:\n                try:\n                    confidence = float(confidence_match.group(1))\n                    if 0 <= confidence <= 1:\n                        result['confidence'] = confidence\n                except ValueError:\n                    pass\n            \n            # Extract key points\n            key_points_match = re.search(r'Key Points:\\n((?:- [^\\n]*\\n?)+)', text, re.DOTALL)\n            if key_points_match:\n                points = key_points_match.group(1).split('\\n- ')\n                points = [p.strip('- ').strip() for p in points if p.strip('- ').strip()]\n                if len(points) >= 2:\n                    result['key_points'] = points[:3]\n            \n            return result\n        except Exception as e:\n            print(f\"Error parsing LLM text output for {doc_type}: {e}\")\n            return result\n    \n    def load_and_analyze_documents(self, file_paths: Dict[str, str]) -> Dict[str, Any]:\n        \"\"\"Load documents and extract structured information\"\"\"\n        results = {\n            'documents_processed': 0,\n            'total_content_length': 0,\n            'extraction_summary': {}\n        }\n        \n        for doc_type, file_path in file_paths.items():\n            print(f\"\\n📄 Analyzing {doc_type}...\")\n            text = self.processor.extract_text_from_pdf(file_path)\n            \n            if not text:\n                print(f\"  ⚠️  Warning: Could not extract text from {file_path}\")\n                continue\n            \n            print(f\"  ✓ Extracted {len(text)} characters\")\n            results['documents_processed'] += 1\n            results['total_content_length'] += len(text)\n            \n            # Store document summary\n            self.document_summaries[doc_type] = {\n                'length': len(text),\n                'preview': text[:500],\n                'sentences': len(sent_tokenize(text)),\n                'llm_summary': '',\n                'confidence': 0.0,\n                'key_points': []\n            }\n            \n            # Get LLM analysis for the document\n            if self.processor.llm_processor:\n                print(f\"  🤖 Running AI analysis...\")\n                prompt = f\"\"\"\n                You are an expert RFP analyst. Analyze the following document of type '{doc_type}' and provide:\n                - A summary of the document (max 200 words).\n                - A confidence score (0.0 to 1.0) for the accuracy of the analysis.\n                - Key points (list 2-3 bullet points summarizing critical insights).\n                Document text: {text[:1500]}\n                Return in the format:\n                Summary: [summary]\n                Confidence: [score]\n                Key Points:\n                - [point 1]\n                - [point 2]\n                - [point 3]\n                \"\"\"\n                llm_result = self.processor.llm_processor._generate_text(prompt, max_length=1000)\n                parsed_result = self._parse_llm_text_output(llm_result, doc_type)\n                print(f\"  ✓ AI insights generated\")\n                self.document_summaries[doc_type]['llm_summary'] = parsed_result['llm_analysis']\n                self.document_summaries[doc_type]['confidence'] = parsed_result['confidence']\n                self.document_summaries[doc_type]['key_points'] = parsed_result['key_points']\n            \n            # Extract information based on document type\n            if doc_type == 'module_matching':\n                self.modules = self.processor.parse_modules_enhanced(text)\n                results['extraction_summary']['modules'] = len(self.modules)\n                print(f\"  ✓ Extracted {len(self.modules)} modules\")\n                \n            elif doc_type == 'gap_analysis':\n                self.gaps = self.processor.parse_gaps_enhanced(text)\n                results['extraction_summary']['gaps'] = len(self.gaps)\n                print(f\"  ✓ Extracted {len(self.gaps)} gaps\")\n                \n            elif doc_type == 'win_loss':\n                self.win_loss_factors = self.processor.parse_win_loss_enhanced(text)\n                results['extraction_summary']['win_loss_factors'] = len(self.win_loss_factors)\n                print(f\"  ✓ Extracted {len(self.win_loss_factors)} win/loss factors\")\n                \n            elif doc_type == 'customer_needs':\n                self.requirements = self.processor.parse_requirements_enhanced(text)\n                results['extraction_summary']['requirements'] = len(self.requirements)\n                print(f\"  ✓ Extracted {len(self.requirements)} requirements\")\n        \n        return results\n    \n    def calculate_feasibility(self) -> RFPFeasibilityAssessment:\n        \"\"\"Calculate overall feasibility of responding to RFP with LLM insights\"\"\"\n        \n        # Module analysis\n        total_modules = len(self.modules)\n        available_modules = len([m for m in self.modules if m.status in [\"Available\", \"Partial\"]])\n        partial_modules = len([m for m in self.modules if m.status == \"Partial\"])\n        missing_modules = len([m for m in self.modules if m.status in [\"Missing\", \"Unknown\"]])\n        \n        module_coverage = (available_modules / total_modules * 100) if total_modules > 0 else 0\n        \n        # Gap analysis\n        critical_gaps = [g for g in self.gaps if g.severity in ['Critical', 'High']]\n        medium_gaps = [g for g in self.gaps if g.severity == 'Medium']\n        low_gaps = [g for g in self.gaps if g.severity == 'Low']\n        \n        # Requirements analysis\n        must_have_reqs = [r for r in self.requirements if r.priority == 'Must Have']\n        met_must_haves = [r for r in must_have_reqs if r.our_capability in ['Full', 'Partial']]\n        requirement_coverage = (len(met_must_haves) / len(must_have_reqs) * 100) if must_have_reqs else 100\n        \n        # Win/Loss analysis\n        win_factors = [f for f in self.win_loss_factors if f.factor_type == 'Win']\n        loss_factors = [f for f in self.win_loss_factors if f.factor_type == 'Loss']\n        win_loss_ratio = len(win_factors) / (len(loss_factors) + 1)  # +1 to avoid division by zero\n        \n        # Calculate confidence score (0-100)\n        confidence_score = 0\n        \n        # Module coverage (30% weight)\n        confidence_score += module_coverage * 0.3\n        \n        # Requirement coverage (30% weight)\n        confidence_score += requirement_coverage * 0.3\n        \n        # Gap severity (20% weight - inverse)\n        gap_penalty = len(critical_gaps) * 10 + len(medium_gaps) * 5 + len(low_gaps) * 2\n        confidence_score += max(0, 20 - gap_penalty)\n        \n        # Win/Loss history (20% weight)\n        if win_loss_ratio > 2:\n            confidence_score += 20\n        elif win_loss_ratio > 1:\n            confidence_score += 15\n        elif win_loss_ratio > 0.5:\n            confidence_score += 10\n        else:\n            confidence_score += 5\n        \n        # Determine if we can respond\n        can_respond = confidence_score >= 60 and len(critical_gaps) <= 2\n        \n        # Calculate win probability (includes market factors)\n        win_probability = confidence_score * 0.8 if can_respond else confidence_score * 0.5\n        \n        # Get LLM insights\n        print(\"\\n🤖 Generating AI insights...\")\n        module_insights = self.processor.llm_processor.analyze_module_coverage(self.modules)\n        gap_insights = self.processor.llm_processor.analyze_gaps_impact(self.gaps)\n        win_loss_insights = self.processor.llm_processor.analyze_win_loss_patterns(self.win_loss_factors)\n        \n        # Generate SWOT analysis\n        strengths = [\n            f\"Strong win/loss ratio: {win_loss_ratio:.1f}\" if win_loss_ratio > 1 else None,\n            f\"{available_modules} modules available\" if available_modules > 0 else None,\n            f\"{len(met_must_haves)} must-have requirements met\" if met_must_haves else None,\n        ] + [f.description for f in win_factors[:2]]\n        if \"strength\" in module_insights.lower():\n            strengths.append(f\"AI Insight: {module_insights[:100]}...\")\n        strengths = [s for s in strengths if s]\n        \n        weaknesses = [\n            f\"{missing_modules} modules missing\" if missing_modules > 0 else None,\n            f\"{len(critical_gaps)} critical gaps\" if critical_gaps else None,\n            f\"Low requirement coverage: {requirement_coverage:.0f}%\" if requirement_coverage < 70 else None,\n        ] + [f.description for f in loss_factors[:2]]\n        if \"weakness\" in gap_insights.lower() or \"concern\" in gap_insights.lower():\n            weaknesses.append(f\"AI Insight: {gap_insights[:100]}...\")\n        weaknesses = [w for w in weaknesses if w]\n        \n        opportunities = [\n            \"Leverage partial modules\" if partial_modules > 0 else None,\n            \"Use past win experience\" if win_factors else None,\n            \"Mitigate identified gaps\" if self.gaps else None,\n        ]\n        if \"opportunity\" in win_loss_insights.lower():\n            opportunities.append(f\"AI Insight: {win_loss_insights[:100]}...\")\n        opportunities = [o for o in opportunities if o]\n        \n        threats = [\n            \"Critical gaps may disqualify\" if critical_gaps else None,\n            \"Loss factors remain relevant\" if loss_factors else None,\n            \"High development effort needed\" if missing_modules > total_modules * 0.3 else None,\n        ]\n        threats = [t for t in threats if t]\n        \n        # Generate required actions\n        required_actions = []\n        for gap in critical_gaps[:3]:\n            required_actions.append((\n                f\"Address {gap.gap_type} gap: {gap.description[:50]}...\",\n                gap.severity,\n                gap.effort_required,\n                \"Gap Team\"\n            ))\n        unmet_must_haves = [r for r in must_have_reqs if r.our_capability in ['None', 'Partial']]\n        for req in unmet_must_haves[:2]:\n            required_actions.append((\n                f\"Develop {req.requirement_type}: {req.description[:40]}...\",\n                \"High\",\n                req.effort_to_meet,\n                \"Development Team\"\n            ))\n        critical_missing_modules = [m for m in self.modules if m.status == \"Missing\" and m.client_priority == \"High\"]\n        for module in critical_missing_modules[:2]:\n            required_actions.append((\n                f\"Develop module: {module.module_name}\",\n                \"Critical\",\n                \"2-4 weeks\",\n                \"Technical Team\"\n            ))\n        \n        # Risk assessment\n        risks = []\n        if len(critical_gaps) > 0:\n            risks.append(RiskAssessment(\n                risk_type=\"Technical\",\n                description=f\"{len(critical_gaps)} critical gaps may prevent delivery\",\n                probability=\"High\" if len(critical_gaps) > 2 else \"Medium\",\n                impact=\"High\",\n                mitigation_plan=\"Fast-track gap closure\"\n            ))\n        if module_coverage < 70:\n            risks.append(RiskAssessment(\n                risk_type=\"Delivery\",\n                description=f\"Low module coverage ({module_coverage:.0f}%) risks timeline\",\n                probability=\"High\",\n                impact=\"Medium\",\n                mitigation_plan=\"Partner for missing modules\"\n            ))\n        if requirement_coverage < 80:\n            risks.append(RiskAssessment(\n                risk_type=\"Commercial\",\n                description=\"Requirement gaps may impact satisfaction\",\n                probability=\"Medium\",\n                impact=\"High\",\n                mitigation_plan=\"Communicate roadmap to client\"\n            ))\n        \n        # Investment and timeline estimates\n        investment_parts = []\n        timeline_parts = []\n        if missing_modules > 0:\n            investment_parts.append(f\"${missing_modules * 50}K-${missing_modules * 100}K for modules\")\n            timeline_parts.append(f\"{missing_modules * 2}-{missing_modules * 4} weeks for modules\")\n        if len(critical_gaps) > 0:\n            investment_parts.append(f\"${len(critical_gaps) * 25}K-${len(critical_gaps) * 50}K for gaps\")\n            timeline_parts.append(f\"{len(critical_gaps)}-{len(critical_gaps) * 2} weeks for gaps\")\n        investment_required = \" + \".join(investment_parts) if investment_parts else \"Minimal investment\"\n        timeline_estimate = \", \".join(timeline_parts) if timeline_parts else \"Immediate start\"\n        \n        # Resource requirements\n        resource_needs = []\n        if missing_modules > 5:\n            resource_needs.append(f\"{missing_modules // 2} developers\")\n        if len(critical_gaps) > 3:\n            resource_needs.append(f\"{len(critical_gaps) // 2} architects\")\n        if len(unmet_must_haves) > 0:\n            resource_needs.append(\"1-2 business analysts\")\n        resource_requirements = \", \".join(resource_needs) if resource_needs else \"Existing team sufficient\"\n        \n        # Create initial assessment\n        initial_assessment = RFPFeasibilityAssessment(\n            can_respond=can_respond,\n            confidence_score=confidence_score,\n            win_probability=win_probability,\n            total_modules=total_modules,\n            available_modules=available_modules,\n            partial_modules=partial_modules,\n            missing_modules=missing_modules,\n            critical_gaps=critical_gaps,\n            all_gaps=self.gaps,\n            strengths=strengths,\n            weaknesses=weaknesses,\n            opportunities=opportunities,\n            threats=threats,\n            required_actions=required_actions,\n            risks=risks,\n            investment_required=investment_required,\n            timeline_estimate=timeline_estimate,\n            resource_requirements=resource_requirements\n        )\n        \n        # Get LLM-enhanced insights\n        executive_recommendation = self.processor.llm_processor.generate_executive_recommendation(initial_assessment)\n        competitive_analysis = self.processor.llm_processor.analyze_competitive_positioning(\n            self.modules, self.gaps, self.win_loss_factors\n        )\n        action_plan = self.processor.llm_processor.generate_action_plan(\n            self.gaps, [m for m in self.modules if m.status == \"Missing\"],\n            timeline_estimate, investment_required\n        )\n        \n        # Generate detailed rationale\n        detailed_rationale = f\"\"\"\n## Feasibility Analysis Details\n\n### Module Readiness\n- Total Modules: {total_modules}\n- Available: {available_modules} ({module_coverage:.1f}%)\n- Partial: {partial_modules} ({partial_modules/total_modules*100:.1f}%)\n- Missing: {missing_modules} ({missing_modules/total_modules*100:.1f}%)\n**AI Analysis:** {module_insights}\n\n### Requirements Coverage\n- Must-Have Requirements: {len(must_have_reqs)}\n- Met: {len(met_must_haves)} ({requirement_coverage:.1f}%)\n- Gaps: {len(unmet_must_haves)} requirements\n\n### Gap Assessment\n- Critical Gaps: {len(critical_gaps)}\n- Risks: {len(risks)}\n- Risk Area: {\"Technical\" if len(critical_gaps) > 2 else \"Delivery\" if module_coverage < 70 else \"Commercial\"}\n**AI Analysis:** {gap_insights}\n\n### Historical Performance\n- Win/Loss Ratio: {win_loss_ratio:.2f}\n- Success Factors: {len(win_factors)}\n- Challenges: {len(loss_factors)}\n**AI Analysis:** {win_loss_insights}\n\n### Investment & Timeline\n- Investment: {investment_required}\n- Timeline: {timeline_estimate}\n- Resources: {resource_requirements}\n\n### AI Action Plan:\n{action_plan}\n        \"\"\".strip()\n        \n        # Competitive positioning\n        competitive_positioning = f\"\"\"\n## Competitive Analysis\n\n{competitive_analysis}\n\n### Summary:\n- Market Position: {\"Strong\" if win_loss_ratio > 1.5 else \"Average\" if win_loss_ratio > 0.7 else \"Weak\"}\n- Differentiators: {', '.join([s[:30] + '...' for s in strengths[:3]]) if strengths else 'Limited differentiators'}\n- Gaps: {', '.join([w[:30] + '...' for w in weaknesses[:3]]) if weaknesses else 'No major gaps'}\n        \"\"\".strip()\n        \n        # Executive summary\n        executive_summary = f\"\"\"\n## RFP Response Feasibility Assessment\n\n**Decision: {\"GO - Proceed\" if can_respond else \"NO-GO - Do Not Proceed\"}**\n\n### Key Metrics:\n- Confidence: {confidence_score:.1f}%\n- Win Probability: {win_probability:.1f}%\n- Module Coverage: {module_coverage:.1f}%\n- Requirement Coverage: {requirement_coverage:.1f}%\n\n### Summary:\nAnalyzed {len(self.document_summaries)} documents ({sum(d['length'] for d in self.document_summaries.values())} characters):\n- Modules: {available_modules}/{total_modules} ({module_coverage:.0f}%)\n- Requirements: {len(met_must_haves)}/{len(must_have_reqs)} ({requirement_coverage:.0f}%)\n- Gaps: {len(critical_gaps)} critical, {len(medium_gaps)} medium, {len(low_gaps)} low\n- Win/Loss: Ratio {win_loss_ratio:.1f} ({len(self.win_loss_factors)} factors)\n\n### AI Recommendation:\n{executive_recommendation}\n\n### Next Steps:\n1. {required_actions[0][0] if required_actions else \"Proceed with RFP response\"}\n2. {required_actions[1][0] if len(required_actions) > 1 else \"Allocate resources\"}\n3. {required_actions[2][0] if len(required_actions) > 2 else \"Schedule review\"}\n        \"\"\".strip()\n        \n        # Update assessment\n        initial_assessment.executive_summary = executive_summary\n        initial_assessment.detailed_rationale = detailed_rationale\n        initial_assessment.competitive_positioning = competitive_positioning\n        return initial_assessment","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:48.271190Z","iopub.execute_input":"2025-07-29T15:48:48.271374Z","iopub.status.idle":"2025-07-29T15:48:48.303557Z","shell.execute_reply.started":"2025-07-29T15:48:48.271360Z","shell.execute_reply":"2025-07-29T15:48:48.302824Z"}},"outputs":[],"execution_count":176},{"cell_type":"code","source":"class RFPFeasibilityReportGenerator:\n    \"\"\"Generates comprehensive RFP feasibility report\"\"\"\n    \n    def __init__(self):\n        self.styles = getSampleStyleSheet()\n        self.title_style = ParagraphStyle(\n            'CustomTitle',\n            parent=self.styles['Heading1'],\n            fontSize=24,\n            spaceAfter=30,\n            alignment=TA_CENTER,\n            textColor=colors.HexColor('#1e3a8a')\n        )\n        self.heading_style = ParagraphStyle(\n            'CustomHeading',\n            parent=self.styles['Heading2'],\n            fontSize=16,\n            spaceAfter=12,\n            textColor=colors.HexColor('#1e3a8a')\n        )\n        self.subheading_style = ParagraphStyle(\n            'CustomSubheading',\n            parent=self.styles['Heading3'],\n            fontSize=13,\n            spaceAfter=8,\n            textColor=colors.HexColor('#1e3a8a')\n        )\n        \n    def create_go_no_go_decision(self, assessment: RFPFeasibilityAssessment) -> List:\n        \"\"\"Create GO/NO-GO decision section\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"GO / NO-GO Decision\", self.title_style))\n        elements.append(Spacer(1, 20))\n        \n        # Decision box\n        decision_color = colors.green if assessment.can_respond else colors.red\n        decision_text = \"GO - Proceed with RFP Response\" if assessment.can_respond else \"NO-GO - Do Not Proceed\"\n        \n        decision_data = [[Paragraph(decision_text, ParagraphStyle(\n            'Decision',\n            parent=self.styles['Heading1'],\n            fontSize=20,\n            alignment=TA_CENTER,\n            textColor=colors.white\n        ))]]\n        \n        decision_table = Table(decision_data, colWidths=[6*inch])\n        decision_table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, -1), decision_color),\n            ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n            ('TOPPADDING', (0, 0), (-1, -1), 20),\n            ('BOTTOMPADDING', (0, 0), (-1, -1), 20),\n            ('LEFTPADDING', (0, 0), (-1, -1), 10),\n            ('RIGHTPADDING', (0, 0), (-1, -1), 10),\n        ]))\n        \n        elements.append(decision_table)\n        elements.append(Spacer(1, 20))\n        \n        # Key metrics dashboard\n        metrics_data = [\n            ['Metric', 'Value', 'Status'],\n            ['Confidence Score', f\"{assessment.confidence_score:.1f}%\", \n             '✅' if assessment.confidence_score >= 70 else '⚠️' if assessment.confidence_score >= 50 else '❌'],\n            ['Win Probability', f\"{assessment.win_probability:.1f}%\",\n             '✅' if assessment.win_probability >= 60 else '⚠️' if assessment.win_probability >= 40 else '❌'],\n            ['Module Coverage', f\"{assessment.available_modules}/{assessment.total_modules} ({(assessment.available_modules/assessment.total_modules*100) if assessment.total_modules > 0 else 0:.0f}%)\",\n             '✅' if assessment.total_modules > 0 and assessment.available_modules/assessment.total_modules >= 0.7 else '⚠️' if assessment.total_modules > 0 and assessment.available_modules/assessment.total_modules >= 0.5 else '❌'],\n            ['Critical Gaps', str(len(assessment.critical_gaps)),\n             '✅' if len(assessment.critical_gaps) == 0 else '⚠️' if len(assessment.critical_gaps) <= 2 else '❌'],\n            ['Investment Required', assessment.investment_required.split(' + ')[0] if ' + ' in assessment.investment_required else assessment.investment_required[:30] + '...',\n             '✅' if 'Minimal' in assessment.investment_required else '⚠️'],\n        ]\n        \n        metrics_table = Table(metrics_data, colWidths=[2*inch, 3*inch, 1*inch])\n        metrics_table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1e3a8a')),\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n            ('GRID', (0, 0), (-1, -1), 1, colors.black),\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n            ('FONTNAME', (0, 1), (-1, -1), 'Helvetica'),\n            ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n            ('ALIGN', (2, 0), (2, -1), 'CENTER'),\n            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n            ('TOPPADDING', (0, 0), (-1, -1), 8),\n            ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f0f0f0')])\n        ]))\n        \n        elements.append(metrics_table)\n        elements.append(Spacer(1, 30))\n        \n        return elements\n    \n    def create_executive_summary(self, assessment: RFPFeasibilityAssessment) -> List:\n        \"\"\"Create executive summary with proper formatting\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"Executive Summary\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        \n        # Convert markdown-style formatting to ReportLab\n        summary_parts = assessment.executive_summary.split('\\n')\n        for part in summary_parts:\n            if part.startswith('##'):\n                # Main heading\n                clean_text = part.replace('##', '').strip()\n                elements.append(Paragraph(clean_text, self.subheading_style))\n            elif part.startswith('**') and part.endswith('**'):\n                # Bold text\n                clean_text = part.replace('**', '')\n                elements.append(Paragraph(clean_text, ParagraphStyle(\n                    'BoldText',\n                    parent=self.styles['Normal'],\n                    fontName='Helvetica-Bold',\n                    fontSize=11\n                )))\n            elif part.startswith('###'):\n                # Subheading\n                clean_text = part.replace('###', '').strip()\n                elements.append(Paragraph(clean_text, self.subheading_style))\n            elif part.startswith('-'):\n                # Bullet point\n                clean_text = '• ' + part[1:].strip()\n                elements.append(Paragraph(clean_text, self.styles['Normal']))\n            elif part.strip():\n                # Regular paragraph\n                elements.append(Paragraph(part.strip(), self.styles['Normal']))\n            \n            if part.strip():\n                elements.append(Spacer(1, 6))\n        \n        elements.append(Spacer(1, 20))\n        return elements\n    \n    def create_module_analysis_section(self, modules: List[ModuleMapping], assessment: RFPFeasibilityAssessment) -> List:\n        \"\"\"Create detailed module analysis section\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"Module Analysis\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        \n        # Module summary\n        summary_text = f\"\"\"Total modules analyzed: {assessment.total_modules} | \n        Available: {assessment.available_modules} | \n        Partial: {assessment.partial_modules} | \n        Missing: {assessment.missing_modules}\"\"\"\n        \n        elements.append(Paragraph(summary_text, self.styles['Normal']))\n        elements.append(Spacer(1, 12))\n        \n        if modules:\n            # Create module table\n            module_data = [['Module Code', 'Module Name', 'Status', 'Priority', 'Coverage', 'Notes']]\n            \n            # Sort modules by status and priority\n            sorted_modules = sorted(modules, key=lambda x: (\n                0 if x.status == \"Missing\" else 1 if x.status == \"Partial\" else 2,\n                0 if x.client_priority == \"High\" else 1 if x.client_priority == \"Medium\" else 2\n            ))\n            \n            for module in sorted_modules[:20]:  # Limit to top 20 for space\n                status_color = colors.green if module.status == \"Available\" else colors.orange if module.status == \"Partial\" else colors.red if module.status == \"Missing\" else colors.grey\n                \n                # Ensure module name is complete and readable\n                module_name = module.module_name\n                if len(module_name) > 40:\n                    module_name = module_name[:37] + \"...\"\n                \n                # Clean up notes\n                notes = module.notes\n                if len(notes) > 60:\n                    notes = notes[:57] + \"...\"\n                \n                module_data.append([\n                    module.module_code,\n                    Paragraph(module_name, self.styles['Normal']),\n                    Paragraph(module.status, ParagraphStyle('Status', parent=self.styles['Normal'], textColor=status_color, fontSize=8)),\n                    module.client_priority,\n                    f\"{module.coverage_percentage:.0f}%\",\n                    Paragraph(notes, ParagraphStyle('Notes', parent=self.styles['Normal'], fontSize=8))\n                ])\n            \n            module_table = Table(module_data, colWidths=[0.8*inch, 1.5*inch, 0.8*inch, 0.7*inch, 0.7*inch, 2*inch])\n            module_table.setStyle(TableStyle([\n                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1e3a8a')),\n                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n                ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),\n                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n                ('FONTSIZE', (0, 0), (-1, -1), 8),\n                ('VALIGN', (0, 0), (-1, -1), 'TOP'),\n                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f5f5f5')])\n            ]))\n            \n            elements.append(module_table)\n            \n            if len(modules) > 20:\n                elements.append(Spacer(1, 6))\n                elements.append(Paragraph(f\"Note: Showing 20 of {len(modules)} modules. See appendix for complete list.\", \n                                        ParagraphStyle('Note', parent=self.styles['Normal'], fontSize=8, textColor=colors.grey)))\n        \n        elements.append(Spacer(1, 20))\n        return elements\n    \n    def create_gap_analysis_section(self, assessment: RFPFeasibilityAssessment) -> List:\n        \"\"\"Create enhanced gap analysis section\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"Gap Analysis\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        \n        # Gap summary by severity\n        gap_summary = f\"\"\"Critical Gaps: {len([g for g in assessment.all_gaps if g.severity == 'Critical'])} | \n        High: {len([g for g in assessment.all_gaps if g.severity == 'High'])} | \n        Medium: {len([g for g in assessment.all_gaps if g.severity == 'Medium'])} | \n        Low: {len([g for g in assessment.all_gaps if g.severity == 'Low'])}\"\"\"\n        \n        elements.append(Paragraph(gap_summary, self.styles['Normal']))\n        elements.append(Spacer(1, 12))\n        \n        if assessment.all_gaps:\n            gap_data = [['Type', 'Description', 'Severity', 'Impact', 'Mitigation', 'Effort']]\n            \n            # Sort by severity\n            severity_order = {'Critical': 0, 'High': 1, 'Medium': 2, 'Low': 3}\n            sorted_gaps = sorted(assessment.all_gaps, key=lambda x: severity_order.get(x.severity, 4))\n            \n            for gap in sorted_gaps[:15]:  # Top 15 gaps\n                severity_color = colors.red if gap.severity == 'Critical' else colors.orange if gap.severity == 'High' else colors.yellow if gap.severity == 'Medium' else colors.green\n                \n                gap_data.append([\n                    gap.gap_type,\n                    Paragraph(gap.description[:60] + '...' if len(gap.description) > 60 else gap.description, self.styles['Normal']),\n                    Paragraph(gap.severity, ParagraphStyle('Severity', parent=self.styles['Normal'], textColor=severity_color, fontName='Helvetica-Bold')),\n                    Paragraph(gap.business_impact[:40] + '...' if len(gap.business_impact) > 40 else gap.business_impact, self.styles['Normal']),\n                    Paragraph(gap.mitigation_strategy[:50] + '...' if len(gap.mitigation_strategy) > 50 else gap.mitigation_strategy, self.styles['Normal']),\n                    gap.effort_required\n                ])\n            \n            gap_table = Table(gap_data, colWidths=[0.8*inch, 1.8*inch, 0.7*inch, 1.2*inch, 1.5*inch, 0.7*inch])\n            gap_table.setStyle(TableStyle([\n                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1e3a8a')),\n                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n                ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),\n                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n                ('FONTSIZE', (0, 0), (-1, -1), 8),\n                ('VALIGN', (0, 0), (-1, -1), 'TOP'),\n                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f5f5f5')])\n            ]))\n            \n            elements.append(gap_table)\n        else:\n            elements.append(Paragraph(\"No gaps identified in the analysis.\", self.styles['Normal']))\n        \n        elements.append(Spacer(1, 20))\n        return elements\n\n    def create_swot_analysis(self, assessment: RFPFeasibilityAssessment) -> List:\n        \"\"\"Create SWOT analysis section with size constraints\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"SWOT Analysis\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        \n        swot_style = ParagraphStyle(\n            'SWOT',\n            parent=self.styles['Normal'],\n            fontSize=9,\n            leading=12,\n            spaceAfter=4\n        )\n        \n        # Helper function to format SWOT items\n        def format_items(items, title, max_items=4, max_length=100):\n            content = [Paragraph(f\"<b>{title}</b>\", swot_style), Spacer(1, 6)]\n            for i, item in enumerate(items[:max_items], 1):\n                if item:\n                    text = item[:max_length] + ('...' if len(item) > max_length else '')\n                    content.append(Paragraph(f\"{i}. {text}\", swot_style))\n                    content.append(Spacer(1, 4))\n            return content\n        \n        # Create SWOT content\n        strengths_content = format_items(assessment.strengths, \"STRENGTHS\")\n        weaknesses_content = format_items(assessment.weaknesses, \"WEAKNESSES\")\n        opportunities_content = format_items(assessment.opportunities, \"OPPORTUNITIES\")\n        threats_content = format_items(assessment.threats, \"THREATS\")\n        \n        # Create 2x2 SWOT grid\n        swot_data = [\n            [strengths_content, weaknesses_content],\n            [opportunities_content, threats_content]\n        ]\n        \n        swot_table = Table(swot_data, colWidths=[3*inch, 3*inch])\n        swot_table.setStyle(TableStyle([\n            ('GRID', (0, 0), (-1, -1), 2, colors.HexColor('#1e3a8a')),\n            ('VALIGN', (0, 0), (-1, -1), 'TOP'),\n            ('BACKGROUND', (0, 0), (0, 0), colors.HexColor('#e8f5e9')),  # Green for strengths\n            ('BACKGROUND', (1, 0), (1, 0), colors.HexColor('#ffebee')),  # Red for weaknesses\n            ('BACKGROUND', (0, 1), (0, 1), colors.HexColor('#e3f2fd')),  # Blue for opportunities\n            ('BACKGROUND', (1, 1), (1, 1), colors.HexColor('#fff3e0')),  # Orange for threats\n            ('TOPPADDING', (0, 0), (-1, -1), 12),\n            ('BOTTOMPADDING', (0, 0), (-1, -1), 12),\n            ('LEFTPADDING', (0, 0), (-1, -1), 12),\n            ('RIGHTPADDING', (0, 0), (-1, -1), 12),\n        ]))\n        \n        elements.append(swot_table)\n        if any(len(items) > 4 for items in [assessment.strengths, assessment.weaknesses, assessment.opportunities, assessment.threats]):\n            elements.append(Spacer(1, 6))\n            elements.append(Paragraph(\"Note: Additional SWOT items available in appendix.\", \n                                     ParagraphStyle('Note', parent=self.styles['Normal'], fontSize=8, textColor=colors.grey)))\n        \n        elements.append(Spacer(1, 20))\n        return elements\n        \n    def create_action_plan(self, assessment: RFPFeasibilityAssessment) -> List:\n        \"\"\"Create detailed action plan\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"Action Plan\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        \n        if assessment.required_actions:\n            action_data = [['#', 'Action', 'Priority', 'Timeline', 'Owner']]\n            \n            for i, (action, priority, timeline, owner) in enumerate(assessment.required_actions[:10], 1):\n                priority_color = colors.red if priority == 'Critical' else colors.orange if priority == 'High' else colors.black\n                \n                action_data.append([\n                    str(i),\n                    Paragraph(action, self.styles['Normal']),\n                    Paragraph(priority, ParagraphStyle('Priority', parent=self.styles['Normal'], \n                                                       textColor=priority_color, fontName='Helvetica-Bold')),\n                    timeline,\n                    owner\n                ])\n            \n            action_table = Table(action_data, colWidths=[0.3*inch, 3.2*inch, 0.8*inch, 1*inch, 1.2*inch])\n            action_table.setStyle(TableStyle([\n                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1e3a8a')),\n                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n                ('GRID', (0, 0), (-1, -1), 1, colors.black),\n                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n                ('FONTSIZE', (0, 0), (-1, -1), 9),\n                ('VALIGN', (0, 0), (-1, -1), 'TOP'),\n                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f0f0f0')])\n            ]))\n            \n            elements.append(action_table)\n        else:\n            elements.append(Paragraph(\"No immediate actions required.\", self.styles['Normal']))\n        \n        elements.append(Spacer(1, 20))\n        return elements\n    \n    def create_risk_assessment_section(self, assessment: RFPFeasibilityAssessment) -> List:\n        \"\"\"Create risk assessment section\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"Risk Assessment\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        \n        if assessment.risks:\n            risk_data = [['Risk Type', 'Description', 'Probability', 'Impact', 'Mitigation']]\n            \n            for risk in assessment.risks:\n                prob_color = colors.red if risk.probability == 'High' else colors.orange if risk.probability == 'Medium' else colors.green\n                impact_color = colors.red if risk.impact == 'High' else colors.orange if risk.impact == 'Medium' else colors.green\n                \n                risk_data.append([\n                    risk.risk_type,\n                    Paragraph(risk.description[:80] + '...' if len(risk.description) > 80 else risk.description, self.styles['Normal']),\n                    Paragraph(risk.probability, ParagraphStyle('Risk', parent=self.styles['Normal'], textColor=prob_color)),\n                    Paragraph(risk.impact, ParagraphStyle('Risk', parent=self.styles['Normal'], textColor=impact_color)),\n                    Paragraph(risk.mitigation_plan[:60] + '...' if len(risk.mitigation_plan) > 60 else risk.mitigation_plan, self.styles['Normal'])\n                ])\n            \n            risk_table = Table(risk_data, colWidths=[0.8*inch, 2.3*inch, 0.8*inch, 0.8*inch, 1.8*inch])\n            risk_table.setStyle(TableStyle([\n                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1e3a8a')),\n                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n                ('GRID', (0, 0), (-1, -1), 1, colors.black),\n                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n                ('FONTSIZE', (0, 0), (-1, -1), 9),\n                ('VALIGN', (0, 0), (-1, -1), 'TOP'),\n                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f0f0f0')])\n            ]))\n            \n            elements.append(risk_table)\n        else:\n            elements.append(Paragraph(\"No significant risks identified.\", self.styles['Normal']))\n        \n        elements.append(Spacer(1, 20))\n        return elements\n    \n    def create_investment_timeline_section(self, assessment: RFPFeasibilityAssessment) -> List:\n        \"\"\"Create investment and timeline section\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"Investment & Timeline\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        \n        inv_time_data = [\n            ['Aspect', 'Details'],\n            ['Investment Required', assessment.investment_required],\n            ['Timeline Estimate', assessment.timeline_estimate],\n            ['Resource Requirements', assessment.resource_requirements],\n            ['ROI Expectation', 'Positive ROI within 6-12 months post-implementation'],\n            ['Critical Path', 'Module development → Gap mitigation → Integration testing']\n        ]\n        \n        inv_table = Table(inv_time_data, colWidths=[2*inch, 4*inch])\n        inv_table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1e3a8a')),\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n            ('GRID', (0, 0), (-1, -1), 1, colors.black),\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n            ('FONTNAME', (0, 1), (0, -1), 'Helvetica-Bold'),\n            ('VALIGN', (0, 0), (-1, -1), 'TOP'),\n            ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f0f0f0')])\n        ]))\n        \n        elements.append(inv_table)\n        elements.append(Spacer(1, 20))\n        return elements\n    \n    def create_win_loss_analysis_section(self, factors: List[WinLossFactor]) -> List:\n        \"\"\"Create win/loss analysis section\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"Historical Win/Loss Analysis\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        \n        # Separate win and loss factors\n        win_factors = [f for f in factors if f.factor_type == 'Win']\n        loss_factors = [f for f in factors if f.factor_type == 'Loss']\n        \n        # Summary\n        summary_text = f\"Based on {len(factors)} historical factors: {len(win_factors)} win factors, {len(loss_factors)} loss factors\"\n        elements.append(Paragraph(summary_text, self.styles['Normal']))\n        elements.append(Spacer(1, 12))\n        \n        # Win factors\n        if win_factors:\n            elements.append(Paragraph(\"Key Success Factors\", self.subheading_style))\n            elements.append(Spacer(1, 8))\n            \n            for i, factor in enumerate(win_factors[:5], 1):\n                elements.append(Paragraph(f\"{i}. [{factor.category}] {factor.description}\", self.styles['Normal']))\n                elements.append(Spacer(1, 4))\n        \n        elements.append(Spacer(1, 8))\n        \n        # Loss factors\n        if loss_factors:\n            elements.append(Paragraph(\"Common Loss Factors\", self.subheading_style))\n            elements.append(Spacer(1, 8))\n            \n            for i, factor in enumerate(loss_factors[:5], 1):\n                elements.append(Paragraph(f\"{i}. [{factor.category}] {factor.description}\", self.styles['Normal']))\n                elements.append(Spacer(1, 4))\n        \n        elements.append(Spacer(1, 20))\n        return elements\n    \n    def create_requirements_coverage_section(self, requirements: List[Requirement]) -> List:\n        \"\"\"Create requirements coverage section\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"Requirements Coverage Analysis\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        \n        if requirements:\n            # Group by priority\n            must_haves = [r for r in requirements if r.priority == 'Must Have']\n            nice_to_haves = [r for r in requirements if r.priority == 'Nice to Have']\n            optionals = [r for r in requirements if r.priority == 'Optional']\n            \n            # Summary\n            summary_text = f\"Total Requirements: {len(requirements)} | Must Have: {len(must_haves)} | Nice to Have: {len(nice_to_haves)} | Optional: {len(optionals)}\"\n            elements.append(Paragraph(summary_text, self.styles['Normal']))\n            elements.append(Spacer(1, 12))\n            \n            # Requirements table\n            req_data = [['ID', 'Type', 'Description', 'Priority', 'Our Capability', 'Gap']]\n            \n            # Sort by priority and capability\n            sorted_reqs = sorted(requirements, key=lambda x: (\n                0 if x.priority == 'Must Have' else 1 if x.priority == 'Nice to Have' else 2,\n                0 if x.our_capability == 'None' else 1 if x.our_capability == 'Partial' else 2\n            ))\n            \n            for req in sorted_reqs[:15]:  # Top 15 requirements\n                capability_color = colors.green if req.our_capability == 'Full' else colors.orange if req.our_capability == 'Partial' else colors.red if req.our_capability == 'None' else colors.blue\n                \n                req_data.append([\n                    req.requirement_type[:8],\n                    Paragraph(req.description[:50] + '...' if len(req.description) > 50 else req.description, self.styles['Normal']),\n                    req.priority,\n                    Paragraph(req.our_capability, ParagraphStyle('Cap', parent=self.styles['Normal'], textColor=capability_color))\n                ])\n            \n            req_table = Table(req_data, colWidths=[0.6*inch, 0.8*inch, 2.5*inch, 0.9*inch, 1*inch, 0.5*inch])\n            req_table.setStyle(TableStyle([\n                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1e3a8a')),\n                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n                ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),\n                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n                ('FONTSIZE', (0, 0), (-1, -1), 8),\n                ('VALIGN', (0, 0), (-1, -1), 'TOP'),\n                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f5f5f5')])\n            ]))\n            \n            elements.append(req_table)\n        else:\n            elements.append(Paragraph(\"No requirements identified in the analysis.\", self.styles['Normal']))\n        \n        elements.append(Spacer(1, 20))\n        return elements\n    \n    def create_detailed_rationale_section(self, assessment: RFPFeasibilityAssessment) -> List:\n        \"\"\"Create detailed rationale section\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"Detailed Analysis Rationale\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        \n        # Convert markdown-style formatting\n        rationale_parts = assessment.detailed_rationale.split('\\n')\n        for part in rationale_parts:\n            if part.startswith('##'):\n                clean_text = part.replace('##', '').strip()\n                elements.append(Paragraph(clean_text, self.subheading_style))\n            elif part.startswith('###'):\n                clean_text = part.replace('###', '').strip()\n                elements.append(Paragraph(clean_text, ParagraphStyle(\n                    'SubSubHeading',\n                    parent=self.styles['Normal'],\n                    fontName='Helvetica-Bold',\n                    fontSize=10\n                )))\n            elif part.startswith('-'):\n                clean_text = '• ' + part[1:].strip()\n                elements.append(Paragraph(clean_text, self.styles['Normal']))\n            elif part.strip():\n                elements.append(Paragraph(part.strip(), self.styles['Normal']))\n            \n            if part.strip():\n                elements.append(Spacer(1, 4))\n        \n        elements.append(Spacer(1, 20))\n        return elements\n    \n    def create_appendix(self, analyzer: RFPFeasibilityAnalyzer) -> List:\n        \"\"\"Create appendix with additional details\"\"\"\n        elements = []\n        \n        elements.append(PageBreak())\n        elements.append(Paragraph(\"Appendix\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        \n        # Document analysis summary\n        elements.append(Paragraph(\"Document Analysis Summary\", self.subheading_style))\n        elements.append(Spacer(1, 8))\n        \n        doc_data = [['Document Type', 'Size (chars)', 'Sentences', 'Key Findings']]\n        for doc_type, summary in analyzer.document_summaries.items():\n            doc_data.append([\n                doc_type.replace('_', ' ').title(),\n                f\"{summary['length']:,}\",\n                str(summary['sentences']),\n                f\"{len(analyzer.modules if doc_type == 'module_matching' else analyzer.gaps if doc_type == 'gap_analysis' else analyzer.requirements if doc_type == 'customer_needs' else analyzer.win_loss_factors)} items extracted\"\n            ])\n        \n        doc_table = Table(doc_data, colWidths=[1.5*inch, 1*inch, 1*inch, 2.5*inch])\n        doc_table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n            ('GRID', (0, 0), (-1, -1), 1, colors.black),\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n            ('FONTSIZE', (0, 0), (-1, -1), 9),\n            ('VALIGN', (0, 0), (-1, -1), 'TOP')\n        ]))\n        \n        elements.append(doc_table)\n        elements.append(Spacer(1, 20))\n        \n        # Methodology note\n        elements.append(Paragraph(\"Analysis Methodology\", self.subheading_style))\n        elements.append(Spacer(1, 8))\n        methodology_text = \"\"\"\n        This feasibility assessment was generated using advanced text analysis and pattern recognition \n        techniques to extract structured information from unstructured documents. The analysis includes:\n        \n        • Module mapping and coverage assessment\n        • Gap identification and severity classification\n        • Requirements extraction and capability matching\n        • Historical win/loss factor analysis\n        • Risk assessment and mitigation planning\n        • Investment and timeline estimation\n        \n        Confidence scores are calculated based on weighted factors including module coverage, \n        requirement fulfillment, gap severity, and historical performance metrics.\n        \"\"\"\n        elements.append(Paragraph(methodology_text.strip(), self.styles['Normal']))\n        \n        return elements\n    \n    def create_ai_insights_section(self, assessment: RFPFeasibilityAssessment, analyzer: RFPFeasibilityAnalyzer) -> List:\n        \"\"\"Create AI insights section\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"AI-Generated Strategic Insights\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        \n        # Document-level insights if available\n        if any('llm_summary' in summary for summary in analyzer.document_summaries.values()):\n            elements.append(Paragraph(\"Document Analysis Insights\", self.subheading_style))\n            elements.append(Spacer(1, 8))\n            \n            for doc_type, summary in analyzer.document_summaries.items():\n                if 'llm_summary' in summary:\n                    elements.append(Paragraph(f\"<b>{doc_type.replace('_', ' ').title()}:</b>\", self.styles['Normal']))\n                    elements.append(Spacer(1, 4))\n                    \n                    # Format the LLM summary nicely\n                    insights_text = summary['llm_summary']\n                    if len(insights_text) > 500:\n                        insights_text = insights_text[:497] + \"...\"\n                    \n                    elements.append(Paragraph(insights_text, ParagraphStyle(\n                        'AIInsight',\n                        parent=self.styles['Normal'],\n                        fontSize=9,\n                        leftIndent=20,\n                        rightIndent=20,\n                        textColor=colors.HexColor('#333333')\n                    )))\n                    elements.append(Spacer(1, 12))\n        \n        # Strategic recommendations from detailed rationale\n        if \"AI Module Analysis:\" in assessment.detailed_rationale:\n            elements.append(Paragraph(\"Strategic Analysis\", self.subheading_style))\n            elements.append(Spacer(1, 8))\n            \n            # Extract AI sections from detailed rationale\n            rationale_parts = assessment.detailed_rationale.split('\\n')\n            capture_ai = False\n            ai_content = []\n            \n            for part in rationale_parts:\n                if \"AI\" in part and (\"Analysis:\" in part or \"Plan:\" in part):\n                    capture_ai = True\n                    ai_content.append(Paragraph(f\"<b>{part.strip()}</b>\", self.styles['Normal']))\n                elif capture_ai and part.strip() and not part.startswith('#'):\n                    ai_content.append(Paragraph(part.strip(), ParagraphStyle(\n                        'AIContent',\n                        parent=self.styles['Normal'],\n                        fontSize=9,\n                        leftIndent=10\n                    )))\n                elif part.startswith('#'):\n                    capture_ai = False\n            \n            for element in ai_content[:10]:  # Limit to prevent too long\n                elements.append(element)\n                elements.append(Spacer(1, 4))\n        \n        elements.append(Spacer(1, 20))\n        return elements\n    \n    def generate_report(self, analyzer: RFPFeasibilityAnalyzer, assessment: RFPFeasibilityAssessment, output_path: str):\n        \"\"\"Generate complete feasibility report\"\"\"\n        doc = SimpleDocTemplate(\n            output_path, \n            pagesize=A4,\n            topMargin=0.75*inch,\n            bottomMargin=0.75*inch,\n            leftMargin=0.75*inch,\n            rightMargin=0.75*inch\n        )\n        elements = []\n        \n        # Title page\n        elements.append(Spacer(1, 1*inch))\n        elements.append(Paragraph(\"RFP Response Feasibility Analysis\", self.title_style))\n        elements.append(Spacer(1, 20))\n        elements.append(Paragraph(f\"Generated on {datetime.now().strftime('%B %d, %Y at %I:%M %p')}\", \n                                  ParagraphStyle('DateStyle', parent=self.styles['Normal'], alignment=TA_CENTER)))\n        elements.append(Spacer(1, 40))\n        \n        # Add document count summary\n        doc_count = len(analyzer.document_summaries)\n        total_chars = sum(d['length'] for d in analyzer.document_summaries.values())\n        elements.append(Paragraph(f\"Analysis based on {doc_count} documents containing {total_chars:,} characters\", \n                                  ParagraphStyle('Summary', parent=self.styles['Normal'], alignment=TA_CENTER, fontSize=10)))\n        elements.append(PageBreak())\n        \n        # Table of Contents\n        elements.append(Paragraph(\"Table of Contents\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        toc_items = [\n            \"1. GO/NO-GO Decision\",\n            \"2. Executive Summary\",\n            \"3. AI-Generated Strategic Insights\",\n            \"4. Module Analysis\",\n            \"5. Gap Analysis\",\n            \"6. Requirements Coverage\",\n            \"7. Historical Win/Loss Analysis\",\n            \"8. SWOT Analysis\",\n            \"9. Risk Assessment\",\n            \"10. Action Plan\",\n            \"11. Investment & Timeline\",\n            \"12. Detailed Rationale\",\n            \"13. Competitive Positioning\",\n            \"14. Appendix\"\n        ]\n        for item in toc_items:\n            elements.append(Paragraph(item, self.styles['Normal']))\n            elements.append(Spacer(1, 6))\n        elements.append(PageBreak())\n        \n        # Main sections\n        elements.extend(self.create_go_no_go_decision(assessment))\n        elements.append(PageBreak())\n        \n        elements.extend(self.create_executive_summary(assessment))\n        \n        # Add AI insights section\n        elements.extend(self.create_ai_insights_section(assessment, analyzer))\n        \n        elements.extend(self.create_module_analysis_section(analyzer.modules, assessment))\n        \n        elements.extend(self.create_gap_analysis_section(assessment))\n        \n        elements.extend(self.create_requirements_coverage_section(analyzer.requirements))\n        \n        elements.extend(self.create_win_loss_analysis_section(analyzer.win_loss_factors))\n        \n        elements.extend(self.create_swot_analysis(assessment))\n        \n        elements.extend(self.create_risk_assessment_section(assessment))\n        \n        elements.extend(self.create_action_plan(assessment))\n        \n        elements.extend(self.create_investment_timeline_section(assessment))\n        \n        elements.extend(self.create_detailed_rationale_section(assessment))\n        \n        # Competitive positioning\n        elements.append(Paragraph(\"Competitive Positioning\", self.heading_style))\n        elements.append(Spacer(1, 12))\n        elements.append(Paragraph(assessment.competitive_positioning, self.styles['Normal']))\n        elements.append(Spacer(1, 20))\n        \n        # Appendix\n        elements.extend(self.create_appendix(analyzer))\n        \n        # Build PDF\n        try:\n            doc.build(elements)\n            print(f\"✅ RFP Feasibility Report generated successfully: {output_path}\")\n        except Exception as e:\n            print(f\"❌ Error generating PDF: {e}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:48.304816Z","iopub.execute_input":"2025-07-29T15:48:48.305051Z","iopub.status.idle":"2025-07-29T15:48:48.381659Z","shell.execute_reply.started":"2025-07-29T15:48:48.305025Z","shell.execute_reply":"2025-07-29T15:48:48.380907Z"}},"outputs":[],"execution_count":177},{"cell_type":"code","source":"class RFPResponseGenerator:\n    \"\"\"Generates comprehensive RFP responses based on feasibility analysis\"\"\"\n    \n    def __init__(self, llm_processor: LLMProcessor):\n        self.llm_processor = llm_processor\n        \n    def generate_technical_proposal(self, modules: List[ModuleMapping], gaps: List[GapItem], \n                                  requirements: List[Requirement]) -> TechnicalProposal:\n        \"\"\"Generate detailed technical proposal with improved structure\"\"\"\n        \n        # Categorize modules for better presentation\n        available_modules = [m for m in modules if m.status == \"Available\"]\n        partial_modules = [m for m in modules if m.status == \"Partial\"]\n        missing_modules = [m for m in modules if m.status == \"Missing\"]\n        \n        # Enhanced Solution Overview\n        solution_prompt = f\"\"\"\n        Create a professional solution overview for an RFP response. Our capabilities include:\n        \n        AVAILABLE MODULES ({len(available_modules)}):\n        {chr(10).join([f'- {m.module_name}: {m.notes.split(\"|\")[0] if \"|\" in m.notes else m.notes[:60]}' for m in available_modules])}\n        \n        MODULES REQUIRING DEVELOPMENT ({len(missing_modules)}):\n        {chr(10).join([f'- {m.module_name}' for m in missing_modules])}\n        \n        CLIENT REQUIREMENTS:\n        {chr(10).join([f'- {r.description[:80]}' for r in requirements[:3]])}\n        \n        Write a compelling solution overview (200-250 words) that:\n        1. Positions our existing capabilities as competitive advantages\n        2. Demonstrates understanding of client needs\n        3. Shows how we'll address any gaps\n        4. Emphasizes our technical expertise and proven approach\n        \"\"\"\n        solution_overview = self.llm_processor._generate_text(solution_prompt, 500)\n        \n        # Enhanced Technical Architecture\n        arch_prompt = f\"\"\"\n        Design a comprehensive technical architecture description for our solution:\n        \n        CORE SYSTEM COMPONENTS:\n        - {len(available_modules)} proven modules ready for deployment\n        - {len(partial_modules)} modules requiring customization\n        - {len(missing_modules)} new modules for development\n        \n        INTEGRATION REQUIREMENTS:\n        - Seamless data flow between all modules\n        - API-first architecture for extensibility\n        - Cloud-native deployment with on-premise options\n        \n        Write a technical architecture section (180-220 words) covering:\n        1. High-level system design and component interaction\n        2. Data management and storage strategy\n        3. Security and performance considerations\n        4. Technology stack and frameworks\n        \"\"\"\n        technical_architecture = self.llm_processor._generate_text(arch_prompt, 450)\n        \n        # Enhanced Implementation Approach\n        total_complexity_score = len(missing_modules) * 3 + len(partial_modules) * 1.5 + len([g for g in gaps if g.severity == 'High']) * 2\n        \n        impl_prompt = f\"\"\"\n        Create a structured implementation approach for a project with complexity score {total_complexity_score:.1f}:\n        \n        PROJECT SCOPE:\n        - Configure {len(available_modules)} existing modules\n        - Customize {len(partial_modules)} partial modules  \n        - Develop {len(missing_modules)} new modules from scratch\n        - Address {len([g for g in gaps if g.severity in ['High', 'Critical']])} critical gaps\n        \n        Write an implementation approach (160-200 words) with:\n        1. Phased delivery strategy (3-4 phases)\n        2. Risk mitigation through proven methodologies\n        3. Quality assurance at each milestone\n        4. Client collaboration and feedback loops\n        \"\"\"\n        implementation_approach = self.llm_processor._generate_text(impl_prompt, 400)\n        \n        # Enhanced Integration Strategy\n        integration_prompt = f\"\"\"\n        Define integration strategy for a solution connecting {len(modules)} modules:\n        \n        INTEGRATION CHALLENGES:\n        - Data format standardization across modules\n        - Real-time synchronization requirements\n        - Legacy system compatibility\n        - Third-party API integration\n        \n        Write integration strategy (120-150 words) addressing:\n        1. API design principles and standards\n        2. Data transformation and validation\n        3. Error handling and monitoring\n        4. Performance optimization techniques\n        \"\"\"\n        integration_strategy = self.llm_processor._generate_text(integration_prompt, 300)\n        \n        # Enhanced Security Framework\n        security_prompt = f\"\"\"\n        Design enterprise security framework for a solution handling sensitive data:\n        \n        SECURITY REQUIREMENTS:\n        - Multi-layer security architecture\n        - Compliance with industry standards (ISO 27001, SOC 2)\n        - Data encryption at rest and in transit\n        - Role-based access control\n        \n        Write security framework description (140-170 words) covering:\n        1. Authentication and authorization mechanisms\n        2. Data protection and privacy controls\n        3. Security monitoring and incident response\n        4. Compliance and audit capabilities\n        \"\"\"\n        security_framework = self.llm_processor._generate_text(security_prompt, 350)\n        \n        # Enhanced Performance Specifications\n        perf_specs = f\"\"\"\n        **Performance Specifications & Commitments:**\n        \n        **Response Time Performance:**\n        - Standard Operations: < 1.5 seconds (target: 1.2 seconds)\n        - Complex Queries: < 3.0 seconds (target: 2.5 seconds)\n        - Report Generation: < 5.0 seconds for standard reports\n        \n        **Scalability & Capacity:**\n        - Concurrent Users: 2,000+ simultaneous users (scalable to 5,000+)\n        - Data Processing: 15GB/hour sustained (burst to 25GB/hour)\n        - Storage Capacity: Petabyte-scale with auto-scaling\n        \n        **Availability & Reliability:**\n        - System Uptime: 99.95% with SLA guarantees\n        - Disaster Recovery: < 4 hours RTO, < 1 hour RPO\n        - Load Balancing: Auto-scaling based on demand\n        \n        **Quality Metrics:**\n        - Data Accuracy: 99.9% with validation checks\n        - Security Response: < 15 minutes for critical incidents\n        - Backup Frequency: Continuous with point-in-time recovery\n        \"\"\"\n        \n        # Enhanced Testing Methodology\n        testing_methodology = f\"\"\"\n        **Comprehensive Testing Framework:**\n        \n        **Phase 1: Foundation Testing**\n        - Unit Testing: 90%+ code coverage for all modules\n        - Component Testing: Individual module validation\n        - Integration Testing: API and data flow verification\n        \n        **Phase 2: System Testing**\n        - Performance Testing: Load testing with 150% expected capacity\n        - Security Testing: Penetration testing and vulnerability assessment\n        - Compatibility Testing: Cross-platform and browser validation\n        \n        **Phase 3: Acceptance Testing**\n        - User Acceptance Testing: Client-driven scenario validation\n        - Regression Testing: Automated test suite execution\n        - Production Readiness: Go-live checklist verification\n        \n        **Continuous Quality Assurance:**\n        - Automated Testing: CI/CD pipeline integration\n        - Code Review: Peer review for all changes\n        - Quality Gates: Mandatory checkpoints at each phase\n        \"\"\"\n        \n        # Enhanced Deployment Strategy\n        deployment_prompt = f\"\"\"\n        Create deployment strategy for enterprise solution with {len(modules)} modules:\n        \n        DEPLOYMENT CONSIDERATIONS:\n        - Minimal business disruption during rollout\n        - Rollback capabilities for risk mitigation\n        - Production monitoring and alerting\n        - User training and change management\n        \n        Write deployment strategy (130-160 words) including:\n        1. Blue-green deployment approach\n        2. Phased rollout with pilot groups\n        3. Monitoring and health checks\n        4. Post-deployment support procedures\n        \"\"\"\n        deployment_strategy = self.llm_processor._generate_text(deployment_prompt, 320)\n        \n        return TechnicalProposal(\n            solution_overview=solution_overview or \"Our comprehensive solution leverages proven modules and industry expertise to deliver exceptional value and performance.\",\n            technical_architecture=technical_architecture or \"Scalable, cloud-native architecture designed for enterprise-grade performance, security, and reliability.\",\n            implementation_approach=implementation_approach or \"Agile, phased implementation approach ensuring minimal risk and maximum value delivery at each milestone.\",\n            integration_strategy=integration_strategy or \"API-first integration strategy ensuring seamless data flow and system interoperability.\",\n            security_framework=security_framework or \"Multi-layered security framework with enterprise-grade encryption, access controls, and compliance capabilities.\",\n            performance_specifications=perf_specs,\n            testing_methodology=testing_methodology,\n            deployment_strategy=deployment_strategy or \"Blue-green deployment strategy with comprehensive monitoring and rollback capabilities.\"\n        )\n    \n    def generate_financial_proposal(self, modules: List[ModuleMapping], gaps: List[GapItem], \n                                  assessment: RFPFeasibilityAssessment) -> FinancialProposal:\n        \"\"\"Generate detailed financial proposal\"\"\"\n        \n        # Calculate costs based on modules and gaps\n        available_modules = [m for m in modules if m.status == \"Available\"]\n        partial_modules = [m for m in modules if m.status == \"Partial\"]\n        missing_modules = [m for m in modules if m.status == \"Missing\"]\n        critical_gaps = [g for g in gaps if g.severity in ['High', 'Critical']]\n        \n        # Base cost calculation\n        base_cost = len(available_modules) * 10000  # $10K per existing module\n        development_cost = len(missing_modules) * 75000  # $75K per new module\n        customization_cost = len(partial_modules) * 25000  # $25K per partial module\n        gap_resolution_cost = len(critical_gaps) * 15000  # $15K per critical gap\n        \n        total_project_cost = base_cost + development_cost + customization_cost + gap_resolution_cost\n        \n        # Cost breakdown\n        cost_breakdown = {\n            \"Existing Module Configuration\": f\"${base_cost:,}\",\n            \"New Module Development\": f\"${development_cost:,}\",\n            \"Module Customization\": f\"${customization_cost:,}\",\n            \"Gap Resolution\": f\"${gap_resolution_cost:,}\",\n            \"Project Management (15%)\": f\"${int(total_project_cost * 0.15):,}\",\n            \"Testing & QA (10%)\": f\"${int(total_project_cost * 0.10):,}\",\n            \"Training & Documentation (8%)\": f\"${int(total_project_cost * 0.08):,}\",\n            \"Contingency (5%)\": f\"${int(total_project_cost * 0.05):,}\"\n        }\n        \n        # Total with overhead\n        total_with_overhead = total_project_cost * 1.38  # 38% total overhead\n        \n        # Payment schedule\n        payment_schedule = f\"\"\"\n        Payment Schedule:\n        - Contract Signing: 20% (${int(total_with_overhead * 0.20):,})\n        - Design Approval: 25% (${int(total_with_overhead * 0.25):,})\n        - Development Milestone 1: 20% (${int(total_with_overhead * 0.20):,})\n        - Development Milestone 2: 20% (${int(total_with_overhead * 0.20):,})\n        - UAT Completion: 10% (${int(total_with_overhead * 0.10):,})\n        - Go-Live: 5% (${int(total_with_overhead * 0.05):,})\n        \"\"\"\n        \n        # ROI Analysis\n        roi_prompt = f\"\"\"\n        Calculate ROI for a ${int(total_with_overhead):,} investment that will:\n        - Improve efficiency by 30%\n        - Reduce operational costs by 20%\n        - Enable new revenue streams\n        \n        Provide ROI analysis (150 words) with specific metrics and timeframes.\n        \"\"\"\n        roi_analysis = self.llm_processor._generate_text(roi_prompt, 300)\n        \n        # Cost justification\n        cost_justification = f\"\"\"\n        Investment Justification:\n        This ${int(total_with_overhead):,} investment delivers:\n        - {len(available_modules)} proven, enterprise-ready modules\n        - {len(missing_modules)} custom-developed solutions\n        - Comprehensive testing and quality assurance\n        - Full documentation and training\n        - 12 months warranty and support\n        \n        Cost per module: ${int(total_with_overhead / max(len(modules), 1)):,}\n        Industry benchmark: 15-20% below market rates\n        \"\"\"\n        \n        # Pricing model\n        pricing_model = \"\"\"\n        Flexible Pricing Options:\n        1. Fixed Price: Total project cost with defined scope\n        2. Time & Materials: $150-200/hour for additional work\n        3. Milestone-based: Payments tied to deliverable completion\n        4. Hybrid: Fixed core + T&M for enhancements\n        \"\"\"\n        \n        # Maintenance costs\n        annual_maintenance = int(total_with_overhead * 0.18)  # 18% annually\n        maintenance_costs = f\"\"\"\n        Annual Maintenance & Support: ${annual_maintenance:,}\n        Includes:\n        - 24/7 technical support\n        - Software updates and patches\n        - Performance monitoring\n        - Security updates\n        - Documentation updates\n        \"\"\"\n        \n        # Optional services\n        optional_services = {\n            \"Advanced Analytics Module\": \"$45,000\",\n            \"Mobile Application\": \"$35,000\",\n            \"API Gateway Enhancement\": \"$25,000\",\n            \"Additional Training (per day)\": \"$2,500\",\n            \"Custom Reporting Engine\": \"$30,000\"\n        }\n        \n        return FinancialProposal(\n            total_cost=f\"${int(total_with_overhead):,}\",\n            cost_breakdown=cost_breakdown,\n            payment_schedule=payment_schedule,\n            roi_analysis=roi_analysis or \"Expected ROI of 250% within 24 months through efficiency gains.\",\n            cost_justification=cost_justification,\n            pricing_model=pricing_model,\n            maintenance_costs=maintenance_costs,\n            optional_services=optional_services\n        )\n    \n    def generate_project_timeline(self, modules: List[ModuleMapping], gaps: List[GapItem]) -> str:\n        \"\"\"Generate detailed project timeline\"\"\"\n        \n        missing_modules = [m for m in modules if m.status == \"Missing\"]\n        critical_gaps = [g for g in gaps if g.severity in ['High', 'Critical']]\n        \n        # Calculate timeline based on complexity\n        base_weeks = 12  # Base project duration\n        development_weeks = len(missing_modules) * 3  # 3 weeks per new module\n        gap_weeks = len(critical_gaps) * 1  # 1 week per critical gap\n        \n        total_weeks = base_weeks + development_weeks + gap_weeks\n        \n        timeline = f\"\"\"\n        Project Timeline: {total_weeks} weeks total\n        \n        Phase 1: Project Initiation (Weeks 1-2)\n        - Project kickoff and team mobilization\n        - Requirements validation and finalization\n        - Technical architecture review\n        \n        Phase 2: Design & Planning (Weeks 3-4)\n        - Detailed system design\n        - Database schema design\n        - Integration architecture\n        - Test plan development\n        \n        Phase 3: Development (Weeks 5-{5 + development_weeks})\n        - Core module development/configuration\n        - Custom module development ({len(missing_modules)} modules)\n        - Gap resolution implementation\n        - Continuous integration setup\n        \n        Phase 4: Integration & Testing (Weeks {6 + development_weeks}-{8 + development_weeks})\n        - System integration\n        - Performance testing\n        - Security testing\n        - User acceptance testing\n        \n        Phase 5: Deployment & Go-Live (Weeks {9 + development_weeks}-{total_weeks})\n        - Production deployment\n        - Data migration\n        - User training\n        - Go-live support\n        \n        Parallel Activities:\n        - Documentation (ongoing)\n        - Quality assurance (ongoing)\n        - Client communication (weekly)\n        \"\"\"\n        \n        return timeline\n    \n    def generate_comprehensive_response(self, analyzer: RFPFeasibilityAnalyzer, \n                                      assessment: RFPFeasibilityAssessment) -> RFPResponse:\n        \"\"\"Generate complete RFP response\"\"\"\n        \n        # Executive Summary\n        exec_summary_prompt = f\"\"\"\n        Write an executive summary for an RFP response with:\n        - Confidence score: {assessment.confidence_score:.1f}%\n        - {assessment.available_modules}/{assessment.total_modules} modules available\n        - {len(assessment.critical_gaps)} critical gaps\n        - Investment: {assessment.investment_required}\n        \n        Create compelling executive summary (200 words) highlighting our strengths and approach.\n        \"\"\"\n        executive_summary = self.llm_processor._generate_text(exec_summary_prompt, 400)\n        \n        # Generate technical and financial proposals\n        technical_proposal = self.generate_technical_proposal(\n            analyzer.modules, analyzer.gaps, analyzer.requirements\n        )\n        \n        financial_proposal = self.generate_financial_proposal(\n            analyzer.modules, analyzer.gaps, assessment\n        )\n        \n        # Project timeline\n        project_timeline = self.generate_project_timeline(analyzer.modules, analyzer.gaps)\n        \n        # Risk mitigation\n        risk_mitigation = f\"\"\"\n        Risk Mitigation Strategy:\n        \n        Identified Risks: {len(assessment.risks)}\n        \n        Mitigation Measures:\n        1. Technical Risk: Proven module architecture reduces implementation risk\n        2. Timeline Risk: Agile methodology with regular checkpoints\n        3. Budget Risk: Fixed-price model with defined scope\n        4. Quality Risk: Comprehensive testing at each phase\n        5. Resource Risk: Dedicated team with backup resources\n        \n        Contingency Plans:\n        - 5% budget contingency for scope changes\n        - Alternative implementation paths for critical modules\n        - Escalation procedures for issue resolution\n        \"\"\"\n        \n        # Team composition\n        team_composition = f\"\"\"\n        Dedicated Project Team:\n        \n        Core Team ({4 + len([m for m in analyzer.modules if m.status == \"Missing\"])//2} members):\n        - Project Manager (PMP certified)\n        - Solution Architect (10+ years experience)\n        - Lead Developer (Full-stack expertise)\n        - QA Manager (Testing specialist)\n        {\"- Additional Developers (2-3 for module development)\" if len([m for m in analyzer.modules if m.status == \"Missing\"]) > 2 else \"\"}\n        \n        Extended Team:\n        - Business Analyst\n        - UI/UX Designer\n        - DevOps Engineer\n        - Security Specialist\n        \n        Team Qualifications:\n        - Average 8+ years industry experience\n        - Relevant technology certifications\n        - Previous similar project success\n        \"\"\"\n        \n        # Compliance statement\n        compliance_statement = \"\"\"\n        Compliance & Standards:\n        \n        Our solution ensures compliance with:\n        - Industry security standards (ISO 27001, SOC 2)\n        - Data protection regulations (GDPR, CCPA)\n        - Accessibility standards (WCAG 2.1)\n        - Quality standards (ISO 9001)\n        \n        Certifications:\n        - Company ISO certifications\n        - Team member professional certifications\n        - Technology partner certifications\n        \"\"\"\n        \n        # References and case studies\n        references_prompt = f\"\"\"\n        Create references section for RFP response highlighting:\n        - Similar projects completed successfully\n        - Client testimonials\n        - Relevant case studies\n        \n        Write references section (150 words) with specific examples.\n        \"\"\"\n        references_case_studies = self.llm_processor._generate_text(references_prompt, 300)\n        \n        # Assumptions and dependencies\n        assumptions_dependencies = f\"\"\"\n        Project Assumptions:\n        - Client provides timely access to existing systems\n        - Stakeholders available for requirements validation\n        - Test environment provided within 2 weeks\n        - Decision-making authority clearly defined\n        \n        Dependencies:\n        - Third-party system APIs available as documented\n        - Network infrastructure meets minimum requirements\n        - Security approvals obtained within agreed timeframes\n        - User training schedule coordinated with deployment\n        \n        Success Criteria:\n        - All {len(analyzer.requirements)} requirements fully met\n        - Performance benchmarks achieved\n        - User acceptance criteria satisfied\n        - Go-live within agreed timeline\n        \"\"\"\n        \n        return RFPResponse(\n            executive_summary=executive_summary or \"We are uniquely positioned to deliver this solution with our proven expertise and comprehensive approach.\",\n            technical_proposal=technical_proposal,\n            financial_proposal=financial_proposal,\n            project_timeline=project_timeline,\n            risk_mitigation=risk_mitigation,\n            team_composition=team_composition,\n            compliance_statement=compliance_statement,\n            references_case_studies=references_case_studies or \"Our track record includes successful implementations for Fortune 500 companies with similar requirements.\",\n            assumptions_dependencies=assumptions_dependencies\n        )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:48.384058Z","iopub.execute_input":"2025-07-29T15:48:48.384635Z","iopub.status.idle":"2025-07-29T15:48:48.416131Z","shell.execute_reply.started":"2025-07-29T15:48:48.384616Z","shell.execute_reply":"2025-07-29T15:48:48.415347Z"}},"outputs":[],"execution_count":178},{"cell_type":"code","source":"class RFPResponseReportGenerator:\n    \"\"\"Generates professional RFP response document\"\"\"\n    \n    def __init__(self):\n        self.styles = getSampleStyleSheet()\n        self.title_style = ParagraphStyle(\n            'RFPTitle',\n            parent=self.styles['Heading1'],\n            fontSize=28,\n            spaceAfter=30,\n            alignment=TA_CENTER,\n            textColor=colors.HexColor('#1e3a8a')\n        )\n        self.section_style = ParagraphStyle(\n            'RFPSection',\n            parent=self.styles['Heading2'],\n            fontSize=18,\n            spaceAfter=15,\n            textColor=colors.HexColor('#1e3a8a'),\n            borderWidth=1,\n            borderColor=colors.HexColor('#1e3a8a'),\n            borderPadding=8,\n            backColor=colors.HexColor('#f8fafc')\n        )\n        \n    def create_cover_page(self, rfp_response) -> List:\n        \"\"\"Create professional cover page\"\"\"\n        elements = []\n        \n        elements.append(Spacer(1, 2*inch))\n        elements.append(Paragraph(\"PROPOSAL RESPONSE\", self.title_style))\n        elements.append(Spacer(1, 0.5*inch))\n        \n        # Company info box\n        company_info = \"\"\"\n        <b>Submitted by:</b> Abougia Technologies<br/>\n        <b>Date:</b> {}<br/>\n        <b>Proposal ID:</b> RFP-2025-001<br/>\n        <b>Validity:</b> 90 days from submission<br/>\n        <b>Contact:</b> proposals@abougia.com\n        \"\"\".format(datetime.now().strftime('%B %d, %Y'))\n        \n        elements.append(Paragraph(company_info, ParagraphStyle(\n            'CompanyInfo',\n            parent=self.styles['Normal'],\n            fontSize=12,\n            alignment=TA_CENTER,\n            borderWidth=2,\n            borderColor=colors.HexColor('#1e3a8a'),\n            borderPadding=20,\n            backColor=colors.HexColor('#f0f9ff')\n        )))\n        \n        elements.append(Spacer(1, 1*inch))\n        elements.append(Paragraph(\"Confidential & Proprietary\", ParagraphStyle(\n            'Confidential',\n            parent=self.styles['Normal'],\n            fontSize=10,\n            alignment=TA_CENTER,\n            textColor=colors.red\n        )))\n        \n        elements.append(PageBreak())\n        return elements\n    \n    def create_executive_summary_section(self, rfp_response) -> List:\n        \"\"\"Create enhanced executive summary section\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"EXECUTIVE SUMMARY\", self.section_style))\n        elements.append(Spacer(1, 15))\n        \n        # Enhanced executive summary with structured approach\n        summary_intro = \"\"\"\n        <b>Abougia Technologies</b> is pleased to submit this comprehensive proposal in response to your RFP. \n        Our solution leverages proven technology modules, industry expertise, and innovative approaches to \n        deliver exceptional value that exceeds your requirements.\n        \"\"\"\n        \n        elements.append(Paragraph(summary_intro, ParagraphStyle(\n            'SummaryIntro',\n            parent=self.styles['Normal'],\n            fontSize=11,\n            spaceAfter=12,\n            backColor=colors.HexColor('#f8fafc'),\n            borderPadding=10,\n            borderWidth=1,\n            borderColor=colors.HexColor('#e2e8f0')\n        )))\n        \n        elements.append(Spacer(1, 12))\n        \n        # Process the AI-generated executive summary with better formatting\n        ai_summary = rfp_response.executive_summary\n        if ai_summary and len(ai_summary) > 100:\n            # Split into logical paragraphs\n            summary_sentences = ai_summary.split('. ')\n            current_paragraph = \"\"\n            \n            for sentence in summary_sentences:\n                if len(current_paragraph + sentence) > 180 and current_paragraph:\n                    elements.append(Paragraph(current_paragraph.strip() + '.', self.styles['Normal']))\n                    elements.append(Spacer(1, 8))\n                    current_paragraph = sentence\n                else:\n                    current_paragraph += sentence + '. ' if not sentence.endswith('.') else sentence + ' '\n            \n            if current_paragraph.strip():\n                elements.append(Paragraph(current_paragraph.strip(), self.styles['Normal']))\n        else:\n            # Fallback professional summary\n            fallback_summary = \"\"\"\n            Our proposed solution addresses your core requirements through a combination of proven modules \n            and custom development. We bring extensive experience in similar implementations, a dedicated \n            project team, and a commitment to delivering on time and within budget.\n            \n            Key differentiators include our modular architecture approach, comprehensive testing methodology, \n            and ongoing support framework that ensures long-term success of your investment.\n            \"\"\"\n            elements.append(Paragraph(fallback_summary, self.styles['Normal']))\n        \n        elements.append(Spacer(1, 15))\n        \n        # Enhanced Key highlights box with better structure\n        highlights_header = Paragraph(\"<b>Key Proposal Highlights:</b>\", ParagraphStyle(\n            'HighlightHeader',\n            parent=self.styles['Normal'],\n            fontName='Helvetica-Bold',\n            fontSize=12,\n            textColor=colors.HexColor('#1e3a8a'),\n            spaceAfter=8\n        ))\n        \n        highlights_content = [\n            \"✓ <b>Proven Solution:</b> Leveraging existing modules with demonstrated success\",\n            \"✓ <b>Technical Excellence:</b> Comprehensive architecture with scalability built-in\", \n            \"✓ <b>Competitive Investment:</b> Fixed-price model with transparent cost breakdown\",\n            \"✓ <b>Expert Team:</b> Dedicated professionals with relevant domain expertise\",\n            \"✓ <b>Risk Mitigation:</b> Phased delivery approach with defined milestones\",\n            \"✓ <b>Long-term Partnership:</b> Comprehensive warranty and ongoing support\"\n        ]\n        \n        elements.append(highlights_header)\n        \n        # Add summary box around highlights\n        highlight_table_data = []\n        for highlight in highlights_content:\n            highlight_table_data.append([Paragraph(highlight, ParagraphStyle(\n                'HighlightTable',\n                parent=self.styles['Normal'],\n                fontSize=10\n            ))])\n        \n        highlight_table = Table(highlight_table_data, colWidths=[5.5*inch])\n        highlight_table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, -1), colors.HexColor('#f0f9ff')),\n            ('BORDER', (0, 0), (-1, -1), 1, colors.HexColor('#1e3a8a')),\n            ('VALIGN', (0, 0), (-1, -1), 'TOP'),\n            ('TOPPADDING', (0, 0), (-1, -1), 8),\n            ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n            ('LEFTPADDING', (0, 0), (-1, -1), 15),\n            ('RIGHTPADDING', (0, 0), (-1, -1), 15),\n        ]))\n        \n        elements.append(highlight_table)\n        elements.append(PageBreak())\n        return elements\n\n    def create_technical_section(self, technical_proposal) -> List:\n        \"\"\"Create enhanced technical proposal section with better formatting\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"TECHNICAL PROPOSAL\", self.section_style))\n        elements.append(Spacer(1, 15))\n        \n        # Solution Overview with better formatting\n        elements.append(Paragraph(\"1. Solution Overview\", ParagraphStyle(\n            'TechSubheading',\n            parent=self.styles['Heading3'],\n            fontSize=14,\n            textColor=colors.HexColor('#1e3a8a'),\n            spaceAfter=8\n        )))\n        \n        # Split the solution overview into readable paragraphs\n        solution_text = technical_proposal.solution_overview\n        if \"\\n\\n\" in solution_text:\n            # Already has paragraph breaks\n            paragraphs = solution_text.split('\\n\\n')\n            for para in paragraphs:\n                if para.strip():\n                    elements.append(Paragraph(para.strip(), self.styles['Normal']))\n                    elements.append(Spacer(1, 8))\n        else:\n            # Split into smaller paragraphs for better readability\n            sentences = solution_text.split('. ')\n            current_para = \"\"\n            for sentence in sentences:\n                if len(current_para + sentence) > 200 and current_para:\n                    elements.append(Paragraph(current_para.strip() + '.', self.styles['Normal']))\n                    elements.append(Spacer(1, 8))\n                    current_para = sentence\n                else:\n                    current_para += sentence + '. ' if not sentence.endswith('.') else sentence + ' '\n            if current_para.strip():\n                elements.append(Paragraph(current_para.strip(), self.styles['Normal']))\n        \n        elements.append(Spacer(1, 15))\n        \n        # Technical Architecture\n        elements.append(Paragraph(\"2. Technical Architecture\", ParagraphStyle(\n            'TechSubheading',\n            parent=self.styles['Heading3'],\n            fontSize=14,\n            textColor=colors.HexColor('#1e3a8a'),\n            spaceAfter=8\n        )))\n        \n        # Format architecture with paragraph breaks\n        architecture_text = technical_proposal.technical_architecture\n        if \"\\n\\n\" in architecture_text:\n            paragraphs = architecture_text.split('\\n\\n')\n            for para in paragraphs:\n                if para.strip():\n                    elements.append(Paragraph(para.strip(), self.styles['Normal']))\n                    elements.append(Spacer(1, 8))\n        else:\n            elements.append(Paragraph(architecture_text, self.styles['Normal']))\n        \n        elements.append(Spacer(1, 15))\n        \n        # Implementation Approach\n        elements.append(Paragraph(\"3. Implementation Methodology\", ParagraphStyle(\n            'TechSubheading',\n            parent=self.styles['Heading3'],\n            fontSize=14,\n            textColor=colors.HexColor('#1e3a8a'),\n            spaceAfter=8\n        )))\n        \n        # Format implementation with paragraph breaks\n        implementation_text = technical_proposal.implementation_approach\n        if \"\\n\\n\" in implementation_text:\n            paragraphs = implementation_text.split('\\n\\n')\n            for para in paragraphs:\n                if para.strip():\n                    elements.append(Paragraph(para.strip(), self.styles['Normal']))\n                    elements.append(Spacer(1, 8))\n        else:\n            elements.append(Paragraph(implementation_text, self.styles['Normal']))\n        \n        elements.append(Spacer(1, 15))\n        \n        # Integration Strategy\n        elements.append(Paragraph(\"4. Integration Strategy\", ParagraphStyle(\n            'TechSubheading',\n            parent=self.styles['Heading3'],\n            fontSize=14,\n            textColor=colors.HexColor('#1e3a8a'),\n            spaceAfter=8\n        )))\n        \n        # Format integration with paragraph breaks\n        integration_text = technical_proposal.integration_strategy\n        if \"\\n\\n\" in integration_text:\n            paragraphs = integration_text.split('\\n\\n')\n            for para in paragraphs:\n                if para.strip():\n                    elements.append(Paragraph(para.strip(), self.styles['Normal']))\n                    elements.append(Spacer(1, 8))\n        else:\n            elements.append(Paragraph(integration_text, self.styles['Normal']))\n        \n        elements.append(Spacer(1, 15))\n        \n        # Security Framework\n        elements.append(Paragraph(\"5. Security Framework\", ParagraphStyle(\n            'TechSubheading',\n            parent=self.styles['Heading3'],\n            fontSize=14,\n            textColor=colors.HexColor('#1e3a8a'),\n            spaceAfter=8\n        )))\n        \n        # Format security with paragraph breaks\n        security_text = technical_proposal.security_framework\n        if \"\\n\\n\" in security_text:\n            paragraphs = security_text.split('\\n\\n')\n            for para in paragraphs:\n                if para.strip():\n                    elements.append(Paragraph(para.strip(), self.styles['Normal']))\n                    elements.append(Spacer(1, 8))\n        else:\n            elements.append(Paragraph(security_text, self.styles['Normal']))\n        \n        elements.append(Spacer(1, 15))\n        \n        # Performance Specifications with enhanced table\n        elements.append(Paragraph(\"6. Performance Specifications\", ParagraphStyle(\n            'TechSubheading',\n            parent=self.styles['Heading3'],\n            fontSize=14,\n            textColor=colors.HexColor('#1e3a8a'),\n            spaceAfter=8\n        )))\n        \n        # Parse performance specs if they contain structured data\n        if \"**\" in technical_proposal.performance_specifications:\n            # Handle enhanced format\n            perf_lines = technical_proposal.performance_specifications.split('\\n')\n            for line in perf_lines:\n                if line.strip():\n                    if line.startswith('**') and line.endswith('**'):\n                        # Bold header\n                        clean_line = line.replace('**', '')\n                        elements.append(Paragraph(clean_line, ParagraphStyle(\n                            'PerfHeader',\n                            parent=self.styles['Normal'],\n                            fontName='Helvetica-Bold',\n                            fontSize=10,\n                            spaceAfter=4\n                        )))\n                    elif line.startswith('- '):\n                        # Bullet point\n                        elements.append(Paragraph(line, ParagraphStyle(\n                            'PerfBullet',\n                            parent=self.styles['Normal'],\n                            fontSize=9,\n                            leftIndent=20,\n                            spaceAfter=2\n                        )))\n                    else:\n                        elements.append(Paragraph(line, self.styles['Normal']))\n        else:\n            # Fallback to original table format\n            perf_data = [\n                ['Metric', 'Specification', 'Our Commitment'],\n                ['Response Time', '< 2 seconds', '< 1.5 seconds average'],\n                ['Concurrent Users', '1000+ users', '2000+ users supported'],\n                ['Uptime', '99.9%', '99.95% with SLA'],\n                ['Data Processing', '10GB/hour', '15GB/hour capacity'],\n                ['Scalability', '5x load increase', '10x scaling capability']\n            ]\n            \n            perf_table = Table(perf_data, colWidths=[2*inch, 2*inch, 2*inch])\n            perf_table.setStyle(TableStyle([\n                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1e3a8a')),\n                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n                ('GRID', (0, 0), (-1, -1), 1, colors.black),\n                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n                ('FONTSIZE', (0, 0), (-1, -1), 9),\n                ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f5f5f5')])\n            ]))\n            \n            elements.append(perf_table)\n        \n        elements.append(Spacer(1, 15))\n        \n        # Testing Methodology\n        elements.append(Paragraph(\"7. Testing Methodology\", ParagraphStyle(\n            'TechSubheading',\n            parent=self.styles['Heading3'],\n            fontSize=14,\n            textColor=colors.HexColor('#1e3a8a'),\n            spaceAfter=8\n        )))\n        \n        # Format testing methodology for better readability\n        testing_lines = technical_proposal.testing_methodology.split('\\n')\n        for line in testing_lines:\n            if line.strip():\n                if line.startswith('**') and line.endswith('**'):\n                    # Bold header\n                    clean_line = line.replace('**', '')\n                    elements.append(Paragraph(clean_line, ParagraphStyle(\n                        'TestHeader',\n                        parent=self.styles['Normal'],\n                        fontName='Helvetica-Bold',\n                        fontSize=11,\n                        spaceAfter=6\n                    )))\n                elif line.startswith('- '):\n                    # Bullet point\n                    elements.append(Paragraph(line, ParagraphStyle(\n                        'TestBullet',\n                        parent=self.styles['Normal'],\n                        fontSize=9,\n                        leftIndent=20,\n                        spaceAfter=3\n                    )))\n                elif line.strip().startswith(('1.', '2.', '3.', '4.', '5.', '6.')):\n                    # Numbered list\n                    elements.append(Paragraph(line, ParagraphStyle(\n                        'TestNumber',\n                        parent=self.styles['Normal'],\n                        fontSize=9,\n                        leftIndent=15,\n                        spaceAfter=3\n                    )))\n                else:\n                    elements.append(Paragraph(line, self.styles['Normal']))\n        \n        elements.append(Spacer(1, 15))\n        \n        # Deployment Strategy\n        elements.append(Paragraph(\"8. Deployment Strategy\", ParagraphStyle(\n            'TechSubheading',\n            parent=self.styles['Heading3'],\n            fontSize=14,\n            textColor=colors.HexColor('#1e3a8a'),\n            spaceAfter=8\n        )))\n        \n        # Format deployment with paragraph breaks\n        deployment_text = technical_proposal.deployment_strategy\n        if \"\\n\\n\" in deployment_text:\n            paragraphs = deployment_text.split('\\n\\n')\n            for para in paragraphs:\n                if para.strip():\n                    elements.append(Paragraph(para.strip(), self.styles['Normal']))\n                    elements.append(Spacer(1, 8))\n        else:\n            elements.append(Paragraph(deployment_text, self.styles['Normal']))\n        \n        elements.append(PageBreak())\n        return elements\n\n    def create_financial_section(self, financial_proposal) -> List:\n        \"\"\"Create enhanced financial proposal section\"\"\"\n        elements = []\n        \n        elements.append(Paragraph(\"FINANCIAL PROPOSAL\", self.section_style))\n        elements.append(Spacer(1, 15))\n        \n        # Enhanced Total Investment presentation\n        total_cost_clean = financial_proposal.total_cost.replace('$', '').replace(',', '')\n        try:\n            cost_value = int(total_cost_clean)\n            formatted_cost = f\"${cost_value:,}\"\n        except:\n            formatted_cost = financial_proposal.total_cost\n        \n        elements.append(Paragraph(f\"Total Project Investment: {formatted_cost}\", ParagraphStyle(\n            'TotalCost',\n            parent=self.styles['Heading2'],\n            fontSize=22,\n            textColor=colors.HexColor('#059669'),\n            alignment=TA_CENTER,\n            borderWidth=3,\n            borderColor=colors.HexColor('#059669'),\n            borderPadding=15,\n            backColor=colors.HexColor('#f0fdf4'),\n            spaceAfter=20\n        )))\n        \n        elements.append(Spacer(1, 15))\n        \n        # Investment Summary Box\n        investment_summary = \"\"\"\n        <b>Investment Overview:</b><br/>\n        • Comprehensive solution with proven ROI<br/>\n        • Fixed-price model eliminates budget uncertainty<br/>\n        • Flexible payment schedule aligned with deliverables<br/>\n        • Competitive pricing with exceptional value proposition\n        \"\"\"\n        \n        elements.append(Paragraph(investment_summary, ParagraphStyle(\n            'InvestmentSummary',\n            parent=self.styles['Normal'],\n            fontSize=10,\n            borderWidth=1,\n            borderColor=colors.HexColor('#059669'),\n            borderPadding=12,\n            backColor=colors.HexColor('#f0fdf4'),\n            spaceAfter=15\n        )))\n        \n        # Enhanced Cost Breakdown Table\n        elements.append(Paragraph(\"Detailed Cost Breakdown\", ParagraphStyle(\n            'FinSubheading',\n            parent=self.styles['Heading3'],\n            fontSize=14,\n            textColor=colors.HexColor('#1e3a8a'),\n            spaceAfter=10\n        )))\n        \n        cost_data = [['Cost Component', 'Amount', 'Percentage']]\n        \n        # Calculate total for percentage calculation\n        total_amount = 0\n        cost_values = {}\n        for component, cost in financial_proposal.cost_breakdown.items():\n            clean_cost = cost.replace('$', '').replace(',', '')\n            try:\n                cost_values[component] = int(clean_cost)\n                total_amount += cost_values[component]\n            except:\n                cost_values[component] = 0\n        \n        for component, cost in financial_proposal.cost_breakdown.items():\n            percentage = f\"{(cost_values[component] / total_amount * 100):.1f}%\" if total_amount > 0 else \"0%\"\n            cost_data.append([\n                Paragraph(component, self.styles['Normal']),\n                Paragraph(cost, ParagraphStyle('CostAmount', parent=self.styles['Normal'], alignment=TA_RIGHT)),\n                Paragraph(percentage, ParagraphStyle('CostPercent', parent=self.styles['Normal'], alignment=TA_CENTER))\n            ])\n        \n        # Add total row\n        cost_data.append([\n            Paragraph(\"<b>TOTAL PROJECT COST</b>\", ParagraphStyle('TotalRow', parent=self.styles['Normal'], fontName='Helvetica-Bold')),\n            Paragraph(f\"<b>{formatted_cost}</b>\", ParagraphStyle('TotalAmount', parent=self.styles['Normal'], fontName='Helvetica-Bold', alignment=TA_RIGHT)),\n            Paragraph(\"<b>100.0%</b>\", ParagraphStyle('TotalPercent', parent=self.styles['Normal'], fontName='Helvetica-Bold', alignment=TA_CENTER))\n        ])\n        \n        cost_table = Table(cost_data, colWidths=[3.5*inch, 1.5*inch, 1*inch])\n        cost_table.setStyle(TableStyle([\n            ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1e3a8a')),\n            ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n            ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n            ('FONTSIZE', (0, 0), (-1, 0), 11),\n            ('GRID', (0, 0), (-1, -1), 1, colors.black),\n            ('FONTSIZE', (0, 1), (-1, -2), 9),\n            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n            ('ROWBACKGROUNDS', (0, 1), (-1, -2), [colors.white, colors.HexColor('#f5f5f5')]),\n            ('BACKGROUND', (0, -1), (-1, -1), colors.HexColor('#e5e7eb')),\n            ('FONTNAME', (0, -1), (-1, -1), 'Helvetica-Bold'),\n            ('FONTSIZE', (0, -1), (-1, -1), 10),\n        ]))\n        \n        elements.append(cost_table)\n        elements.append(Spacer(1, 20))\n        \n        # Enhanced Payment Schedule\n        elements.append(Paragraph(\"Payment Schedule & Terms\", ParagraphStyle(\n            'FinSubheading',\n            parent=self.styles['Heading3'],\n            fontSize=14,\n            textColor=colors.HexColor('#1e3a8a'),\n            spaceAfter=10\n        )))\n        \n        # Format payment schedule better\n        payment_lines = financial_proposal.payment_schedule.split('\\n')\n        formatted_payments = []\n        for line in payment_lines:\n            if line.strip() and ('Contract Signing' in line or 'Design Approval' in line or 'Development' in line or 'UAT' in line or 'Go-Live' in line):\n                # Extract milestone and amount\n                if ':' in line and '(' in line:\n                    milestone = line.split(':')[0].replace('-', '').strip()\n                    amount_part = line.split(':')[1].strip()\n                    formatted_payments.append([milestone, amount_part])\n        \n        if formatted_payments:\n            payment_data = [['Milestone', 'Payment Due']]\n            for milestone, amount in formatted_payments:\n                payment_data.append([milestone, amount])\n            \n            payment_table = Table(payment_data, colWidths=[3.5*inch, 2.5*inch])\n            payment_table.setStyle(TableStyle([\n                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1e3a8a')),\n                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n                ('GRID', (0, 0), (-1, -1), 1, colors.black),\n                ('FONTSIZE', (0, 0), (-1, -1), 9),\n                ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n                ('ALIGN', (1, 1), (1, -1), 'RIGHT'),\n                ('ROWBACKGROUNDS', (0, 1), (-1, -1), [colors.white, colors.HexColor('#f5f5f5')])\n            ]))\n            elements.append(payment_table)\n        else:\n            # Fallback to original format\n            elements.append(Paragraph(financial_proposal.payment_schedule, self.styles['Normal']))\n        \n        elements.append(Spacer(1, 20))\n        \n        # Enhanced ROI Analysis\n        elements.append(Paragraph(\"Return on Investment Analysis\", ParagraphStyle(\n            'FinSubheading',\n            parent=self.styles['Heading3'],\n            fontSize=14,\n            textColor=colors.HexColor('#1e3a8a'),\n            spaceAfter=10\n        )))\n        \n        # Format ROI analysis with paragraph breaks\n        roi_text = financial_proposal.roi_analysis\n        if roi_text and len(roi_text) > 50:\n            if \"\\n\\n\" in roi_text:\n                paragraphs = roi_text.split('\\n\\n')\n                for para in paragraphs:\n                    if para.strip():\n                        elements.append(Paragraph(para.strip(), self.styles['Normal']))\n                        elements.append(Spacer(1, 8))\n            else:\n                elements.append(Paragraph(roi_text, self.styles['Normal']))\n        else:\n            # Enhanced fallback ROI analysis\n            roi_fallback = \"\"\"\n            <b>Investment Returns & Business Value:</b><br/><br/>\n            \n            <b>Financial Benefits:</b><br/>\n            • Expected ROI of 250-300% within 24 months<br/>\n            • Operational cost reduction of 20-25%<br/>\n            • Efficiency improvements of 30-40%<br/>\n            • Reduced manual processing time by 50%<br/><br/>\n            \n            <b>Strategic Benefits:</b><br/>\n            • Enhanced decision-making capabilities<br/>\n            • Improved data accuracy and consistency<br/>\n            • Scalable platform for future growth<br/>\n            • Competitive advantage through automation<br/><br/>\n            \n            <b>Risk Mitigation:</b><br/>\n            • Reduced dependency on manual processes<br/>\n            • Improved compliance and audit capabilities<br/>\n            • Enhanced security and data protection\n            \"\"\"\n            elements.append(Paragraph(roi_fallback, self.styles['Normal']))\n        \n        elements.append(Spacer(1, 15))\n        \n        # Value Proposition Summary\n        value_prop = \"\"\"\n        <b>Why Choose Abougia Technologies:</b><br/>\n        • Proven track record with similar implementations<br/>\n        • Fixed-price model eliminates budget risks<br/>\n        • Comprehensive warranty and support included<br/>\n        • Competitive pricing with superior value delivery<br/>\n        • Dedicated project team with relevant expertise\n        \"\"\"\n        \n        elements.append(Paragraph(value_prop, ParagraphStyle(\n            'ValueProp',\n            parent=self.styles['Normal'],\n            fontSize=10,\n            borderWidth=1,\n            borderColor=colors.HexColor('#059669'),\n            borderPadding=12,\n            backColor=colors.HexColor('#f0fdf4')\n        )))\n        \n        elements.append(PageBreak())\n        return elements\n    \n    def generate_rfp_response_document(self, rfp_response, output_path: str):\n        \"\"\"Generate complete RFP response document\"\"\"\n        doc = SimpleDocTemplate(\n            output_path,\n            pagesize=A4,\n            topMargin=0.75*inch,\n            bottomMargin=0.75*inch,\n            leftMargin=0.75*inch,\n            rightMargin=0.75*inch\n        )\n        \n        elements = []\n        \n        # Cover page\n        elements.extend(self.create_cover_page(rfp_response))\n        \n        # Table of contents\n        elements.append(Paragraph(\"TABLE OF CONTENTS\", self.section_style))\n        elements.append(Spacer(1, 15))\n        \n        toc_items = [\n            \"1. Executive Summary\",\n            \"2. Technical Proposal\",\n            \"3. Financial Proposal\", \n            \"4. Project Timeline\",\n            \"5. Risk Mitigation\",\n            \"6. Team Composition\",\n            \"7. Compliance Statement\",\n            \"8. References & Case Studies\",\n            \"9. Assumptions & Dependencies\"\n        ]\n        \n        for item in toc_items:\n            elements.append(Paragraph(item, self.styles['Normal']))\n            elements.append(Spacer(1, 6))\n        \n        elements.append(PageBreak())\n        \n        # Main sections\n        elements.extend(self.create_executive_summary_section(rfp_response))\n        elements.extend(self.create_technical_section(rfp_response.technical_proposal))\n        elements.extend(self.create_financial_section(rfp_response.financial_proposal))\n        \n        # Project Timeline\n        elements.append(Paragraph(\"PROJECT TIMELINE\", self.section_style))\n        elements.append(Spacer(1, 15))\n        \n        # Format timeline with better structure\n        timeline_text = rfp_response.project_timeline\n        timeline_lines = timeline_text.split('\\n')\n        \n        for line in timeline_lines:\n            line = line.strip()\n            if line:\n                if line.startswith('Project Timeline:'):\n                    # Main timeline header\n                    elements.append(Paragraph(line, ParagraphStyle(\n                        'TimelineHeader',\n                        parent=self.styles['Normal'],\n                        fontName='Helvetica-Bold',\n                        fontSize=12,\n                        spaceAfter=10\n                    )))\n                elif line.startswith('Phase'):\n                    # Phase headers\n                    elements.append(Paragraph(line, ParagraphStyle(\n                        'PhaseHeader',\n                        parent=self.styles['Normal'],\n                        fontName='Helvetica-Bold',\n                        fontSize=11,\n                        spaceAfter=6,\n                        textColor=colors.HexColor('#1e3a8a')\n                    )))\n                elif line.startswith('-'):\n                    # Phase activities\n                    elements.append(Paragraph(line, ParagraphStyle(\n                        'PhaseActivity',\n                        parent=self.styles['Normal'],\n                        fontSize=9,\n                        leftIndent=20,\n                        spaceAfter=2\n                    )))\n                elif line.startswith('Parallel Activities:'):\n                    # Parallel activities header\n                    elements.append(Spacer(1, 8))\n                    elements.append(Paragraph(line, ParagraphStyle(\n                        'ParallelHeader',\n                        parent=self.styles['Normal'],\n                        fontName='Helvetica-Bold',\n                        fontSize=10,\n                        spaceAfter=4\n                    )))\n                else:\n                    # Regular text\n                    elements.append(Paragraph(line, self.styles['Normal']))\n                    elements.append(Spacer(1, 4))\n        \n        elements.append(PageBreak())\n        \n        # Risk Mitigation\n        elements.append(Paragraph(\"RISK MITIGATION\", self.section_style))\n        elements.append(Spacer(1, 15))\n        \n        # Format risk mitigation with paragraph breaks\n        risk_text = rfp_response.risk_mitigation\n        if \"\\n\\n\" in risk_text:\n            paragraphs = risk_text.split('\\n\\n')\n            for para in paragraphs:\n                if para.strip():\n                    # Check if it's a header or regular text\n                    if para.strip().endswith(':'):\n                        elements.append(Paragraph(para.strip(), ParagraphStyle(\n                            'RiskHeader',\n                            parent=self.styles['Normal'],\n                            fontName='Helvetica-Bold',\n                            fontSize=11,\n                            spaceAfter=6\n                        )))\n                    else:\n                        elements.append(Paragraph(para.strip(), self.styles['Normal']))\n                        elements.append(Spacer(1, 8))\n        else:\n            elements.append(Paragraph(risk_text, self.styles['Normal']))\n        \n        elements.append(Spacer(1, 20))\n        \n        # Team Composition\n        elements.append(Paragraph(\"TEAM COMPOSITION\", self.section_style))\n        elements.append(Spacer(1, 15))\n        \n        # Format team composition with better structure\n        team_text = rfp_response.team_composition\n        team_lines = team_text.split('\\n')\n        \n        for line in team_lines:\n            line = line.strip()\n            if line:\n                if line.endswith(':'):\n                    # Section headers\n                    elements.append(Paragraph(line, ParagraphStyle(\n                        'TeamHeader',\n                        parent=self.styles['Normal'],\n                        fontName='Helvetica-Bold',\n                        fontSize=11,\n                        spaceAfter=6,\n                        textColor=colors.HexColor('#1e3a8a')\n                    )))\n                elif line.startswith('-'):\n                    # Team member roles\n                    elements.append(Paragraph(line, ParagraphStyle(\n                        'TeamMember',\n                        parent=self.styles['Normal'],\n                        fontSize=9,\n                        leftIndent=20,\n                        spaceAfter=3\n                    )))\n                else:\n                    # Regular text\n                    elements.append(Paragraph(line, self.styles['Normal']))\n                    elements.append(Spacer(1, 4))\n        \n        elements.append(PageBreak())\n        \n        # Compliance\n        elements.append(Paragraph(\"COMPLIANCE STATEMENT\", self.section_style))\n        elements.append(Spacer(1, 15))\n        \n        # Format compliance with paragraph breaks\n        compliance_text = rfp_response.compliance_statement\n        if \"\\n\\n\" in compliance_text:\n            paragraphs = compliance_text.split('\\n\\n')\n            for para in paragraphs:\n                if para.strip():\n                    if para.strip().endswith(':'):\n                        elements.append(Paragraph(para.strip(), ParagraphStyle(\n                            'ComplianceHeader',\n                            parent=self.styles['Normal'],\n                            fontName='Helvetica-Bold',\n                            fontSize=11,\n                            spaceAfter=6\n                        )))\n                    else:\n                        elements.append(Paragraph(para.strip(), self.styles['Normal']))\n                        elements.append(Spacer(1, 8))\n        else:\n            elements.append(Paragraph(compliance_text, self.styles['Normal']))\n        \n        elements.append(Spacer(1, 20))\n        \n        # References\n        elements.append(Paragraph(\"REFERENCES & CASE STUDIES\", self.section_style))\n        elements.append(Spacer(1, 15))\n        \n        # Format references with paragraph breaks\n        references_text = rfp_response.references_case_studies\n        if \"\\n\\n\" in references_text:\n            paragraphs = references_text.split('\\n\\n')\n            for para in paragraphs:\n                if para.strip():\n                    elements.append(Paragraph(para.strip(), self.styles['Normal']))\n                    elements.append(Spacer(1, 8))\n        else:\n            elements.append(Paragraph(references_text, self.styles['Normal']))\n        \n        elements.append(Spacer(1, 20))\n        \n        # Assumptions\n        elements.append(Paragraph(\"ASSUMPTIONS & DEPENDENCIES\", self.section_style))\n        elements.append(Spacer(1, 15))\n        \n        # Format assumptions with better structure\n        assumptions_text = rfp_response.assumptions_dependencies\n        assumptions_lines = assumptions_text.split('\\n')\n        \n        for line in assumptions_lines:\n            line = line.strip()\n            if line:\n                if line.endswith(':'):\n                    # Section headers\n                    elements.append(Paragraph(line, ParagraphStyle(\n                        'AssumptionHeader',\n                        parent=self.styles['Normal'],\n                        fontName='Helvetica-Bold',\n                        fontSize=11,\n                        spaceAfter=6,\n                        textColor=colors.HexColor('#1e3a8a')\n                    )))\n                elif line.startswith('-'):\n                    # Assumption items\n                    elements.append(Paragraph(line, ParagraphStyle(\n                        'AssumptionItem',\n                        parent=self.styles['Normal'],\n                        fontSize=9,\n                        leftIndent=20,\n                        spaceAfter=3\n                    )))\n                else:\n                    # Regular text\n                    elements.append(Paragraph(line, self.styles['Normal']))\n                    elements.append(Spacer(1, 4))\n        \n        # Build document\n        try:\n            doc.build(elements)\n            print(f\"✅ RFP Response generated successfully: {output_path}\")\n        except Exception as e:\n            print(f\"❌ Error generating RFP response: {e}\")\n            import traceback\n            traceback.print_exc()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:48.417077Z","iopub.execute_input":"2025-07-29T15:48:48.417305Z","iopub.status.idle":"2025-07-29T15:48:49.080707Z","shell.execute_reply.started":"2025-07-29T15:48:48.417288Z","shell.execute_reply":"2025-07-29T15:48:49.080052Z"}},"outputs":[],"execution_count":179},{"cell_type":"code","source":"# Enhanced main function to generate both feasibility and response\ndef generate_rfp_response():\n    \"\"\"Generate complete RFP response after feasibility analysis\"\"\"\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"GENERATING RFP RESPONSE...\")\n    print(\"=\"*70)\n    \n    # Initialize analyzer (reuse from existing code)\n    analyzer = RFPFeasibilityAnalyzer()\n    \n    # File paths (same as your existing code)\n    file_paths = {\n        'module_matching': '/kaggle/input/input-reports-fr-agent/module-matching-report.pdf',\n        'win_loss': '/kaggle/input/input-reports-fr-agent/win_loss_analysis.pdf', \n        'gap_analysis': '/kaggle/input/input-reports-fr-agent/gap_analysis_report.pdf',\n        'customer_needs': '/kaggle/input/input-reports-fr-agent/customer_needs_report.pdf'\n    }\n    \n    try:\n        # Load and analyze documents\n        print(\"📄 Loading and analyzing documents...\")\n        results = analyzer.load_and_analyze_documents(file_paths)\n        \n        # Calculate feasibility\n        print(\"🔍 Calculating feasibility...\")\n        assessment = analyzer.calculate_feasibility()\n        \n        # Only generate response if feasible\n        if assessment.can_respond:\n            print(\"✅ Project is feasible - generating RFP response...\")\n            \n            # Initialize response generator\n            response_generator = RFPResponseGenerator(analyzer.processor.llm_processor)\n            \n            # Generate comprehensive response\n            print(\"🤖 Generating technical and financial proposals...\")\n            rfp_response = response_generator.generate_comprehensive_response(analyzer, assessment)\n            \n            # Generate response document\n            response_output_path = \"/kaggle/working/rfp_response_proposal.pdf\"\n            print(\"📝 Creating RFP response document...\")\n            \n            response_doc_generator = RFPResponseReportGenerator()\n            response_doc_generator.generate_rfp_response_document(rfp_response, response_output_path)\n            \n            # Display response summary\n            print(\"\\n\" + \"=\"*70)\n            print(\"RFP RESPONSE SUMMARY\")\n            print(\"=\"*70)\n            print(f\"💰 Total Investment: {rfp_response.financial_proposal.total_cost}\")\n            print(f\"⏱️  Project Duration: {rfp_response.project_timeline.split('weeks total')[0].split(':')[1].strip()} weeks\")\n            print(f\"👥 Team Size: Core team + specialists\")\n            print(f\"🎯 Key Modules: {len([m for m in analyzer.modules if m.status == 'Available'])} available, {len([m for m in analyzer.modules if m.status == 'Missing'])} to develop\")\n            \n            # Show cost breakdown summary\n            print(\"\\n💳 COST BREAKDOWN SUMMARY:\")\n            for component, cost in list(rfp_response.financial_proposal.cost_breakdown.items())[:5]:\n                print(f\"   • {component}: {cost}\")\n            \n            # Show key technical highlights\n            print(\"\\n🔧 TECHNICAL HIGHLIGHTS:\")\n            print(f\"   • Solution: {rfp_response.technical_proposal.solution_overview[:100]}...\")\n            \n            print(f\"\\n📊 Response document saved to: {response_output_path}\")\n            \n        else:\n            print(\"❌ Project not feasible - RFP response not recommended\")\n            print(f\"   Confidence Score: {assessment.confidence_score:.1f}%\")\n            print(f\"   Critical Gaps: {len(assessment.critical_gaps)}\")\n            print(\"   Consider addressing gaps before proceeding\")\n            \n    except Exception as e:\n        print(f\"❌ Error generating RFP response: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:49.081841Z","iopub.execute_input":"2025-07-29T15:48:49.082087Z","iopub.status.idle":"2025-07-29T15:48:49.100123Z","shell.execute_reply.started":"2025-07-29T15:48:49.082065Z","shell.execute_reply":"2025-07-29T15:48:49.099577Z"}},"outputs":[],"execution_count":180},{"cell_type":"code","source":"def main():\n    \"\"\"Main function to run the RFP feasibility analysis\"\"\"\n    \n    print(\"=\" * 70)\n    print(\"RFP RESPONSE FEASIBILITY ANALYZER v2.1\")\n    print(\"=\" * 70)\n    print(\"Comprehensive document analysis for RFP go/no-go decision making\")\n    print(\"-\" * 70)\n    \n    # Initialize the analyzer\n    analyzer = RFPFeasibilityAnalyzer()\n    \n    # Define file paths\n    file_paths = {\n        'module_matching': '/kaggle/input/input-reports-fr-agent/module-matching-report.pdf',\n        'win_loss': '/kaggle/input/input-reports-fr-agent/win_loss_analysis.pdf', \n        'gap_analysis': '/kaggle/input/input-reports-fr-agent/gap_analysis_report.pdf',\n        'customer_needs': '/kaggle/input/input-reports-fr-agent/customer_needs_report.pdf'\n    }\n    \n    print(\"\\n📁 Input Documents:\")\n    for doc_type, path in file_paths.items():\n        print(f\"   • {doc_type.replace('_', ' ').title()}: {os.path.basename(path)}\")\n    \n    print(\"\\n\" + \"-\" * 70)\n    print(\"STARTING ANALYSIS...\")\n    print(\"-\" * 70)\n    \n    try:\n        # Load and analyze documents\n        results = analyzer.load_and_analyze_documents(file_paths)\n        \n        print(\"\\n\" + \"=\" * 70)\n        print(\"EXTRACTION SUMMARY\")\n        print(\"=\" * 70)\n        print(f\"Documents Processed: {results['documents_processed']}\")\n        print(f\"Total Content Analyzed: {results['total_content_length']:,} characters\")\n        print(\"\\nExtracted Items:\")\n        for item_type, count in results['extraction_summary'].items():\n            print(f\"   • {item_type.replace('_', ' ').title()}: {count}\")\n        \n        # Display extracted modules\n        print(\"\\nModules Identified:\")\n        if analyzer.modules:\n            for module in analyzer.modules:\n                print(f\"   • {module.module_name} (Status: {module.status}, Priority: {module.client_priority}, Coverage: {module.coverage_percentage:.0f}%)\")\n        else:\n            print(\"   • No modules identified (fallback to default module may apply)\")\n        \n        # Display extracted gaps with structured format\n        print(\"\\nGaps Identified:\")\n        if analyzer.gaps:\n            for gap in analyzer.gaps:\n                print(f\"   • {gap.description}\")\n                print(f\"     Type: {gap.gap_type}, Severity: {gap.severity}\")\n        else:\n            print(\"   • No gaps identified (fallback to default gap may apply)\")\n        \n        # Calculate feasibility\n        print(\"\\n\" + \"-\" * 70)\n        print(\"CALCULATING FEASIBILITY...\")\n        print(\"-\" * 70)\n        \n        assessment = analyzer.calculate_feasibility()\n        \n        # Display results\n        print(\"\\n\" + \"=\" * 70)\n        print(\"FEASIBILITY ASSESSMENT RESULTS\")\n        print(\"=\" * 70)\n        print(f\"\\n{'✅ GO' if assessment.can_respond else '❌ NO-GO'} - {'Proceed with RFP Response' if assessment.can_respond else 'Do Not Proceed'}\")\n        print(f\"\\nConfidence Score: {assessment.confidence_score:.1f}%\")\n        print(f\"Win Probability: {assessment.win_probability:.1f}%\")\n        print(f\"\\nModule Coverage: {assessment.available_modules}/{assessment.total_modules} ({(assessment.available_modules/assessment.total_modules*100) if assessment.total_modules > 0 else 0:.0f}%)\")\n        print(f\"Critical Gaps: {len(assessment.critical_gaps)}\")\n        print(f\"Total Risks: {len(assessment.risks)}\")\n        \n        # Detailed gap summary\n        if assessment.critical_gaps:\n            print(\"\\nCritical Gaps (High/Critical Severity):\")\n            for gap in assessment.critical_gaps:\n                print(f\"   • {gap.description}\")\n                print(f\"     Type: {gap.gap_type}, Severity: {gap.severity}, Mitigation: {gap.mitigation_strategy}\")\n        \n        # Investment summary\n        print(f\"\\nInvestment Required: {assessment.investment_required}\")\n        print(f\"Timeline Estimate: {assessment.timeline_estimate}\")\n        print(f\"Resources Needed: {assessment.resource_requirements}\")\n        \n        # Top actions\n        if assessment.required_actions:\n            print(\"\\n🎯 TOP PRIORITY ACTIONS:\")\n            for i, (action, priority, timeline, owner) in enumerate(assessment.required_actions[:3], 1):\n                print(f\"   {i}. [{priority}] {action}\")\n                print(f\"      Timeline: {timeline} | Owner: {owner}\")\n        \n        # Generate PDF report\n        output_path = \"/kaggle/working/rfp_feasibility_report_enhanced.pdf\"\n        print(\"\\n\" + \"-\" * 70)\n        print(\"GENERATING COMPREHENSIVE REPORT...\")\n        print(\"-\" * 70)\n        \n        generator = RFPFeasibilityReportGenerator()\n        generator.generate_report(analyzer, assessment, output_path)\n        \n        print(\"\\n\" + \"=\" * 70)\n        print(\"✅ ANALYSIS COMPLETE!\")\n        print(\"=\" * 70)\n        print(f\"📊 Detailed report saved to: {output_path}\")\n\n        \n    except Exception as e:\n        print(f\"\\n❌ ERROR during analysis: {e}\")\n        print(\"Please verify that all input files exist and are readable at the specified paths:\")\n        for doc_type, path in file_paths.items():\n            print(f\"   • {doc_type.replace('_', ' ').title()}: {path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:49.100968Z","iopub.execute_input":"2025-07-29T15:48:49.101200Z","iopub.status.idle":"2025-07-29T15:48:49.116403Z","shell.execute_reply.started":"2025-07-29T15:48:49.101179Z","shell.execute_reply":"2025-07-29T15:48:49.115876Z"}},"outputs":[],"execution_count":181},{"cell_type":"code","source":"def main_enhanced():\n    \"\"\"Enhanced main function that generates both feasibility and response\"\"\"\n    \n    print(\"=\"*70)\n    print(\"RFP ANALYSIS & RESPONSE GENERATOR v2.1\")\n    print(\"=\"*70)\n    print(\"Complete solution: Feasibility Analysis + RFP Response\")\n    print(\"-\"*70)\n    \n    # Run original feasibility analysis\n    main()\n    \n    # Generate RFP response if feasible\n    generate_rfp_response()\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"✅ COMPLETE ANALYSIS & RESPONSE GENERATION FINISHED!\")\n    print(\"=\"*70)\n    print(\"Generated files:\")\n    print(\"   📊 Feasibility Report: /kaggle/working/rfp_feasibility_report_enhanced.pdf\")\n    print(\"   📝 RFP Response: /kaggle/working/rfp_response_proposal.pdf\")\n\n# Alternative standalone function for just RFP response generation\ndef standalone_rfp_response():\n    \"\"\"Standalone function to generate RFP response without feasibility check\"\"\"\n    \n    print(\"=\"*70)\n    print(\"STANDALONE RFP RESPONSE GENERATOR\")\n    print(\"=\"*70)\n    \n    analyzer = RFPFeasibilityAnalyzer()\n    \n    file_paths = {\n        'module_matching': '/kaggle/input/input-reports-fr-agent/module-matching-report.pdf',\n        'win_loss': '/kaggle/input/input-reports-fr-agent/win_loss_analysis.pdf', \n        'gap_analysis': '/kaggle/input/input-reports-fr-agent/gap_analysis_report.pdf',\n        'customer_needs': '/kaggle/input/input-reports-fr-agent/customer_needs_report.pdf'\n    }\n    \n    try:\n        # Load documents\n        results = analyzer.load_and_analyze_documents(file_paths)\n        assessment = analyzer.calculate_feasibility()\n        \n        # Force generate response regardless of feasibility\n        print(\"🚀 Generating RFP response (bypassing feasibility check)...\")\n        \n        response_generator = RFPResponseGenerator(analyzer.processor.llm_processor)\n        rfp_response = response_generator.generate_comprehensive_response(analyzer, assessment)\n        \n        # Generate documents\n        response_output_path = \"/kaggle/working/rfp_response_standalone.pdf\"\n        response_doc_generator = RFPResponseReportGenerator()\n        response_doc_generator.generate_rfp_response_document(rfp_response, response_output_path)\n        \n        print(f\"✅ Standalone RFP response generated: {response_output_path}\")\n        \n        # Show financial summary\n        print(\"\\n💰 FINANCIAL SUMMARY:\")\n        print(f\"   Total Cost: {rfp_response.financial_proposal.total_cost}\")\n        print(f\"   Payment Terms: Milestone-based with 20% upfront\")\n        print(f\"   ROI Expected: Positive within 24 months\")\n        \n    except Exception as e:\n        print(f\"❌ Error in standalone generation: {e}\")\n\n# Usage examples:\n# 1. Run complete analysis + response: main_enhanced()\n# 2. Run just feasibility: main() \n# 3. Run just RFP response: standalone_rfp_response()\n# 4. Run targeted response: generate_rfp_response()\n\nif __name__ == \"__main__\":\n    # Use this for complete analysis and response generation\n    standalone_rfp_response()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T15:48:49.117246Z","iopub.execute_input":"2025-07-29T15:48:49.117521Z","iopub.status.idle":"2025-07-29T15:49:29.520352Z","shell.execute_reply.started":"2025-07-29T15:48:49.117498Z","shell.execute_reply":"2025-07-29T15:49:29.519527Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nSTANDALONE RFP RESPONSE GENERATOR\n======================================================================\n","output_type":"stream"},{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"},{"name":"stdout","text":"Initialized LLMProcessor with TinyLlama/TinyLlama-1.1B-Chat-v1.0 on cuda\n\n📄 Analyzing module_matching...\n  ✓ Extracted 17127 characters\n  🤖 Running AI analysis...\n  ✓ AI insights generated\n  ✓ Extracted 13 modules\n\n📄 Analyzing win_loss...\n  ✓ Extracted 11671 characters\n  🤖 Running AI analysis...\n  ✓ AI insights generated\n  ✓ Extracted 22 win/loss factors\n\n📄 Analyzing gap_analysis...\n  ✓ Extracted 3812 characters\n  🤖 Running AI analysis...\n  ✓ AI insights generated\n  ✓ Extracted 4 gaps\n\n📄 Analyzing customer_needs...\n  ✓ Extracted 2801 characters\n  🤖 Running AI analysis...\n  ✓ AI insights generated\n  ✓ Extracted 4 requirements\n\n🤖 Generating AI insights...\n🚀 Generating RFP response (bypassing feasibility check)...\n❌ Error in standalone generation: 'RFPResponseGenerator' object has no attribute 'generate_comprehensive_response'\n","output_type":"stream"}],"execution_count":182},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}