{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas matplotlib seaborn jinja2 groq reportlab chromadb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GRbO7ERkuEBV","outputId":"c30ae843-5a58-471f-c4a5-4c00fb6dd1e5","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:40:12.876933Z","iopub.execute_input":"2025-07-31T09:40:12.877195Z","iopub.status.idle":"2025-07-31T09:40:41.793034Z","shell.execute_reply.started":"2025-07-31T09:40:12.877167Z","shell.execute_reply":"2025-07-31T09:40:41.792058Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (3.1.6)\nCollecting groq\n  Downloading groq-0.30.0-py3-none-any.whl.metadata (16 kB)\nCollecting reportlab\n  Downloading reportlab-4.4.3-py3-none-any.whl.metadata (1.7 kB)\nCollecting chromadb\n  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2) (3.0.2)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.7)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.14.0)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from reportlab) (3.4.2)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\nCollecting pybase64>=1.4.1 (from chromadb)\n  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\nRequirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\nCollecting posthog<6.0.0,>=2.4.0 (from chromadb)\n  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.2)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.73.1)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\nCollecting kubernetes>=28.1.0 (from chromadb)\n  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (8.5.0)\nRequirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\nCollecting mmh3>=4.0.1 (from chromadb)\n  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.0.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.4)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\nRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\nRequirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting protobuf (from onnxruntime>=1.14.1->chromadb)\n  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\nCollecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.33.1)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.5.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.5)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\nDownloading groq-0.30.0-py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading reportlab-4.4.3-py3-none-any.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m94.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\nDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=c6de4d24840fa193a6e030e07beee52eb0d6113ceae39d3d4f4408ce513b53a6\n  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\nSuccessfully built pypika\nInstalling collected packages: pypika, durationpy, uvloop, reportlab, python-dotenv, pybase64, protobuf, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, kubernetes, groq, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, onnxruntime, chromadb\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.31.1 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.31.1 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.31.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 durationpy-0.10 groq-0.30.0 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.2.0 onnxruntime-1.22.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 posthog-5.4.0 protobuf-6.31.1 pybase64-1.4.2 pypika-0.48.9 python-dotenv-1.1.1 reportlab-4.4.3 uvloop-0.21.0 watchfiles-1.1.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nfrom pathlib import Path\nimport logging\nimport json\nimport datetime\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass, asdict\nfrom enum import Enum\nimport logging\nfrom pathlib import Path\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom jinja2 import Template\nimport uuid\nimport re\nfrom datetime import datetime\nimport torch\nfrom transformers import pipeline\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:40:41.794091Z","iopub.execute_input":"2025-07-31T09:40:41.794378Z","iopub.status.idle":"2025-07-31T09:41:04.648439Z","shell.execute_reply.started":"2025-07-31T09:40:41.794316Z","shell.execute_reply":"2025-07-31T09:41:04.647665Z"}},"outputs":[{"name":"stderr","text":"2025-07-31 09:40:51.916850: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753954852.058747      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753954852.101286      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"# Install required packages in Colab\ndef install_requirements():\n    \"\"\"Install required packages for Colab environment\"\"\"\n    try:\n        import markdown\n        from weasyprint import HTML, CSS\n        from markdown.extensions import tables, toc\n        print(\"✅ All required packages are already installed\")\n    except ImportError:\n        print(\"📦 Installing required packages...\")\n        os.system(\"apt-get update\")\n        os.system(\"apt-get install -y wkhtmltopdf\")\n        os.system(\"pip install markdown weasyprint\")\n        print(\"✅ Installation complete!\")\n\n# Run installation\ninstall_requirements()\n\nimport markdown\nfrom weasyprint import HTML, CSS\nfrom markdown.extensions import tables, toc\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:41:04.649978Z","iopub.execute_input":"2025-07-31T09:41:04.650472Z","iopub.status.idle":"2025-07-31T09:41:38.968936Z","shell.execute_reply.started":"2025-07-31T09:41:04.650452Z","shell.execute_reply":"2025-07-31T09:41:38.968119Z"}},"outputs":[{"name":"stdout","text":"📦 Installing required packages...\nGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\nGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\nGet:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\nGet:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,853 kB]\nGet:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\nGet:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\nGet:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\nGet:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,154 kB]\nGet:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\nGet:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,270 kB]\nGet:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,519 kB]\nGet:13 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\nHit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\nGet:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,204 kB]\nGet:16 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [48.5 kB]\nGet:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,094 kB]\nGet:18 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,772 kB]\nGet:19 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [32.9 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5,290 kB]\nGet:21 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [75.9 kB]\nGet:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,575 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nGet:24 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\nGet:25 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [51.0 kB]\nFetched 34.5 MB in 3s (12.5 MB/s)\nReading package lists...\nReading package lists...","output_type":"stream"},{"name":"stderr","text":"W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","output_type":"stream"},{"name":"stdout","text":"\nBuilding dependency tree...\nReading state information...\nThe following additional packages will be installed:\n  avahi-daemon geoclue-2.0 glib-networking glib-networking-common\n  glib-networking-services gsettings-desktop-schemas iio-sensor-proxy\n  libavahi-core7 libavahi-glib1 libdaemon0 libevdev2 libgudev-1.0-0 libhyphen0\n  libinput-bin libinput10 libjson-glib-1.0-0 libjson-glib-1.0-common\n  libmbim-glib4 libmbim-proxy libmd4c0 libmm-glib0 libmtdev1 libnl-genl-3-200\n  libnotify4 libnss-mdns libproxy1v5 libqmi-glib5 libqmi-proxy libqt5core5a\n  libqt5dbus5 libqt5gui5 libqt5network5 libqt5positioning5 libqt5printsupport5\n  libqt5qml5 libqt5qmlmodels5 libqt5quick5 libqt5sensors5 libqt5svg5\n  libqt5webchannel5 libqt5webkit5 libqt5widgets5 libsoup2.4-1\n  libsoup2.4-common libudev1 libwacom-bin libwacom-common libwacom9 libwoff1\n  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 modemmanager\n  qt5-gtk-platformtheme qttranslations5-l10n session-migration\n  systemd-hwe-hwdb udev usb-modeswitch usb-modeswitch-data wpasupplicant\nSuggested packages:\n  avahi-autoipd gnome-shell | notification-daemon avahi-autoipd | zeroconf\n  qt5-image-formats-plugins qtwayland5 qt5-qmltooling-plugins comgt wvdial\n  wpagui libengine-pkcs11-openssl\nThe following NEW packages will be installed:\n  avahi-daemon geoclue-2.0 glib-networking glib-networking-common\n  glib-networking-services gsettings-desktop-schemas iio-sensor-proxy\n  libavahi-core7 libavahi-glib1 libdaemon0 libevdev2 libgudev-1.0-0 libhyphen0\n  libinput-bin libinput10 libjson-glib-1.0-0 libjson-glib-1.0-common\n  libmbim-glib4 libmbim-proxy libmd4c0 libmm-glib0 libmtdev1 libnl-genl-3-200\n  libnotify4 libnss-mdns libproxy1v5 libqmi-glib5 libqmi-proxy libqt5core5a\n  libqt5dbus5 libqt5gui5 libqt5network5 libqt5positioning5 libqt5printsupport5\n  libqt5qml5 libqt5qmlmodels5 libqt5quick5 libqt5sensors5 libqt5svg5\n  libqt5webchannel5 libqt5webkit5 libqt5widgets5 libsoup2.4-1\n  libsoup2.4-common libwacom-bin libwacom-common libwacom9 libwoff1\n  libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxkbcommon-x11-0 modemmanager\n  qt5-gtk-platformtheme qttranslations5-l10n session-migration\n  systemd-hwe-hwdb udev usb-modeswitch usb-modeswitch-data wkhtmltopdf\n  wpasupplicant\nThe following packages will be upgraded:\n  libudev1\n1 upgraded, 67 newly installed, 0 to remove and 89 not upgraded.\nNeed to get 35.5 MB of archives.\nAfter this operation, 141 MB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-core7 amd64 0.8-5ubuntu5.2 [90.8 kB]\nGet:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdaemon0 amd64 0.14-7.1ubuntu3 [14.1 kB]\nGet:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 avahi-daemon amd64 0.8-5ubuntu5.2 [69.7 kB]\nGet:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5core5a amd64 5.15.3+dfsg-2ubuntu0.2 [2,006 kB]\nGet:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevdev2 amd64 1.12.1+dfsg-1 [39.5 kB]\nGet:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmtdev1 amd64 1.1.6-1build4 [14.5 kB]\nGet:7 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libudev1 amd64 249.11-0ubuntu3.16 [76.7 kB]\nGet:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\nGet:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-common all 2.2.0-1 [54.3 kB]\nGet:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom9 amd64 2.2.0-1 [22.0 kB]\nGet:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput-bin amd64 1.20.0-1ubuntu0.3 [19.9 kB]\nGet:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput10 amd64 1.20.0-1ubuntu0.3 [131 kB]\nGet:13 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmd4c0 amd64 0.4.8-1 [42.0 kB]\nGet:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5dbus5 amd64 5.15.3+dfsg-2ubuntu0.2 [222 kB]\nGet:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5network5 amd64 5.15.3+dfsg-2ubuntu0.2 [731 kB]\nGet:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\nGet:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\nGet:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\nGet:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\nGet:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\nGet:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\nGet:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\nGet:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\nGet:25 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5gui5 amd64 5.15.3+dfsg-2ubuntu0.2 [3,722 kB]\nGet:26 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5widgets5 amd64 5.15.3+dfsg-2ubuntu0.2 [2,561 kB]\nGet:27 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5svg5 amd64 5.15.3-1 [149 kB]\nGet:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhyphen0 amd64 2.8.8-7build2 [28.2 kB]\nGet:29 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5positioning5 amd64 5.15.3+dfsg-3 [223 kB]\nGet:30 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5printsupport5 amd64 5.15.3+dfsg-2ubuntu0.2 [214 kB]\nGet:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qml5 amd64 5.15.3+dfsg-1 [1,472 kB]\nGet:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5qmlmodels5 amd64 5.15.3+dfsg-1 [205 kB]\nGet:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5quick5 amd64 5.15.3+dfsg-1 [1,748 kB]\nGet:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5sensors5 amd64 5.15.3-1 [123 kB]\nGet:35 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5webchannel5 amd64 5.15.3-1 [62.9 kB]\nGet:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwoff1 amd64 1.0.2-1build4 [45.2 kB]\nGet:37 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5webkit5 amd64 5.212.0~alpha4-15ubuntu1 [12.8 MB]\nGet:38 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 udev amd64 249.11-0ubuntu3.16 [1,557 kB]\nGet:39 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libavahi-glib1 amd64 0.8-5ubuntu5.2 [8,296 B]\nGet:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-common all 1.6.6-1build1 [4,432 B]\nGet:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 libjson-glib-1.0-0 amd64 1.6.6-1build1 [69.9 kB]\nGet:42 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmm-glib0 amd64 1.20.0-1~ubuntu22.04.4 [262 kB]\nGet:43 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libnotify4 amd64 0.7.9-3ubuntu5.22.04.1 [20.3 kB]\nGet:44 http://archive.ubuntu.com/ubuntu jammy/main amd64 libproxy1v5 amd64 0.4.17-2 [51.9 kB]\nGet:45 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-common all 2.72.0-1 [3,718 B]\nGet:46 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking-services amd64 2.72.0-1 [9,982 B]\nGet:47 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\nGet:48 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\nGet:49 http://archive.ubuntu.com/ubuntu jammy/main amd64 glib-networking amd64 2.72.0-1 [69.8 kB]\nGet:50 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-common all 2.74.2-3ubuntu0.6 [4,778 B]\nGet:51 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libsoup2.4-1 amd64 2.74.2-3ubuntu0.6 [288 kB]\nGet:52 http://archive.ubuntu.com/ubuntu jammy/main amd64 geoclue-2.0 amd64 2.5.7-3ubuntu3 [111 kB]\nGet:53 http://archive.ubuntu.com/ubuntu jammy/main amd64 iio-sensor-proxy amd64 3.3-0ubuntu6 [34.4 kB]\nGet:54 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmbim-glib4 amd64 1.28.0-1~ubuntu20.04.2 [192 kB]\nGet:55 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libmbim-proxy amd64 1.28.0-1~ubuntu20.04.2 [6,160 B]\nGet:56 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnl-genl-3-200 amd64 3.5.0-0.1 [12.4 kB]\nGet:57 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnss-mdns amd64 0.15.1-1ubuntu1 [27.0 kB]\nGet:58 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libqmi-glib5 amd64 1.32.0-1ubuntu0.22.04.1 [772 kB]\nGet:59 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libqmi-proxy amd64 1.32.0-1ubuntu0.22.04.1 [6,072 B]\nGet:60 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-bin amd64 2.2.0-1 [13.6 kB]\nGet:61 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 modemmanager amd64 1.20.0-1~ubuntu22.04.4 [1,094 kB]\nGet:62 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qt5-gtk-platformtheme amd64 5.15.3+dfsg-2ubuntu0.2 [130 kB]\nGet:63 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qttranslations5-l10n all 5.15.3-1 [1,983 kB]\nGet:64 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 systemd-hwe-hwdb all 249.11.5 [3,228 B]\nGet:65 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 wpasupplicant amd64 2:2.10-6ubuntu2.2 [1,482 kB]\nGet:66 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb-modeswitch-data all 20191128-4 [33.2 kB]\nGet:67 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb-modeswitch amd64 2.6.1-3ubuntu2 [46.0 kB]\nGet:68 http://archive.ubuntu.com/ubuntu jammy/universe amd64 wkhtmltopdf amd64 0.12.6-2 [173 kB]\nFetched 35.5 MB in 2s (21.0 MB/s)\nSelecting previously unselected package libavahi-core7:amd64.\n(Reading database ... 128663 files and directories currently installed.)\nPreparing to unpack .../0-libavahi-core7_0.8-5ubuntu5.2_amd64.deb ...\nUnpacking libavahi-core7:amd64 (0.8-5ubuntu5.2) ...\nSelecting previously unselected package libdaemon0:amd64.\nPreparing to unpack .../1-libdaemon0_0.14-7.1ubuntu3_amd64.deb ...\nUnpacking libdaemon0:amd64 (0.14-7.1ubuntu3) ...\nSelecting previously unselected package avahi-daemon.\nPreparing to unpack .../2-avahi-daemon_0.8-5ubuntu5.2_amd64.deb ...\nUnpacking avahi-daemon (0.8-5ubuntu5.2) ...\nSelecting previously unselected package libqt5core5a:amd64.\nPreparing to unpack .../3-libqt5core5a_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\nUnpacking libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSelecting previously unselected package libevdev2:amd64.\nPreparing to unpack .../4-libevdev2_1.12.1+dfsg-1_amd64.deb ...\nUnpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\nSelecting previously unselected package libmtdev1:amd64.\nPreparing to unpack .../5-libmtdev1_1.1.6-1build4_amd64.deb ...\nUnpacking libmtdev1:amd64 (1.1.6-1build4) ...\nPreparing to unpack .../6-libudev1_249.11-0ubuntu3.16_amd64.deb ...\nUnpacking libudev1:amd64 (249.11-0ubuntu3.16) over (249.11-0ubuntu3.12) ...\nSetting up libudev1:amd64 (249.11-0ubuntu3.16) ...\nSelecting previously unselected package libgudev-1.0-0:amd64.\n(Reading database ... 128732 files and directories currently installed.)\nPreparing to unpack .../00-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\nUnpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\nSelecting previously unselected package libwacom-common.\nPreparing to unpack .../01-libwacom-common_2.2.0-1_all.deb ...\nUnpacking libwacom-common (2.2.0-1) ...\nSelecting previously unselected package libwacom9:amd64.\nPreparing to unpack .../02-libwacom9_2.2.0-1_amd64.deb ...\nUnpacking libwacom9:amd64 (2.2.0-1) ...\nSelecting previously unselected package libinput-bin.\nPreparing to unpack .../03-libinput-bin_1.20.0-1ubuntu0.3_amd64.deb ...\nUnpacking libinput-bin (1.20.0-1ubuntu0.3) ...\nSelecting previously unselected package libinput10:amd64.\nPreparing to unpack .../04-libinput10_1.20.0-1ubuntu0.3_amd64.deb ...\nUnpacking libinput10:amd64 (1.20.0-1ubuntu0.3) ...\nSelecting previously unselected package libmd4c0:amd64.\nPreparing to unpack .../05-libmd4c0_0.4.8-1_amd64.deb ...\nUnpacking libmd4c0:amd64 (0.4.8-1) ...\nSelecting previously unselected package libqt5dbus5:amd64.\nPreparing to unpack .../06-libqt5dbus5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\nUnpacking libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSelecting previously unselected package libqt5network5:amd64.\nPreparing to unpack .../07-libqt5network5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\nUnpacking libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSelecting previously unselected package libxcb-icccm4:amd64.\nPreparing to unpack .../08-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\nUnpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\nSelecting previously unselected package libxcb-util1:amd64.\nPreparing to unpack .../09-libxcb-util1_0.4.0-1build2_amd64.deb ...\nUnpacking libxcb-util1:amd64 (0.4.0-1build2) ...\nSelecting previously unselected package libxcb-image0:amd64.\nPreparing to unpack .../10-libxcb-image0_0.4.0-2_amd64.deb ...\nUnpacking libxcb-image0:amd64 (0.4.0-2) ...\nSelecting previously unselected package libxcb-keysyms1:amd64.\nPreparing to unpack .../11-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\nUnpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\nSelecting previously unselected package libxcb-render-util0:amd64.\nPreparing to unpack .../12-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\nUnpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\nSelecting previously unselected package libxcb-xinerama0:amd64.\nPreparing to unpack .../13-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\nUnpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\nSelecting previously unselected package libxcb-xinput0:amd64.\nPreparing to unpack .../14-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\nUnpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\nSelecting previously unselected package libxcb-xkb1:amd64.\nPreparing to unpack .../15-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\nUnpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\nSelecting previously unselected package libxkbcommon-x11-0:amd64.\nPreparing to unpack .../16-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\nUnpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\nSelecting previously unselected package libqt5gui5:amd64.\nPreparing to unpack .../17-libqt5gui5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\nUnpacking libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSelecting previously unselected package libqt5widgets5:amd64.\nPreparing to unpack .../18-libqt5widgets5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\nUnpacking libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSelecting previously unselected package libqt5svg5:amd64.\nPreparing to unpack .../19-libqt5svg5_5.15.3-1_amd64.deb ...\nUnpacking libqt5svg5:amd64 (5.15.3-1) ...\nSelecting previously unselected package libhyphen0:amd64.\nPreparing to unpack .../20-libhyphen0_2.8.8-7build2_amd64.deb ...\nUnpacking libhyphen0:amd64 (2.8.8-7build2) ...\nSelecting previously unselected package libqt5positioning5:amd64.\nPreparing to unpack .../21-libqt5positioning5_5.15.3+dfsg-3_amd64.deb ...\nUnpacking libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\nSelecting previously unselected package libqt5printsupport5:amd64.\nPreparing to unpack .../22-libqt5printsupport5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\nUnpacking libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSelecting previously unselected package libqt5qml5:amd64.\nPreparing to unpack .../23-libqt5qml5_5.15.3+dfsg-1_amd64.deb ...\nUnpacking libqt5qml5:amd64 (5.15.3+dfsg-1) ...\nSelecting previously unselected package libqt5qmlmodels5:amd64.\nPreparing to unpack .../24-libqt5qmlmodels5_5.15.3+dfsg-1_amd64.deb ...\nUnpacking libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\nSelecting previously unselected package libqt5quick5:amd64.\nPreparing to unpack .../25-libqt5quick5_5.15.3+dfsg-1_amd64.deb ...\nUnpacking libqt5quick5:amd64 (5.15.3+dfsg-1) ...\nSelecting previously unselected package libqt5sensors5:amd64.\nPreparing to unpack .../26-libqt5sensors5_5.15.3-1_amd64.deb ...\nUnpacking libqt5sensors5:amd64 (5.15.3-1) ...\nSelecting previously unselected package libqt5webchannel5:amd64.\nPreparing to unpack .../27-libqt5webchannel5_5.15.3-1_amd64.deb ...\nUnpacking libqt5webchannel5:amd64 (5.15.3-1) ...\nSelecting previously unselected package libwoff1:amd64.\nPreparing to unpack .../28-libwoff1_1.0.2-1build4_amd64.deb ...\nUnpacking libwoff1:amd64 (1.0.2-1build4) ...\nSelecting previously unselected package libqt5webkit5:amd64.\nPreparing to unpack .../29-libqt5webkit5_5.212.0~alpha4-15ubuntu1_amd64.deb ...\nUnpacking libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\nSelecting previously unselected package udev.\nPreparing to unpack .../30-udev_249.11-0ubuntu3.16_amd64.deb ...\nUnpacking udev (249.11-0ubuntu3.16) ...\nSelecting previously unselected package libavahi-glib1:amd64.\nPreparing to unpack .../31-libavahi-glib1_0.8-5ubuntu5.2_amd64.deb ...\nUnpacking libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...\nSelecting previously unselected package libjson-glib-1.0-common.\nPreparing to unpack .../32-libjson-glib-1.0-common_1.6.6-1build1_all.deb ...\nUnpacking libjson-glib-1.0-common (1.6.6-1build1) ...\nSelecting previously unselected package libjson-glib-1.0-0:amd64.\nPreparing to unpack .../33-libjson-glib-1.0-0_1.6.6-1build1_amd64.deb ...\nUnpacking libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\nSelecting previously unselected package libmm-glib0:amd64.\nPreparing to unpack .../34-libmm-glib0_1.20.0-1~ubuntu22.04.4_amd64.deb ...\nUnpacking libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.4) ...\nSelecting previously unselected package libnotify4:amd64.\nPreparing to unpack .../35-libnotify4_0.7.9-3ubuntu5.22.04.1_amd64.deb ...\nUnpacking libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\nSelecting previously unselected package libproxy1v5:amd64.\nPreparing to unpack .../36-libproxy1v5_0.4.17-2_amd64.deb ...\nUnpacking libproxy1v5:amd64 (0.4.17-2) ...\nSelecting previously unselected package glib-networking-common.\nPreparing to unpack .../37-glib-networking-common_2.72.0-1_all.deb ...\nUnpacking glib-networking-common (2.72.0-1) ...\nSelecting previously unselected package glib-networking-services.\nPreparing to unpack .../38-glib-networking-services_2.72.0-1_amd64.deb ...\nUnpacking glib-networking-services (2.72.0-1) ...\nSelecting previously unselected package session-migration.\nPreparing to unpack .../39-session-migration_0.3.6_amd64.deb ...\nUnpacking session-migration (0.3.6) ...\nSelecting previously unselected package gsettings-desktop-schemas.\nPreparing to unpack .../40-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\nUnpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\nSelecting previously unselected package glib-networking:amd64.\nPreparing to unpack .../41-glib-networking_2.72.0-1_amd64.deb ...\nUnpacking glib-networking:amd64 (2.72.0-1) ...\nSelecting previously unselected package libsoup2.4-common.\nPreparing to unpack .../42-libsoup2.4-common_2.74.2-3ubuntu0.6_all.deb ...\nUnpacking libsoup2.4-common (2.74.2-3ubuntu0.6) ...\nSelecting previously unselected package libsoup2.4-1:amd64.\nPreparing to unpack .../43-libsoup2.4-1_2.74.2-3ubuntu0.6_amd64.deb ...\nUnpacking libsoup2.4-1:amd64 (2.74.2-3ubuntu0.6) ...\nSelecting previously unselected package geoclue-2.0.\nPreparing to unpack .../44-geoclue-2.0_2.5.7-3ubuntu3_amd64.deb ...\nUnpacking geoclue-2.0 (2.5.7-3ubuntu3) ...\nSelecting previously unselected package iio-sensor-proxy.\nPreparing to unpack .../45-iio-sensor-proxy_3.3-0ubuntu6_amd64.deb ...\nUnpacking iio-sensor-proxy (3.3-0ubuntu6) ...\nSelecting previously unselected package libmbim-glib4:amd64.\nPreparing to unpack .../46-libmbim-glib4_1.28.0-1~ubuntu20.04.2_amd64.deb ...\nUnpacking libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.2) ...\nSelecting previously unselected package libmbim-proxy.\nPreparing to unpack .../47-libmbim-proxy_1.28.0-1~ubuntu20.04.2_amd64.deb ...\nUnpacking libmbim-proxy (1.28.0-1~ubuntu20.04.2) ...\nSelecting previously unselected package libnl-genl-3-200:amd64.\nPreparing to unpack .../48-libnl-genl-3-200_3.5.0-0.1_amd64.deb ...\nUnpacking libnl-genl-3-200:amd64 (3.5.0-0.1) ...\nSelecting previously unselected package libnss-mdns:amd64.\nPreparing to unpack .../49-libnss-mdns_0.15.1-1ubuntu1_amd64.deb ...\nUnpacking libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\nSelecting previously unselected package libqmi-glib5:amd64.\nPreparing to unpack .../50-libqmi-glib5_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\nUnpacking libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\nSelecting previously unselected package libqmi-proxy.\nPreparing to unpack .../51-libqmi-proxy_1.32.0-1ubuntu0.22.04.1_amd64.deb ...\nUnpacking libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\nSelecting previously unselected package libwacom-bin.\nPreparing to unpack .../52-libwacom-bin_2.2.0-1_amd64.deb ...\nUnpacking libwacom-bin (2.2.0-1) ...\nSelecting previously unselected package modemmanager.\nPreparing to unpack .../53-modemmanager_1.20.0-1~ubuntu22.04.4_amd64.deb ...\nUnpacking modemmanager (1.20.0-1~ubuntu22.04.4) ...\nSelecting previously unselected package qt5-gtk-platformtheme:amd64.\nPreparing to unpack .../54-qt5-gtk-platformtheme_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\nUnpacking qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSelecting previously unselected package qttranslations5-l10n.\nPreparing to unpack .../55-qttranslations5-l10n_5.15.3-1_all.deb ...\nUnpacking qttranslations5-l10n (5.15.3-1) ...\nSelecting previously unselected package systemd-hwe-hwdb.\nPreparing to unpack .../56-systemd-hwe-hwdb_249.11.5_all.deb ...\nUnpacking systemd-hwe-hwdb (249.11.5) ...\nSelecting previously unselected package wpasupplicant.\nPreparing to unpack .../57-wpasupplicant_2%3a2.10-6ubuntu2.2_amd64.deb ...\nUnpacking wpasupplicant (2:2.10-6ubuntu2.2) ...\nSelecting previously unselected package usb-modeswitch-data.\nPreparing to unpack .../58-usb-modeswitch-data_20191128-4_all.deb ...\nUnpacking usb-modeswitch-data (20191128-4) ...\nSelecting previously unselected package usb-modeswitch.\nPreparing to unpack .../59-usb-modeswitch_2.6.1-3ubuntu2_amd64.deb ...\nUnpacking usb-modeswitch (2.6.1-3ubuntu2) ...\nSelecting previously unselected package wkhtmltopdf.\nPreparing to unpack .../60-wkhtmltopdf_0.12.6-2_amd64.deb ...\nUnpacking wkhtmltopdf (0.12.6-2) ...\nSetting up session-migration (0.3.6) ...\nCreated symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\nSetting up libproxy1v5:amd64 (0.4.17-2) ...\nSetting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\nSetting up libwoff1:amd64 (1.0.2-1build4) ...\nSetting up libhyphen0:amd64 (2.8.8-7build2) ...\nSetting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\nSetting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\nSetting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\nSetting up libxcb-util1:amd64 (0.4.0-1build2) ...\nSetting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\nSetting up libxcb-image0:amd64 (0.4.0-2) ...\nSetting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\nSetting up qttranslations5-l10n (5.15.3-1) ...\nSetting up libnotify4:amd64 (0.7.9-3ubuntu5.22.04.1) ...\nSetting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\nSetting up usb-modeswitch-data (20191128-4) ...\nSetting up udev (249.11-0ubuntu3.16) ...\ninvoke-rc.d: could not determine current runlevel\ninvoke-rc.d: policy-rc.d denied execution of start.\nSetting up libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSetting up libmtdev1:amd64 (1.1.6-1build4) ...\nSetting up libsoup2.4-common (2.74.2-3ubuntu0.6) ...\nSetting up systemd-hwe-hwdb (249.11.5) ...\nSetting up libmm-glib0:amd64 (1.20.0-1~ubuntu22.04.4) ...\nSetting up libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSetting up libnl-genl-3-200:amd64 (3.5.0-0.1) ...\nSetting up libmd4c0:amd64 (0.4.8-1) ...\nSetting up libavahi-glib1:amd64 (0.8-5ubuntu5.2) ...\nSetting up libjson-glib-1.0-common (1.6.6-1build1) ...\nSetting up usb-modeswitch (2.6.1-3ubuntu2) ...\nSetting up glib-networking-common (2.72.0-1) ...\nSetting up libqt5sensors5:amd64 (5.15.3-1) ...\nSetting up libdaemon0:amd64 (0.14-7.1ubuntu3) ...\nSetting up libavahi-core7:amd64 (0.8-5ubuntu5.2) ...\nSetting up libnss-mdns:amd64 (0.15.1-1ubuntu1) ...\nFirst installation detected...\nChecking NSS setup...\nSetting up libevdev2:amd64 (1.12.1+dfsg-1) ...\nSetting up libgudev-1.0-0:amd64 (1:237-2build1) ...\nSetting up libmbim-glib4:amd64 (1.28.0-1~ubuntu20.04.2) ...\nSetting up libwacom-common (2.2.0-1) ...\nSetting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\nSetting up glib-networking-services (2.72.0-1) ...\nSetting up iio-sensor-proxy (3.3-0ubuntu6) ...\nSetting up libwacom9:amd64 (2.2.0-1) ...\nSetting up libqt5positioning5:amd64 (5.15.3+dfsg-3) ...\nSetting up libmbim-proxy (1.28.0-1~ubuntu20.04.2) ...\nSetting up libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSetting up libjson-glib-1.0-0:amd64 (1.6.6-1build1) ...\nSetting up libinput-bin (1.20.0-1ubuntu0.3) ...\nSetting up wpasupplicant (2:2.10-6ubuntu2.2) ...\nCreated symlink /etc/systemd/system/dbus-fi.w1.wpa_supplicant1.service → /lib/systemd/system/wpa_supplicant.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/wpa_supplicant.service → /lib/systemd/system/wpa_supplicant.service.\nSetting up libqt5qml5:amd64 (5.15.3+dfsg-1) ...\nSetting up libqt5webchannel5:amd64 (5.15.3-1) ...\nSetting up libwacom-bin (2.2.0-1) ...\nSetting up avahi-daemon (0.8-5ubuntu5.2) ...\ninvoke-rc.d: could not determine current runlevel\ninvoke-rc.d: policy-rc.d denied execution of force-reload.\ninvoke-rc.d: could not determine current runlevel\ninvoke-rc.d: policy-rc.d denied execution of start.\nCreated symlink /etc/systemd/system/dbus-org.freedesktop.Avahi.service → /lib/systemd/system/avahi-daemon.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/avahi-daemon.service → /lib/systemd/system/avahi-daemon.service.\nCreated symlink /etc/systemd/system/sockets.target.wants/avahi-daemon.socket → /lib/systemd/system/avahi-daemon.socket.\nSetting up libinput10:amd64 (1.20.0-1ubuntu0.3) ...\nSetting up libqt5qmlmodels5:amd64 (5.15.3+dfsg-1) ...\nSetting up libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSetting up libqmi-glib5:amd64 (1.32.0-1ubuntu0.22.04.1) ...\nSetting up libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSetting up qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSetting up libqt5printsupport5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\nSetting up libqt5quick5:amd64 (5.15.3+dfsg-1) ...\nSetting up libqt5svg5:amd64 (5.15.3-1) ...\nSetting up libqmi-proxy (1.32.0-1ubuntu0.22.04.1) ...\nSetting up libqt5webkit5:amd64 (5.212.0~alpha4-15ubuntu1) ...\nSetting up modemmanager (1.20.0-1~ubuntu22.04.4) ...\nCreated symlink /etc/systemd/system/dbus-org.freedesktop.ModemManager1.service → /lib/systemd/system/ModemManager.service.\nCreated symlink /etc/systemd/system/multi-user.target.wants/ModemManager.service → /lib/systemd/system/ModemManager.service.\nSetting up wkhtmltopdf (0.12.6-2) ...\nProcessing triggers for man-db (2.10.2-1) ...\nProcessing triggers for dbus (1.12.20-2ubuntu4.1) ...\nProcessing triggers for mailcap (3.70+nmu1ubuntu1) ...\nProcessing triggers for hicolor-icon-theme (0.17-2) ...\nProcessing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.5) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\nSetting up glib-networking:amd64 (2.72.0-1) ...\nSetting up libsoup2.4-1:amd64 (2.74.2-3ubuntu0.6) ...\nSetting up geoclue-2.0 (2.5.7-3ubuntu3) ...\nProcessing triggers for libc-bin (2.35-0ubuntu3.8) ...\n/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n\n/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n\nProcessing triggers for dbus (1.12.20-2ubuntu4.1) ...\nRequirement already satisfied: markdown in /usr/local/lib/python3.11/dist-packages (3.8.2)\nCollecting weasyprint\n  Downloading weasyprint-66.0-py3-none-any.whl.metadata (3.7 kB)\nCollecting pydyf>=0.11.0 (from weasyprint)\n  Downloading pydyf-0.11.0-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (1.17.1)\nCollecting tinyhtml5>=2.0.0b1 (from weasyprint)\n  Downloading tinyhtml5-2.0.0-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: tinycss2>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (1.4.0)\nCollecting cssselect2>=0.8.0 (from weasyprint)\n  Downloading cssselect2-0.8.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting Pyphen>=0.9.1 (from weasyprint)\n  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: Pillow>=9.1.0 in /usr/local/lib/python3.11/dist-packages (from weasyprint) (11.2.1)\nRequirement already satisfied: fonttools>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from fonttools[woff]>=4.0.0->weasyprint) (4.58.4)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=0.6->weasyprint) (2.22)\nRequirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from cssselect2>=0.8.0->weasyprint) (0.5.1)\nCollecting brotli>=1.0.1 (from fonttools[woff]>=4.0.0->weasyprint)\n  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nCollecting zopfli>=0.1.4 (from fonttools[woff]>=4.0.0->weasyprint)\n  Downloading zopfli-0.2.3.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\nDownloading weasyprint-66.0-py3-none-any.whl (301 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 302.0/302.0 kB 9.2 MB/s eta 0:00:00\nDownloading cssselect2-0.8.0-py3-none-any.whl (15 kB)\nDownloading pydyf-0.11.0-py3-none-any.whl (8.1 kB)\nDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 55.9 MB/s eta 0:00:00\nDownloading tinyhtml5-2.0.0-py3-none-any.whl (39 kB)\nDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 79.0 MB/s eta 0:00:00\nDownloading zopfli-0.2.3.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (850 kB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 850.6/850.6 kB 38.7 MB/s eta 0:00:00\nInstalling collected packages: brotli, zopfli, tinyhtml5, Pyphen, pydyf, cssselect2, weasyprint\nSuccessfully installed Pyphen-0.17.2 brotli-1.1.0 cssselect2-0.8.0 pydyf-0.11.0 tinyhtml5-2.0.0 weasyprint-66.0 zopfli-0.2.3.post1\n✅ Installation complete!\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\"\"\"\nReport Agent - Système de Génération de Rapports Stratégiques\n============================================================\n\nLe Report Agent est le pilier décisionnel final du système multi-agent.\nIl centralise, agrège et synthétise les analyses pour produire un rapport stratégique complet.\n\"\"\"\n\nimport json\nfrom datetime import datetime \nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass, asdict\nfrom enum import Enum\nimport logging\nfrom pathlib import Path\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom jinja2 import Template\nimport uuid\n\n# Configuration du logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass ModuleStatus(Enum):\n    \"\"\"États possibles des modules techniques\"\"\"\n    AVAILABLE = \"disponible\"\n    TO_ADJUST = \"à_ajuster\"\n    TO_DEVELOP = \"à_développer\"\n\nclass CompetencyLevel(Enum):\n    \"\"\"Niveaux de compétences\"\"\"\n    EXPERT = \"expert\"\n    INTERMEDIATE = \"intermédiaire\"\n    BEGINNER = \"débutant\"\n    MISSING = \"manquant\"\n\nclass Priority(Enum):\n    \"\"\"Niveaux de priorité\"\"\"\n    CRITICAL = \"critique\"\n    HIGH = \"élevée\"\n    MEDIUM = \"moyenne\"\n    LOW = \"faible\"\n\n@dataclass\nclass ModuleAnalysis:\n    \"\"\"Structure des données d'analyse des modules\"\"\"\n    module_name: str\n    status: ModuleStatus\n    description: str\n    technologies: List[str]\n    complexity_score: int  # 1-10\n    development_time_weeks: int\n    dependencies: List[str]\n    risk_level: str\n    notes: str = \"\"\n\n@dataclass\nclass CompetencyGap:\n    \"\"\"Structure des données d'analyse des compétences\"\"\"\n    competency_name: str\n    current_level: CompetencyLevel\n    required_level: CompetencyLevel\n    gap_severity: Priority\n    team_members_count: int\n    training_available: bool\n    recruitment_needed: bool\n    development_plan: str\n    cost_estimate: float\n\n@dataclass\nclass ModuleMatchReport:\n    \"\"\"Rapport du Module-Match Agent\"\"\"\n    timestamp: str\n    available_modules: List[ModuleAnalysis]\n    modules_to_adjust: List[ModuleAnalysis]\n    modules_to_develop: List[ModuleAnalysis]\n    technical_summary: Dict[str, Any]\n    ml_ai_capabilities: Dict[str, str]\n    mcp_analysis: Dict[str, Any]\n\n@dataclass\nclass GapAnalysisReport:\n    \"\"\"Rapport du Gap-Analysis Agent\"\"\"\n    timestamp: str\n    existing_competencies: List[CompetencyGap]\n    competencies_to_develop: List[CompetencyGap]\n    competencies_to_recruit: List[CompetencyGap]\n    organizational_gaps: List[Dict[str, Any]]\n    strategic_recommendations: List[str]\n    budget_implications: Dict[str, float]\n\nclass ReportAgent:\n    \"\"\"\n    Agent principal de génération de rapports stratégiques\n\n    Centralise les analyses des agents spécialisés et produit\n    un rapport consolidé final pour la prise de décision.\n    \"\"\"\n\n    def __init__(self, config: Optional[Dict] = None):\n        self.config = config or self._default_config()\n        self.report_id = str(uuid.uuid4())\n        self.timestamp = datetime.now().isoformat()\n        self.module_report: Optional[ModuleMatchReport] = None\n        self.gap_report: Optional[GapAnalysisReport] = None\n\n        # Templates pour la génération de rapports\n        self.templates = self._load_templates()\n\n        logger.info(f\"Report Agent initialisé - ID: {self.report_id}\")\n\n    def _default_config(self) -> Dict:\n        \"\"\"Configuration par défaut\"\"\"\n        return {\n            \"output_format\": \"pdf\",\n            \"include_charts\": True,\n            \"language\": \"fr\",\n            \"template_style\": \"professional\",\n            \"max_recommendations\": 10,\n            \"priority_threshold\": Priority.MEDIUM\n        }\n\n    def _load_templates(self) -> Dict[str, Template]:\n        \"\"\"Charge les templates de rapport\"\"\"\n        templates = {}\n\n        # Template principal du rapport\n        main_template = \"\"\"\n# RAPPORT STRATÉGIQUE - ANALYSE TECHNIQUE ET COMPÉTENCES\n\n**ID Rapport**: {{ report_id }}\n**Date de génération**: {{ timestamp }}\n**Type**: Rapport consolidé multi-agent\n\n---\n\n## RÉSUMÉ EXÉCUTIF\n\n{{ executive_summary }}\n\n---\n\n## 1. ÉTAT ACTUEL DES MODULES TECHNIQUES ET MODÈLES IA/ML\n\n### 1.1 Modules Disponibles ({{ available_count }})\n{% for module in available_modules %}\n- **{{ module.module_name }}**\n  - Technologies: {{ module.technologies|join(', ') }}\n  - Complexité: {{ module.complexity_score }}/10\n  - Notes: {{ module.notes }}\n{% endfor %}\n\n### 1.2 Modules à Ajuster ({{ adjust_count }})\n{% for module in modules_to_adjust %}\n- **{{ module.module_name }}**\n  - Statut: {{ module.status.value }}\n  - Temps estimé: {{ module.development_time_weeks }} semaines\n  - Risque: {{ module.risk_level }}\n  - Dépendances: {{ module.dependencies|join(', ') }}\n{% endfor %}\n\n### 1.3 Modules à Développer ({{ develop_count }})\n{% for module in modules_to_develop %}\n- **{{ module.module_name }}**\n  - Description: {{ module.description }}\n  - Technologies requises: {{ module.technologies|join(', ') }}\n  - Temps de développement: {{ module.development_time_weeks }} semaines\n  - Complexité: {{ module.complexity_score }}/10\n{% endfor %}\n\n---\n\n## 2. ÉTAT DES COMPÉTENCES INTERNES\n\n### 2.1 Compétences Existantes\n{% for comp in existing_competencies %}\n- **{{ comp.competency_name }}**\n  - Niveau actuel: {{ comp.current_level.value }}\n  - Équipe: {{ comp.team_members_count }} personnes\n{% endfor %}\n\n### 2.2 Compétences à Développer\n{% for comp in competencies_to_develop %}\n- **{{ comp.competency_name }}**\n  - Gap: {{ comp.current_level.value }} → {{ comp.required_level.value }}\n  - Priorité: {{ comp.gap_severity.value }}\n  - Formation disponible: {{ 'Oui' if comp.training_available else 'Non' }}\n  - Coût estimé: {{ comp.cost_estimate }}€\n{% endfor %}\n\n### 2.3 Recrutements Nécessaires\n{% for comp in competencies_to_recruit %}\n- **{{ comp.competency_name }}**\n  - Niveau requis: {{ comp.required_level.value }}\n  - Priorité: {{ comp.gap_severity.value }}\n  - Plan de développement: {{ comp.development_plan }}\n{% endfor %}\n\n---\n\n## 3. PLAN D'ÉVOLUTION ET RECOMMANDATIONS STRATÉGIQUES\n\n### 3.1 Développement de Nouveaux Modules\n{{ module_development_plan }}\n\n### 3.2 Stratégie de Recrutement\n{{ recruitment_strategy }}\n\n### 3.3 Plans de Formation\n{{ training_plans }}\n\n### 3.4 Ajustements Organisationnels\n{{ organizational_adjustments }}\n\n---\n\n## 4. SYNTHÈSE STRATÉGIQUE\n\n### 4.1 Priorités d'Action\n{{ action_priorities }}\n\n### 4.2 Budget Global Estimé\n{{ budget_summary }}\n\n### 4.3 Timeline Recommandée\n{{ timeline }}\n\n### 4.4 Indicateurs Clés de Performance\n{{ kpis }}\n\n---\n\n## ANNEXES\n\n### A. Analyse Technique Détaillée\n{{ technical_details }}\n\n### B. Matrice des Compétences\n{{ competency_matrix }}\n\n### C. Analyse des Risques\n{{ risk_analysis }}\n\n---\n\n*Rapport généré automatiquement par le Report Agent v1.0*\n*Pour plus d'informations, contactez l'équipe technique*\n        \"\"\"\n\n        templates[\"main\"] = Template(main_template)\n        return templates\n\n    def receive_module_analysis(self, module_report: ModuleMatchReport):\n        \"\"\"Réception du rapport du Module-Match Agent\"\"\"\n        self.module_report = module_report\n        logger.info(f\"Rapport Module-Match reçu - Modules analysés: \"\n                   f\"{len(module_report.available_modules + module_report.modules_to_adjust + module_report.modules_to_develop)}\")\n\n    def receive_gap_analysis(self, gap_report: GapAnalysisReport):\n        \"\"\"Réception du rapport du Gap-Analysis Agent\"\"\"\n        self.gap_report = gap_report\n        logger.info(f\"Rapport Gap-Analysis reçu - Compétences analysées: \"\n                   f\"{len(gap_report.existing_competencies + gap_report.competencies_to_develop + gap_report.competencies_to_recruit)}\")\n\n    def validate_inputs(self) -> bool:\n        \"\"\"Validation des données d'entrée\"\"\"\n        if not self.module_report:\n            logger.error(\"Rapport Module-Match manquant\")\n            return False\n\n        if not self.gap_report:\n            logger.error(\"Rapport Gap-Analysis manquant\")\n            return False\n\n        logger.info(\"Validation des inputs réussie\")\n        return True\n\n    def analyze_and_correlate(self) -> Dict[str, Any]:\n        \"\"\"Analyse et corrélation des données des deux agents\"\"\"\n        if not self.validate_inputs():\n            raise ValueError(\"Données d'entrée invalides\")\n\n        # Analyse des corrélations entre modules et compétences\n        correlations = {\n            \"module_competency_mapping\": self._map_modules_to_competencies(),\n            \"critical_dependencies\": self._identify_critical_dependencies(),\n            \"resource_conflicts\": self._detect_resource_conflicts(),\n            \"timeline_optimization\": self._optimize_timeline(),\n            \"budget_consolidation\": self._consolidate_budgets()\n        }\n\n        logger.info(\"Analyse de corrélation terminée\")\n        return correlations\n\n    def _map_modules_to_competencies(self) -> Dict[str, List[str]]:\n        \"\"\"Cartographie des modules vers les compétences requises\"\"\"\n        mapping = {}\n\n        all_modules = (self.module_report.modules_to_adjust +\n                      self.module_report.modules_to_develop)\n\n        for module in all_modules:\n            required_competencies = []\n            for tech in module.technologies:\n                # Recherche des compétences correspondantes\n                for comp in (self.gap_report.competencies_to_develop +\n                           self.gap_report.competencies_to_recruit):\n                    if tech.lower() in comp.competency_name.lower():\n                        required_competencies.append(comp.competency_name)\n\n            mapping[module.module_name] = required_competencies\n\n        return mapping\n\n    def _identify_critical_dependencies(self) -> List[Dict[str, Any]]:\n        \"\"\"Identification des dépendances critiques\"\"\"\n        dependencies = []\n\n        for module in self.module_report.modules_to_develop:\n            if module.complexity_score >= 7:  # Modules complexes\n                dependencies.append({\n                    \"module\": module.module_name,\n                    \"type\": \"technique\",\n                    \"criticality\": \"high\",\n                    \"dependencies\": module.dependencies,\n                    \"impact\": f\"Bloque {len(module.dependencies)} autres modules\"\n                })\n\n        return dependencies\n\n    def _detect_resource_conflicts(self) -> List[Dict[str, Any]]:\n        \"\"\"Détection des conflits de ressources\"\"\"\n        conflicts = []\n\n        # Analyse des compétences sur-demandées\n        competency_demand = {}\n        for comp in self.gap_report.competencies_to_develop:\n            competency_demand[comp.competency_name] = comp.team_members_count\n\n        for comp_name, demand in competency_demand.items():\n            if demand < 2:  # Ressource limitée\n                conflicts.append({\n                    \"type\": \"competency_shortage\",\n                    \"resource\": comp_name,\n                    \"severity\": \"high\",\n                    \"recommendation\": \"Prioriser le recrutement ou la formation\"\n                })\n\n        return conflicts\n\n    def _optimize_timeline(self) -> Dict[str, Any]:\n        \"\"\"Optimisation de la timeline globale\"\"\"\n        total_weeks = 0\n        parallel_tracks = []\n\n        # Calcul du temps de développement total\n        for module in self.module_report.modules_to_develop:\n            total_weeks += module.development_time_weeks\n\n        # Calcul du temps de formation\n        training_weeks = 0\n        for comp in self.gap_report.competencies_to_develop:\n            if comp.training_available:\n                training_weeks += 8  # Estimation standard\n\n        return {\n            \"total_development_weeks\": total_weeks,\n            \"training_weeks\": training_weeks,\n            \"optimized_timeline\": max(total_weeks * 0.7, training_weeks),  # Parallélisation\n            \"critical_path\": \"Développement des modules critiques en parallèle de la formation\"\n        }\n\n    def _consolidate_budgets(self) -> Dict[str, float]:\n        \"\"\"Consolidation des budgets\"\"\"\n        budgets = {\n            \"development\": 0,\n            \"training\": 0,\n            \"recruitment\": 0,\n            \"infrastructure\": 0,\n            \"total\": 0\n        }\n\n        # Budget formation\n        for comp in self.gap_report.competencies_to_develop:\n            budgets[\"training\"] += comp.cost_estimate\n\n        # Budget recrutement (estimation)\n        budgets[\"recruitment\"] = len(self.gap_report.competencies_to_recruit) * 50000\n\n        # Budget développement\n        for module in self.module_report.modules_to_develop:\n            budgets[\"development\"] += module.development_time_weeks * 5000  # 5k€/semaine\n\n        # Budget infrastructure (estimation 20% du développement)\n        budgets[\"infrastructure\"] = budgets[\"development\"] * 0.2\n\n        budgets[\"total\"] = sum(budgets.values()) - budgets[\"total\"]\n\n        return budgets\n\n    def generate_executive_summary(self, correlations: Dict[str, Any]) -> str:\n        \"\"\"Génération du résumé exécutif\"\"\"\n        total_modules = (len(self.module_report.available_modules) +\n                        len(self.module_report.modules_to_adjust) +\n                        len(self.module_report.modules_to_develop))\n\n        total_competencies = (len(self.gap_report.existing_competencies) +\n                            len(self.gap_report.competencies_to_develop) +\n                            len(self.gap_report.competencies_to_recruit))\n\n        summary = f\"\"\"\nCe rapport consolide l'analyse de {total_modules} modules techniques et {total_competencies} compétences clés.\n\n**Points saillants:**\n- {len(self.module_report.available_modules)} modules opérationnels\n- {len(self.module_report.modules_to_develop)} nouveaux modules à développer\n- {len(self.gap_report.competencies_to_recruit)} recrutements critiques\n- Budget global estimé: {correlations['budget_consolidation']['total']:,.0f}€\n- Timeline optimisée: {correlations['timeline_optimization']['optimized_timeline']:.0f} semaines\n\n**Recommandation principale:**\nPrioriser le développement des modules critiques en parallèle du recrutement des compétences manquantes.\n        \"\"\"\n\n        return summary.strip()\n\n    def generate_visualizations(self, correlations: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Génération des graphiques et visualisations\"\"\"\n        charts = {}\n\n        # Configuration du style\n        plt.style.use('seaborn-v0_8')\n\n        # 1. Répartition des modules par statut\n        fig, ax = plt.subplots(figsize=(10, 6))\n        statuses = ['Disponibles', 'À ajuster', 'À développer']\n        counts = [\n            len(self.module_report.available_modules),\n            len(self.module_report.modules_to_adjust),\n            len(self.module_report.modules_to_develop)\n        ]\n        colors = ['#2ecc71', '#f39c12', '#e74c3c']\n\n        bars = ax.bar(statuses, counts, color=colors)\n        ax.set_title('Répartition des Modules par Statut', fontsize=14, fontweight='bold')\n        ax.set_ylabel('Nombre de modules')\n\n        # Ajout des valeurs sur les barres\n        for bar, count in zip(bars, counts):\n            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n                   str(count), ha='center', fontweight='bold')\n\n        plt.tight_layout()\n        chart_path = f\"modules_status_{self.report_id}.png\"\n        plt.savefig(chart_path, dpi=300, bbox_inches='tight')\n        charts['modules_status'] = chart_path\n        plt.close()\n\n        # 2. Matrice des compétences\n        fig, ax = plt.subplots(figsize=(12, 8))\n\n        # Préparation des données pour la heatmap\n        competencies = []\n        current_levels = []\n        required_levels = []\n\n        level_mapping = {\n            CompetencyLevel.MISSING: 0,\n            CompetencyLevel.BEGINNER: 1,\n            CompetencyLevel.INTERMEDIATE: 2,\n            CompetencyLevel.EXPERT: 3\n        }\n\n        for comp in self.gap_report.competencies_to_develop:\n            competencies.append(comp.competency_name[:20])  # Tronquer les noms longs\n            current_levels.append(level_mapping[comp.current_level])\n            required_levels.append(level_mapping[comp.required_level])\n\n        if competencies:  # Vérifier qu'il y a des données\n            data = pd.DataFrame({\n                'Compétence': competencies,\n                'Niveau Actuel': current_levels,\n                'Niveau Requis': required_levels\n            })\n\n            heatmap_data = data.set_index('Compétence')[['Niveau Actuel', 'Niveau Requis']]\n            sns.heatmap(heatmap_data, annot=True, cmap='RdYlGn', ax=ax)\n            ax.set_title('Matrice des Compétences - Gap Analysis', fontsize=14, fontweight='bold')\n\n        plt.tight_layout()\n        chart_path = f\"competency_matrix_{self.report_id}.png\"\n        plt.savefig(chart_path, dpi=300, bbox_inches='tight')\n        charts['competency_matrix'] = chart_path\n        plt.close()\n\n        return charts\n\n    def generate_consolidated_report(self) -> Dict[str, Any]:\n        \"\"\"Génération du rapport consolidé final\"\"\"\n        if not self.validate_inputs():\n            raise ValueError(\"Impossible de générer le rapport: données manquantes\")\n\n        # Analyse et corrélation des données\n        correlations = self.analyze_and_correlate()\n\n        # Génération du résumé exécutif\n        executive_summary = self.generate_executive_summary(correlations)\n\n        # Génération des visualisations\n        charts = self.generate_visualizations(correlations)\n\n        # Préparation des données pour le template\n        template_data = {\n            \"report_id\": self.report_id,\n            \"timestamp\": datetime.now().strftime(\"%d/%m/%Y %H:%M\"),\n            \"executive_summary\": executive_summary,\n\n            # Données modules\n            \"available_modules\": self.module_report.available_modules,\n            \"modules_to_adjust\": self.module_report.modules_to_adjust,\n            \"modules_to_develop\": self.module_report.modules_to_develop,\n            \"available_count\": len(self.module_report.available_modules),\n            \"adjust_count\": len(self.module_report.modules_to_adjust),\n            \"develop_count\": len(self.module_report.modules_to_develop),\n\n            # Données compétences\n            \"existing_competencies\": self.gap_report.existing_competencies,\n            \"competencies_to_develop\": self.gap_report.competencies_to_develop,\n            \"competencies_to_recruit\": self.gap_report.competencies_to_recruit,\n\n            # Plans et recommandations\n            \"module_development_plan\": self._generate_module_development_plan(correlations),\n            \"recruitment_strategy\": self._generate_recruitment_strategy(),\n            \"training_plans\": self._generate_training_plans(),\n            \"organizational_adjustments\": self._generate_organizational_adjustments(),\n\n            # Synthèse stratégique\n            \"action_priorities\": self._generate_action_priorities(correlations),\n            \"budget_summary\": self._format_budget_summary(correlations['budget_consolidation']),\n            \"timeline\": correlations['timeline_optimization'],\n            \"kpis\": self._generate_kpis(),\n\n            # Annexes\n            \"technical_details\": json.dumps(correlations, indent=2),\n            \"competency_matrix\": \"Voir graphique généré\",\n            \"risk_analysis\": self._generate_risk_analysis(correlations)\n        }\n\n        # Génération du rapport final\n        report_content = self.templates[\"main\"].render(**template_data)\n\n        # Métadonnées du rapport\n        report_metadata = {\n            \"id\": self.report_id,\n            \"timestamp\": self.timestamp,\n            \"type\": \"consolidated_strategic_report\",\n            \"sources\": [\"module_match_agent\", \"gap_analysis_agent\"],\n            \"charts_generated\": list(charts.keys()),\n            \"total_pages_estimated\": len(report_content.split('\\n')) // 50,\n            \"correlations_computed\": len(correlations),\n            \"recommendations_count\": len(self.gap_report.strategic_recommendations)\n        }\n\n        final_report = {\n            \"metadata\": report_metadata,\n            \"content\": report_content,\n            \"charts\": charts,\n            \"correlations\": correlations,\n            \"raw_data\": {\n                \"module_report\": asdict(self.module_report),\n                \"gap_report\": asdict(self.gap_report)\n            }\n        }\n\n        logger.info(f\"Rapport consolidé généré - ID: {self.report_id}\")\n        return final_report\n\n    def _generate_module_development_plan(self, correlations: Dict[str, Any]) -> str:\n        \"\"\"Génération du plan de développement des modules\"\"\"\n        plan = \"### Plan de Développement Priorisé\\n\\n\"\n\n        # Tri des modules par criticité\n        modules = sorted(self.module_report.modules_to_develop,\n                        key=lambda x: x.complexity_score, reverse=True)\n\n        for i, module in enumerate(modules[:5], 1):  # Top 5\n            plan += f\"{i}. **{module.module_name}**\\n\"\n            plan += f\"   - Priorité: {'Critique' if module.complexity_score >= 8 else 'Élevée'}\\n\"\n            plan += f\"   - Durée: {module.development_time_weeks} semaines\\n\"\n            plan += f\"   - Technologies: {', '.join(module.technologies)}\\n\\n\"\n\n        return plan\n\n    def _generate_recruitment_strategy(self) -> str:\n        \"\"\"Génération de la stratégie de recrutement\"\"\"\n        strategy = \"### Stratégie de Recrutement Ciblée\\n\\n\"\n\n        critical_recruitments = [comp for comp in self.gap_report.competencies_to_recruit\n                               if comp.gap_severity in [Priority.CRITICAL, Priority.HIGH]]\n\n        for comp in critical_recruitments:\n            strategy += f\"- **{comp.competency_name}**\\n\"\n            strategy += f\"  - Niveau requis: {comp.required_level.value}\\n\"\n            strategy += f\"  - Urgence: {comp.gap_severity.value}\\n\"\n            strategy += f\"  - Profil: {comp.development_plan}\\n\\n\"\n\n        return strategy\n\n    def _generate_training_plans(self) -> str:\n        \"\"\"Génération des plans de formation\"\"\"\n        plans = \"### Plans de Formation Recommandés\\n\\n\"\n\n        for comp in self.gap_report.competencies_to_develop:\n            if comp.training_available:\n                plans += f\"- **{comp.competency_name}**\\n\"\n                plans += f\"  - Progression: {comp.current_level.value} → {comp.required_level.value}\\n\"\n                plans += f\"  - Budget: {comp.cost_estimate}€\\n\"\n                plans += f\"  - Équipe concernée: {comp.team_members_count} personnes\\n\\n\"\n\n        return plans\n\n    def _generate_organizational_adjustments(self) -> str:\n        \"\"\"Génération des ajustements organisationnels\"\"\"\n        adjustments = \"### Ajustements Organisationnels Recommandés\\n\\n\"\n\n        for gap in self.gap_report.organizational_gaps:\n            adjustments += f\"- {gap.get('description', 'Ajustement organisationnel')}\\n\"\n            adjustments += f\"  - Impact: {gap.get('impact', 'À déterminer')}\\n\"\n            adjustments += f\"  - Timeline: {gap.get('timeline', 'Court terme')}\\n\\n\"\n\n        return adjustments\n\n    def _generate_action_priorities(self, correlations: Dict[str, Any]) -> str:\n        \"\"\"Génération des priorités d'action\"\"\"\n        priorities = \"### Priorités d'Action (Top 5)\\n\\n\"\n\n        actions = [\n            (\"Recruter des profils critiques manquants\", \"CRITIQUE\", \"Immédiat\"),\n            (\"Lancer le développement des modules prioritaires\", \"ÉLEVÉE\", \"2 semaines\"),\n            (\"Démarrer les formations internes\", \"ÉLEVÉE\", \"1 mois\"),\n            (\"Mettre en place l'infrastructure technique\", \"MOYENNE\", \"6 semaines\"),\n            (\"Ajuster l'organisation des équipes\", \"MOYENNE\", \"2 mois\")\n        ]\n\n        for i, (action, priority, timeline) in enumerate(actions, 1):\n            priorities += f\"{i}. **{action}**\\n\"\n            priorities += f\"   - Priorité: {priority}\\n\"\n            priorities += f\"   - Timeline: {timeline}\\n\\n\"\n\n        return priorities\n\n    def _format_budget_summary(self, budget: Dict[str, float]) -> str:\n        \"\"\"Formatage du résumé budgétaire\"\"\"\n        summary = \"### Budget Global Estimé\\n\\n\"\n\n        for category, amount in budget.items():\n            if category != \"total\":\n                summary += f\"- {category.capitalize()}: {amount:,.0f}€\\n\"\n\n        summary += f\"\\n**TOTAL: {budget['total']:,.0f}€**\\n\"\n        return summary\n\n    def _generate_kpis(self) -> str:\n        \"\"\"Génération des KPIs\"\"\"\n        kpis = \"### Indicateurs Clés de Performance\\n\\n\"\n\n        kpi_list = [\n            (\"Modules développés\", \"Nombre/trimestre\", \"Target: 80% des modules prioritaires\"),\n            (\"Compétences acquises\", \"Nombre/mois\", \"Target: 100% des formations critiques\"),\n            (\"Time-to-market\", \"Semaines\", \"Target: Réduction de 30%\"),\n            (\"ROI Formation\", \"€/€\", \"Target: 3:1 minimum\"),\n            (\"Satisfaction équipes\", \"Score/10\", \"Target: >8/10\")\n        ]\n\n        for kpi, unit, target in kpi_list:\n            kpis += f\"- **{kpi}** ({unit}): {target}\\n\"\n\n        return kpis\n\n    def _generate_risk_analysis(self, correlations: Dict[str, Any]) -> str:\n        \"\"\"Génération de l'analyse des risques\"\"\"\n        analysis = \"### Analyse des Risques Identifiés\\n\\n\"\n\n        risks = [\n            (\"Dépendances critiques\", \"ÉLEVÉ\", \"Retard en cascade sur les modules\"),\n            (\"Pénurie de compétences\", \"MOYEN\", \"Ralentissement du développement\"),\n            (\"Budget dépassé\", \"FAIBLE\", \"Impact sur d'autres projets\"),\n            (\"Résistance au changement\", \"MOYEN\", \"Adoption lente des nouvelles technologies\")\n        ]\n\n        for risk, level, impact in risks:\n            analysis += f\"- **{risk}**\\n\"\n            analysis += f\"  - Niveau: {level}\\n\"\n            analysis += f\"  - Impact: {impact}\\n\\n\"\n\n        return analysis\n\n    def export_report(self, report: Dict[str, Any], format_type: str = \"markdown\") -> str:\n        \"\"\"Export du rapport dans différents formats\"\"\"\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        filename = f\"rapport_strategique_{timestamp}.{format_type}\"\n\n        if format_type == \"markdown\":\n            with open(filename, 'w', encoding='utf-8') as f:\n                f.write(report['content'])\n\n        elif format_type == \"json\":\n            with open(filename, 'w', encoding='utf-8') as f:\n                json.dump(report, f, indent=2, ensure_ascii=False, default=str)\n\n        logger.info(f\"Rapport exporté: {filename}\")\n        return filename\n\n# Classes utilitaires pour la simulation des agents\n\nclass ModuleMatchAgentSimulator:\n    \"\"\"Simulateur du Module-Match Agent pour les tests\"\"\"\n\n    @staticmethod\n    def generate_sample_report() -> ModuleMatchReport:\n        \"\"\"Génère un rapport d'exemple\"\"\"\n        return ModuleMatchReport(\n            timestamp=datetime.now().isoformat(),\n            available_modules=[\n                ModuleAnalysis(\n                    module_name=\"Authentication Service\",\n                    status=ModuleStatus.AVAILABLE,\n                    description=\"Service d'authentification OAuth2\",\n                    technologies=[\"Python\", \"FastAPI\", \"JWT\"],\n                    complexity_score=5,\n                    development_time_weeks=0,\n                    dependencies=[],\n                    risk_level=\"Faible\"\n                ),\n                ModuleAnalysis(\n                    module_name=\"Data Pipeline\",\n                    status=ModuleStatus.AVAILABLE,\n                    description=\"Pipeline de traitement des données\",\n                    technologies=[\"Apache Kafka\", \"Python\", \"Docker\"],\n                    complexity_score=6,\n                    development_time_weeks=0,\n                    dependencies=[],\n                    risk_level=\"Faible\"\n                )\n            ],\n            modules_to_adjust=[\n                ModuleAnalysis(\n                    module_name=\"ML Model Serving\",\n                    status=ModuleStatus.TO_ADJUST,\n                    description=\"Service de déploiement de modèles ML\",\n                    technologies=[\"TensorFlow\", \"Kubernetes\", \"Python\"],\n                    complexity_score=7,\n                    development_time_weeks=4,\n                    dependencies=[\"Data Pipeline\"],\n                    risk_level=\"Moyen\",\n                    notes=\"Nécessite mise à jour vers TensorFlow 2.x\"\n                ),\n                ModuleAnalysis(\n                    module_name=\"API Gateway\",\n                    status=ModuleStatus.TO_ADJUST,\n                    description=\"Passerelle API avec rate limiting\",\n                    technologies=[\"Kong\", \"Lua\", \"Redis\"],\n                    complexity_score=5,\n                    development_time_weeks=2,\n                    dependencies=[\"Authentication Service\"],\n                    risk_level=\"Faible\",\n                    notes=\"Ajout des métriques de performance\"\n                )\n            ],\n            modules_to_develop=[\n                ModuleAnalysis(\n                    module_name=\"Real-time Analytics Engine\",\n                    status=ModuleStatus.TO_DEVELOP,\n                    description=\"Moteur d'analytics temps réel\",\n                    technologies=[\"Apache Flink\", \"Elasticsearch\", \"Grafana\"],\n                    complexity_score=9,\n                    development_time_weeks=12,\n                    dependencies=[\"Data Pipeline\", \"ML Model Serving\"],\n                    risk_level=\"Élevé\",\n                    notes=\"Module critique pour la prise de décision temps réel\"\n                ),\n                ModuleAnalysis(\n                    module_name=\"AI Recommendation Engine\",\n                    status=ModuleStatus.TO_DEVELOP,\n                    description=\"Moteur de recommandations basé IA\",\n                    technologies=[\"PyTorch\", \"MLflow\", \"Redis\"],\n                    complexity_score=8,\n                    development_time_weeks=10,\n                    dependencies=[\"ML Model Serving\"],\n                    risk_level=\"Élevé\",\n                    notes=\"Algorithmes de deep learning complexes\"\n                ),\n                ModuleAnalysis(\n                    module_name=\"Blockchain Integration\",\n                    status=ModuleStatus.TO_DEVELOP,\n                    description=\"Intégration blockchain pour la traçabilité\",\n                    technologies=[\"Solidity\", \"Web3.py\", \"Ethereum\"],\n                    complexity_score=8,\n                    development_time_weeks=8,\n                    dependencies=[],\n                    risk_level=\"Élevé\",\n                    notes=\"Expertise blockchain requise\"\n                )\n            ],\n            technical_summary={\n                \"total_modules_analyzed\": 7,\n                \"technology_stack_diversity\": 15,\n                \"average_complexity\": 6.7,\n                \"critical_modules_count\": 3\n            },\n            ml_ai_capabilities={\n                \"current_ml_frameworks\": \"TensorFlow 1.x, Scikit-learn\",\n                \"target_ml_frameworks\": \"TensorFlow 2.x, PyTorch, MLflow\",\n                \"ai_maturity_level\": \"Intermédiaire\",\n                \"recommendation\": \"Migration vers stack ML moderne requis\"\n            },\n            mcp_analysis={\n                \"modular_architecture_score\": 7.5,\n                \"component_reusability\": \"Élevée\",\n                \"integration_complexity\": \"Moyenne\",\n                \"scalability_rating\": \"Bonne\"\n            }\n        )\n\nclass GapAnalysisAgentSimulator:\n    \"\"\"Simulateur du Gap-Analysis Agent pour les tests\"\"\"\n\n    @staticmethod\n    def generate_sample_report() -> GapAnalysisReport:\n        \"\"\"Génère un rapport d'exemple\"\"\"\n        return GapAnalysisReport(\n            timestamp=datetime.now().isoformat(),\n            existing_competencies=[\n                CompetencyGap(\n                    competency_name=\"Python Development\",\n                    current_level=CompetencyLevel.EXPERT,\n                    required_level=CompetencyLevel.EXPERT,\n                    gap_severity=Priority.LOW,\n                    team_members_count=5,\n                    training_available=True,\n                    recruitment_needed=False,\n                    development_plan=\"Maintenir le niveau d'excellence\",\n                    cost_estimate=2000\n                ),\n                CompetencyGap(\n                    competency_name=\"DevOps/Docker\",\n                    current_level=CompetencyLevel.INTERMEDIATE,\n                    required_level=CompetencyLevel.EXPERT,\n                    gap_severity=Priority.MEDIUM,\n                    team_members_count=3,\n                    training_available=True,\n                    recruitment_needed=False,\n                    development_plan=\"Formation avancée Kubernetes\",\n                    cost_estimate=5000\n                ),\n                CompetencyGap(\n                    competency_name=\"API Design\",\n                    current_level=CompetencyLevel.INTERMEDIATE,\n                    required_level=CompetencyLevel.INTERMEDIATE,\n                    gap_severity=Priority.LOW,\n                    team_members_count=4,\n                    training_available=True,\n                    recruitment_needed=False,\n                    development_plan=\"Niveau suffisant\",\n                    cost_estimate=1000\n                )\n            ],\n            competencies_to_develop=[\n                CompetencyGap(\n                    competency_name=\"Machine Learning Engineering\",\n                    current_level=CompetencyLevel.BEGINNER,\n                    required_level=CompetencyLevel.EXPERT,\n                    gap_severity=Priority.CRITICAL,\n                    team_members_count=2,\n                    training_available=True,\n                    recruitment_needed=True,\n                    development_plan=\"Formation intensive ML + recrutement senior\",\n                    cost_estimate=15000\n                ),\n                CompetencyGap(\n                    competency_name=\"Apache Flink/Stream Processing\",\n                    current_level=CompetencyLevel.MISSING,\n                    required_level=CompetencyLevel.INTERMEDIATE,\n                    gap_severity=Priority.HIGH,\n                    team_members_count=0,\n                    training_available=True,\n                    recruitment_needed=True,\n                    development_plan=\"Formation spécialisée + consultant externe\",\n                    cost_estimate=12000\n                ),\n                CompetencyGap(\n                    competency_name=\"Elasticsearch/Search Engines\",\n                    current_level=CompetencyLevel.BEGINNER,\n                    required_level=CompetencyLevel.INTERMEDIATE,\n                    gap_severity=Priority.MEDIUM,\n                    team_members_count=1,\n                    training_available=True,\n                    recruitment_needed=False,\n                    development_plan=\"Formation certifiante Elastic\",\n                    cost_estimate=3000\n                )\n            ],\n            competencies_to_recruit=[\n                CompetencyGap(\n                    competency_name=\"Blockchain Developer\",\n                    current_level=CompetencyLevel.MISSING,\n                    required_level=CompetencyLevel.EXPERT,\n                    gap_severity=Priority.CRITICAL,\n                    team_members_count=0,\n                    training_available=False,\n                    recruitment_needed=True,\n                    development_plan=\"Recrutement développeur Solidity senior\",\n                    cost_estimate=80000\n                ),\n                CompetencyGap(\n                    competency_name=\"Deep Learning Specialist\",\n                    current_level=CompetencyLevel.MISSING,\n                    required_level=CompetencyLevel.EXPERT,\n                    gap_severity=Priority.HIGH,\n                    team_members_count=0,\n                    training_available=False,\n                    recruitment_needed=True,\n                    development_plan=\"Recrutement Data Scientist spécialisé PyTorch\",\n                    cost_estimate=75000\n                ),\n                CompetencyGap(\n                    competency_name=\"Site Reliability Engineer\",\n                    current_level=CompetencyLevel.BEGINNER,\n                    required_level=CompetencyLevel.EXPERT,\n                    gap_severity=Priority.MEDIUM,\n                    team_members_count=1,\n                    training_available=True,\n                    recruitment_needed=True,\n                    development_plan=\"Recrutement SRE senior + formation équipe\",\n                    cost_estimate=70000\n                )\n            ],\n            organizational_gaps=[\n                {\n                    \"type\": \"process\",\n                    \"description\": \"Absence de processus CI/CD standardisé\",\n                    \"impact\": \"Ralentissement des déploiements\",\n                    \"timeline\": \"Court terme\",\n                    \"solution\": \"Mise en place pipeline GitLab CI/CD\"\n                },\n                {\n                    \"type\": \"governance\",\n                    \"description\": \"Manque de gouvernance des données\",\n                    \"impact\": \"Qualité des données incertaine\",\n                    \"timeline\": \"Moyen terme\",\n                    \"solution\": \"Nomination d'un Data Steward\"\n                },\n                {\n                    \"type\": \"architecture\",\n                    \"description\": \"Architecture monolithique limitante\",\n                    \"impact\": \"Scalabilité réduite\",\n                    \"timeline\": \"Long terme\",\n                    \"solution\": \"Migration vers microservices\"\n                }\n            ],\n            strategic_recommendations=[\n                \"Prioriser le recrutement de spécialistes blockchain et ML\",\n                \"Investir massivement dans la formation continue\",\n                \"Mettre en place une cellule d'innovation technologique\",\n                \"Développer des partenariats avec des universités\",\n                \"Créer un programme de mentoring interne\",\n                \"Implémenter une stratégie de rétention des talents\",\n                \"Établir des KPIs de compétences par équipe\"\n            ],\n            budget_implications={\n                \"formation_budget\": 38000,\n                \"recruitment_budget\": 225000,\n                \"infrastructure_budget\": 50000,\n                \"total_budget\": 313000\n            }\n        )\n\n# Exemple d'utilisation et tests\ndef demonstrate_report_agent():\n    \"\"\"Démonstration complète du Report Agent\"\"\"\n\n    print(\"🚀 Initialisation du Report Agent...\")\n    agent = ReportAgent()\n\n    print(\"📥 Simulation de la réception des données des agents...\")\n\n    # Simulation des données du Module-Match Agent\n    module_simulator = ModuleMatchAgentSimulator()\n    module_report = module_simulator.generate_sample_report()\n    agent.receive_module_analysis(module_report)\n\n    # Simulation des données du Gap-Analysis Agent\n    gap_simulator = GapAnalysisAgentSimulator()\n    gap_report = gap_simulator.generate_sample_report()\n    agent.receive_gap_analysis(gap_report)\n\n    print(\"🔄 Génération du rapport consolidé...\")\n    consolidated_report = agent.generate_consolidated_report()\n\n    print(\"💾 Export du rapport...\")\n    markdown_file = agent.export_report(consolidated_report, \"markdown\")\n    json_file = agent.export_report(consolidated_report, \"json\")\n\n    print(f\"✅ Rapport généré avec succès!\")\n    print(f\"📄 Fichier Markdown: {markdown_file}\")\n    print(f\"📊 Fichier JSON: {json_file}\")\n    print(f\"🆔 ID du rapport: {consolidated_report['metadata']['id']}\")\n    print(f\"📈 Graphiques générés: {len(consolidated_report['charts'])}\")\n    print(f\"🔗 Corrélations calculées: {len(consolidated_report['correlations'])}\")\n\n    # Affichage d'un extrait du rapport\n    print(\"\\n\" + \"=\"*80)\n    print(\"EXTRAIT DU RAPPORT GÉNÉRÉ\")\n    print(\"=\"*80)\n    content_lines = consolidated_report['content'].split('\\n')\n    for line in content_lines[:50]:  # Afficher les 50 premières lignes\n        print(line)\n    print(\"\\n[...] (rapport complet dans le fichier exporté)\")\n\n    return consolidated_report, markdown_file\n\n# Classes d'API pour l'intégration\nclass ReportAgentAPI:\n    \"\"\"API REST pour le Report Agent\"\"\"\n\n    def __init__(self):\n        self.agent = ReportAgent()\n        self.reports_history = {}\n\n    def receive_module_data(self, data: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Endpoint pour recevoir les données du Module-Match Agent\"\"\"\n        try:\n            # Conversion des données JSON en objet ModuleMatchReport\n            # (Implémentation simplifiée - en production, utiliser une validation plus robuste)\n            module_report = ModuleMatchReport(**data)\n            self.agent.receive_module_analysis(module_report)\n\n            return {\n                \"status\": \"success\",\n                \"message\": \"Données du Module-Match Agent reçues\",\n                \"timestamp\": datetime.now().isoformat()\n            }\n        except Exception as e:\n            return {\n                \"status\": \"error\",\n                \"message\": f\"Erreur lors de la réception: {str(e)}\",\n                \"timestamp\": datetime.now().isoformat()\n            }\n\n    def receive_gap_data(self, data: Dict[str, Any]) -> Dict[str, str]:\n        \"\"\"Endpoint pour recevoir les données du Gap-Analysis Agent\"\"\"\n        try:\n            gap_report = GapAnalysisReport(**data)\n            self.agent.receive_gap_analysis(gap_report)\n\n            return {\n                \"status\": \"success\",\n                \"message\": \"Données du Gap-Analysis Agent reçues\",\n                \"timestamp\": datetime.now().isoformat()\n            }\n        except Exception as e:\n            return {\n                \"status\": \"error\",\n                \"message\": f\"Erreur lors de la réception: {str(e)}\",\n                \"timestamp\": datetime.now().isoformat()\n            }\n\n    def generate_report(self) -> Dict[str, Any]:\n        \"\"\"Endpoint pour générer le rapport consolidé\"\"\"\n        try:\n            report = self.agent.generate_consolidated_report()\n\n            # Sauvegarde dans l'historique\n            self.reports_history[report['metadata']['id']] = {\n                'report': report,\n                'generated_at': datetime.now().isoformat(),\n                'status': 'completed'\n            }\n\n            return {\n                \"status\": \"success\",\n                \"report_id\": report['metadata']['id'],\n                \"message\": \"Rapport généré avec succès\",\n                \"metadata\": report['metadata']\n            }\n        except Exception as e:\n            return {\n                \"status\": \"error\",\n                \"message\": f\"Erreur lors de la génération: {str(e)}\",\n                \"timestamp\": datetime.now().isoformat()\n            }\n\n    def get_report(self, report_id: str) -> Dict[str, Any]:\n        \"\"\"Endpoint pour récupérer un rapport spécifique\"\"\"\n        if report_id in self.reports_history:\n            return {\n                \"status\": \"success\",\n                \"report\": self.reports_history[report_id]['report']\n            }\n        else:\n            return {\n                \"status\": \"error\",\n                \"message\": \"Rapport non trouvé\"\n            }\n\n    def list_reports(self) -> Dict[str, Any]:\n        \"\"\"Endpoint pour lister tous les rapports\"\"\"\n        reports_list = []\n        for report_id, report_data in self.reports_history.items():\n            reports_list.append({\n                \"id\": report_id,\n                \"generated_at\": report_data['generated_at'],\n                \"status\": report_data['status'],\n                \"metadata\": report_data['report']['metadata']\n            })\n\n        return {\n            \"status\": \"success\",\n            \"reports\": reports_list,\n            \"total_count\": len(reports_list)\n        }\n\n# Classe pour la surveillance et monitoring\nclass ReportAgentMonitor:\n    \"\"\"Système de monitoring pour le Report Agent\"\"\"\n\n    def __init__(self):\n        self.metrics = {\n            \"reports_generated\": 0,\n            \"average_generation_time\": 0,\n            \"errors_count\": 0,\n            \"last_generation_time\": None,\n            \"memory_usage\": 0,\n            \"cache_hit_ratio\": 0\n        }\n        self.alerts = []\n\n    def log_report_generation(self, duration: float, success: bool):\n        \"\"\"Enregistrement des métriques de génération\"\"\"\n        if success:\n            self.metrics[\"reports_generated\"] += 1\n            # Calcul de la moyenne mobile\n            current_avg = self.metrics[\"average_generation_time\"]\n            count = self.metrics[\"reports_generated\"]\n            self.metrics[\"average_generation_time\"] = (\n                (current_avg * (count - 1) + duration) / count\n            )\n        else:\n            self.metrics[\"errors_count\"] += 1\n\n        self.metrics[\"last_generation_time\"] = datetime.now().isoformat()\n\n    def check_system_health(self) -> Dict[str, Any]:\n        \"\"\"Vérification de la santé du système\"\"\"\n        health_status = {\n            \"status\": \"healthy\",\n            \"metrics\": self.metrics,\n            \"alerts\": self.alerts,\n            \"recommendations\": []\n        }\n\n        # Vérifications de santé\n        if self.metrics[\"errors_count\"] > 5:\n            health_status[\"status\"] = \"warning\"\n            health_status[\"recommendations\"].append(\n                \"Taux d'erreur élevé - Vérifier les logs système\"\n            )\n\n        if self.metrics[\"average_generation_time\"] > 300:  # 5 minutes\n            health_status[\"status\"] = \"warning\"\n            health_status[\"recommendations\"].append(\n                \"Temps de génération élevé - Optimisation requise\"\n            )\n\n        return health_status\n\n    def generate_performance_report(self) -> str:\n        \"\"\"Génération d'un rapport de performance\"\"\"\n        report = f\"\"\"\nRAPPORT DE PERFORMANCE - REPORT AGENT\n=====================================\n\nGénéré le: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n\nMÉTRIQUES PRINCIPALES:\n- Rapports générés: {self.metrics['reports_generated']}\n- Temps moyen de génération: {self.metrics['average_generation_time']:.2f}s\n- Nombre d'erreurs: {self.metrics['errors_count']}\n- Dernière génération: {self.metrics['last_generation_time']}\n\nÉTAT DU SYSTÈME:\n{self.check_system_health()['status'].upper()}\n\nALERTES ACTIVES:\n{len(self.alerts)} alerte(s) en cours\n\nRECOMMANDATIONS:\n{chr(10).join('- ' + rec for rec in self.check_system_health()['recommendations'])}\n        \"\"\"\n\n        return report.strip()\n\n# Tests unitaires simplifiés\nclass TestReportAgent:\n    \"\"\"Tests unitaires pour le Report Agent\"\"\"\n\n    @staticmethod\n    def test_initialization():\n        \"\"\"Test d'initialisation\"\"\"\n        agent = ReportAgent()\n        assert agent.report_id is not None\n        assert agent.timestamp is not None\n        print(\"✅ Test d'initialisation réussi\")\n\n    @staticmethod\n    def test_data_reception():\n        \"\"\"Test de réception des données\"\"\"\n        agent = ReportAgent()\n\n        # Test réception données modules\n        module_report = ModuleMatchAgentSimulator.generate_sample_report()\n        agent.receive_module_analysis(module_report)\n        assert agent.module_report is not None\n\n        # Test réception données gaps\n        gap_report = GapAnalysisAgentSimulator.generate_sample_report()\n        agent.receive_gap_analysis(gap_report)\n        assert agent.gap_report is not None\n\n        print(\"✅ Test de réception des données réussi\")\n\n    @staticmethod\n    def test_report_generation():\n        \"\"\"Test de génération de rapport\"\"\"\n        agent = ReportAgent()\n\n        # Préparation des données\n        module_report = ModuleMatchAgentSimulator.generate_sample_report()\n        gap_report = GapAnalysisAgentSimulator.generate_sample_report()\n\n        agent.receive_module_analysis(module_report)\n        agent.receive_gap_analysis(gap_report)\n\n        # Génération du rapport\n        report = agent.generate_consolidated_report()\n\n        assert report is not None\n        assert 'metadata' in report\n        assert 'content' in report\n        assert 'correlations' in report\n\n        print(\"✅ Test de génération de rapport réussi\")\n\n    @staticmethod\n    def run_all_tests():\n        \"\"\"Exécution de tous les tests\"\"\"\n        print(\"\\n🧪 LANCEMENT DES TESTS UNITAIRES\")\n        print(\"=\" * 50)\n\n        TestReportAgent.test_initialization()\n        TestReportAgent.test_data_reception()\n        TestReportAgent.test_report_generation()\n\n        print(\"\\n✅ TOUS LES TESTS RÉUSSIS!\")\n\nif __name__ == \"__main__\":\n    print(\"🎯 REPORT AGENT - SYSTÈME DE GÉNÉRATION DE RAPPORTS STRATÉGIQUES\")\n    print(\"=\" * 80)\n\n    # Exécution des tests\n    TestReportAgent.run_all_tests()\n\n    # Démonstration complète\n    print(\"\\n\" + \"=\" * 80)\n    print(\"🚀 DÉMONSTRATION COMPLÈTE\")\n    print(\"=\" * 80)\n\n    report, markdown_file = demonstrate_report_agent()\n\n    # Monitoring\n    print(\"\\n\" + \"=\" * 80)\n    print(\"📊 MONITORING DU SYSTÈME\")\n    print(\"=\" * 80)\n\n    monitor = ReportAgentMonitor()\n    monitor.log_report_generation(45.2, True)  # Simulation\n    print(monitor.generate_performance_report())\n\n    print(\"\\n✅ Démonstration terminée avec succès!\")\n    print(f\"📋 Le rapport complet est disponible avec l'ID: {report['metadata']['id']}\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cla0P3AHt1AT","outputId":"19d4cf8a-80a7-4b39-ae74-d6a19a07eb91","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:41:38.970310Z","iopub.execute_input":"2025-07-31T09:41:38.970867Z","iopub.status.idle":"2025-07-31T09:41:41.239063Z","shell.execute_reply.started":"2025-07-31T09:41:38.970847Z","shell.execute_reply":"2025-07-31T09:41:41.238267Z"}},"outputs":[{"name":"stdout","text":"🎯 REPORT AGENT - SYSTÈME DE GÉNÉRATION DE RAPPORTS STRATÉGIQUES\n================================================================================\n\n🧪 LANCEMENT DES TESTS UNITAIRES\n==================================================\n✅ Test d'initialisation réussi\n✅ Test de réception des données réussi\n✅ Test de génération de rapport réussi\n\n✅ TOUS LES TESTS RÉUSSIS!\n\n================================================================================\n🚀 DÉMONSTRATION COMPLÈTE\n================================================================================\n🚀 Initialisation du Report Agent...\n📥 Simulation de la réception des données des agents...\n🔄 Génération du rapport consolidé...\n💾 Export du rapport...\n✅ Rapport généré avec succès!\n📄 Fichier Markdown: rapport_strategique_20250731_094141.markdown\n📊 Fichier JSON: rapport_strategique_20250731_094141.json\n🆔 ID du rapport: 8bbecda7-b6ab-40ca-941e-8d547c6c3caf\n📈 Graphiques générés: 2\n🔗 Corrélations calculées: 5\n\n================================================================================\nEXTRAIT DU RAPPORT GÉNÉRÉ\n================================================================================\n\n# RAPPORT STRATÉGIQUE - ANALYSE TECHNIQUE ET COMPÉTENCES\n\n**ID Rapport**: 8bbecda7-b6ab-40ca-941e-8d547c6c3caf\n**Date de génération**: 31/07/2025 09:41\n**Type**: Rapport consolidé multi-agent\n\n---\n\n## RÉSUMÉ EXÉCUTIF\n\nCe rapport consolide l'analyse de 7 modules techniques et 9 compétences clés.\n\n**Points saillants:**\n- 2 modules opérationnels\n- 3 nouveaux modules à développer\n- 3 recrutements critiques\n- Budget global estimé: 360,000€\n- Timeline optimisée: 24 semaines\n\n**Recommandation principale:**\nPrioriser le développement des modules critiques en parallèle du recrutement des compétences manquantes.\n\n---\n\n## 1. ÉTAT ACTUEL DES MODULES TECHNIQUES ET MODÈLES IA/ML\n\n### 1.1 Modules Disponibles (2)\n\n- **Authentication Service**\n  - Technologies: Python, FastAPI, JWT\n  - Complexité: 5/10\n  - Notes: \n\n- **Data Pipeline**\n  - Technologies: Apache Kafka, Python, Docker\n  - Complexité: 6/10\n  - Notes: \n\n\n### 1.2 Modules à Ajuster (2)\n\n- **ML Model Serving**\n  - Statut: à_ajuster\n  - Temps estimé: 4 semaines\n  - Risque: Moyen\n  - Dépendances: Data Pipeline\n\n- **API Gateway**\n  - Statut: à_ajuster\n\n[...] (rapport complet dans le fichier exporté)\n\n================================================================================\n📊 MONITORING DU SYSTÈME\n================================================================================\nRAPPORT DE PERFORMANCE - REPORT AGENT\n=====================================\n\nGénéré le: 31/07/2025 09:41:41\n\nMÉTRIQUES PRINCIPALES:\n- Rapports générés: 1\n- Temps moyen de génération: 45.20s\n- Nombre d'erreurs: 0\n- Dernière génération: 2025-07-31T09:41:41.235473\n\nÉTAT DU SYSTÈME:\nHEALTHY\n\nALERTES ACTIVES:\n0 alerte(s) en cours\n\nRECOMMANDATIONS:\n\n✅ Démonstration terminée avec succès!\n📋 Le rapport complet est disponible avec l'ID: 8bbecda7-b6ab-40ca-941e-8d547c6c3caf\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class RFPResponseGenerator:\n    def __init__(self, strategic_report_path: str):\n        \"\"\"\n        Initialise le générateur de réponse RFP avec le rapport stratégique\n        \"\"\"\n        self.strategic_report = self.load_strategic_report(strategic_report_path)\n        self.pipe = pipeline(\n            \"text-generation\",\n            model=\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n            torch_dtype=torch.bfloat16,\n            device_map=\"auto\"\n        )\n\n        # Configuration pour la génération\n        self.generation_config = {\n            \"max_new_tokens\": 512,\n            \"temperature\": 0.7,\n            \"do_sample\": True,\n            \"top_p\": 0.9,\n            \"pad_token_id\": self.pipe.tokenizer.eos_token_id\n        }\n\n    def load_strategic_report(self, file_path: str) -> Dict:\n        \"\"\"Charge et parse le rapport stratégique\"\"\"\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n\n            # Extraction des données structurées du rapport\n            report_data = self.extract_report_data(content)\n            return report_data\n        except FileNotFoundError:\n            print(f\"⚠️  Fichier non trouvé: {file_path}\")\n            print(\"📄 Utilisation des données par défaut du rapport\")\n            return self.get_default_report_data()\n        except Exception as e:\n            print(f\"⚠️  Erreur lors du chargement du rapport: {e}\")\n            print(\"📄 Utilisation des données par défaut du rapport\")\n            return self.get_default_report_data()\n\n    def get_default_report_data(self) -> Dict:\n        \"\"\"Retourne les données par défaut basées sur le rapport stratégique fourni\"\"\"\n        return {\n            \"modules_operationnels\": [\n                {\"name\": \"Authentication Service\", \"technologies\": [\"Python\", \"FastAPI\", \"JWT\"], \"status\": \"Production-ready\"},\n                {\"name\": \"Data Pipeline\", \"technologies\": [\"Apache Kafka\", \"Python\", \"Docker\"], \"status\": \"Production-ready\"}\n            ],\n            \"modules_optimisation\": [\n                {\"name\": \"ML Model Serving\", \"status\": \"Continuous optimization\", \"timeline\": \"4 weeks\"},\n                {\"name\": \"API Gateway\", \"status\": \"Performance enhancement\", \"timeline\": \"2 weeks\"}\n            ],\n            \"competences_existantes\": [\n                {\"skill\": \"Python Development\", \"level\": \"Expert\", \"team_size\": 5},\n                {\"skill\": \"DevOps/Docker\", \"level\": \"Advanced\", \"team_size\": 3},\n                {\"skill\": \"API Design\", \"level\": \"Advanced\", \"team_size\": 4}\n            ],\n            \"competences_strategiques\": [\n                {\"domain\": \"Machine Learning Engineering\", \"investment\": \"15000€\", \"strategic_value\": \"Critical\"},\n                {\"domain\": \"Apache Flink/Stream Processing\", \"investment\": \"12000€\", \"strategic_value\": \"High\"},\n                {\"domain\": \"Elasticsearch/Search Engines\", \"investment\": \"3000€\", \"strategic_value\": \"Medium\"}\n            ],\n            \"budget_total\": 360000,\n            \"timeline\": 24,\n            \"equipe_size\": 12,\n            \"technologies\": [\n                \"Python\", \"FastAPI\", \"JWT\", \"Apache Kafka\", \"Docker\",\n                \"PyTorch\", \"MLflow\", \"Redis\", \"Apache Flink\", \"Elasticsearch\",\n                \"Grafana\", \"Solidity\", \"Web3.py\", \"Ethereum\"\n            ],\n            \"projets_references\": []\n        }\n\n    def extract_report_data(self, content: str) -> Dict:\n        \"\"\"Extrait les données clés du rapport stratégique\"\"\"\n        data = {\n            \"modules_operationnels\": [],\n            \"modules_optimisation\": [],\n            \"competences_existantes\": [],\n            \"competences_strategiques\": [],\n            \"budget_total\": 360000,  # Valeur par défaut du rapport\n            \"timeline\": 24,  # Valeur par défaut du rapport\n            \"equipe_size\": 12,  # Valeur par défaut\n            \"technologies\": [],\n            \"projets_references\": []\n        }\n\n        try:\n            # Extraction des modules opérationnels\n            if \"Authentication Service\" in content:\n                data[\"modules_operationnels\"].append({\n                    \"name\": \"Authentication Service\",\n                    \"technologies\": [\"Python\", \"FastAPI\", \"JWT\"],\n                    \"status\": \"Production-ready\"\n                })\n\n            if \"Data Pipeline\" in content:\n                data[\"modules_operationnels\"].append({\n                    \"name\": \"Data Pipeline\",\n                    \"technologies\": [\"Apache Kafka\", \"Python\", \"Docker\"],\n                    \"status\": \"Production-ready\"\n                })\n\n            # Transformation des modules à ajuster en modules d'optimisation\n            if \"ML Model Serving\" in content:\n                data[\"modules_optimisation\"].append({\n                    \"name\": \"ML Model Serving\",\n                    \"status\": \"Continuous optimization\",\n                    \"timeline\": \"4 weeks\"\n                })\n\n            if \"API Gateway\" in content:\n                data[\"modules_optimisation\"].append({\n                    \"name\": \"API Gateway\",\n                    \"status\": \"Performance enhancement\",\n                    \"timeline\": \"2 weeks\"\n                })\n\n            # Extraction des compétences existantes\n            data[\"competences_existantes\"] = [\n                {\"skill\": \"Python Development\", \"level\": \"Expert\", \"team_size\": 5},\n                {\"skill\": \"DevOps/Docker\", \"level\": \"Advanced\", \"team_size\": 3},\n                {\"skill\": \"API Design\", \"level\": \"Advanced\", \"team_size\": 4}\n            ]\n\n            # Transformation des compétences à développer en domaines d'expertise stratégiques\n            data[\"competences_strategiques\"] = [\n                {\"domain\": \"Machine Learning Engineering\", \"investment\": \"15000€\", \"strategic_value\": \"Critical\"},\n                {\"domain\": \"Apache Flink/Stream Processing\", \"investment\": \"12000€\", \"strategic_value\": \"High\"},\n                {\"domain\": \"Elasticsearch/Search Engines\", \"investment\": \"3000€\", \"strategic_value\": \"Medium\"}\n            ]\n\n            # Extraction budget et timeline avec regex plus robuste\n            budget_patterns = [r'360,000€', r'360000€', r'360\\.000€', r'TOTAL:\\s*(\\d{3}[,.]?\\d{3})€']\n            for pattern in budget_patterns:\n                budget_match = re.search(pattern, content)\n                if budget_match:\n                    if len(budget_match.groups()) > 0:\n                        budget_str = budget_match.group(1).replace(',', '').replace('.', '')\n                        data[\"budget_total\"] = int(budget_str)\n                    else:\n                        data[\"budget_total\"] = 360000\n                    break\n\n            timeline_patterns = [r'24 semaines', r'optimized_timeline[\\'\\\"]\\s*:\\s*(\\d+)', r'timeline.*?(\\d+).*semaines']\n            for pattern in timeline_patterns:\n                timeline_match = re.search(pattern, content, re.IGNORECASE)\n                if timeline_match:\n                    if len(timeline_match.groups()) > 0:\n                        data[\"timeline\"] = int(timeline_match.group(1))\n                    else:\n                        data[\"timeline\"] = 24\n                    break\n\n            # Calcul taille équipe\n            data[\"equipe_size\"] = sum([comp[\"team_size\"] for comp in data[\"competences_existantes\"]])\n\n            # Technologies maîtrisées extraites du rapport\n            tech_patterns = [\n                r'Technologies:\\s*([^Notes]+)',\n                r'Technologies requises:\\s*([^\\n]+)',\n                r'(Python|FastAPI|JWT|Apache Kafka|Docker|PyTorch|MLflow|Redis|Apache Flink|Elasticsearch|Grafana|Solidity|Web3\\.py|Ethereum)'\n            ]\n\n            technologies_found = set()\n            for pattern in tech_patterns:\n                matches = re.findall(pattern, content, re.IGNORECASE)\n                for match in matches:\n                    if isinstance(match, str):\n                        # Nettoyage et extraction des technologies\n                        techs = re.findall(r'[A-Za-z][A-Za-z0-9\\./]*', match)\n                        technologies_found.update(techs)\n\n            # Technologies par défaut si aucune trouvée\n            if not technologies_found:\n                technologies_found = {\n                    \"Python\", \"FastAPI\", \"JWT\", \"Apache Kafka\", \"Docker\",\n                    \"PyTorch\", \"MLflow\", \"Redis\", \"Apache Flink\", \"Elasticsearch\",\n                    \"Grafana\", \"Solidity\", \"Web3.py\", \"Ethereum\"\n                }\n\n            data[\"technologies\"] = list(technologies_found)[:14]  # Limite à 14 technologies\n\n        except Exception as e:\n            print(f\"Erreur lors de l'extraction des données: {e}\")\n            # Utilisation des valeurs par défaut en cas d'erreur\n\n        # Validation des données minimales\n        if not data[\"modules_operationnels\"]:\n            data[\"modules_operationnels\"] = [\n                {\"name\": \"Authentication Service\", \"technologies\": [\"Python\", \"FastAPI\", \"JWT\"], \"status\": \"Production-ready\"},\n                {\"name\": \"Data Pipeline\", \"technologies\": [\"Apache Kafka\", \"Python\", \"Docker\"], \"status\": \"Production-ready\"}\n            ]\n\n        if not data[\"technologies\"]:\n            data[\"technologies\"] = [\"Python\", \"FastAPI\", \"JWT\", \"Apache Kafka\", \"Docker\", \"PyTorch\", \"MLflow\", \"Redis\"]\n\n        return data\n\n    def generate_professional_content(self, prompt: str, context: str = \"\") -> str:\n        \"\"\"Génère du contenu professionnel avec le modèle\"\"\"\n        full_prompt = f\"\"\"<|system|>\nVous êtes un expert en rédaction de propositions commerciales techniques. Rédigez un contenu professionnel, convaincant et détaillé pour une réponse RFP. Le ton doit être confiant, technique mais accessible, et mettre en avant les points forts.\n\n<|user|>\nContexte: {context}\n\nDemande: {prompt}\n\nRédigez un paragraphe professionnel et convaincant qui répond parfaitement à cette demande en mettant en avant nos atouts techniques et notre expertise.\n\n<|assistant|>\"\"\"\n\n        try:\n            result = self.pipe(full_prompt, **self.generation_config)\n            generated_text = result[0]['generated_text']\n\n            # Extraction de la réponse (après <|assistant|>)\n            response = generated_text.split(\"<|assistant|>\")[-1].strip()\n\n            # Nettoyage et formatage\n            response = re.sub(r'\\n+', '\\n\\n', response)\n            response = response.replace('*', '').replace('#', '')\n\n            return response\n        except Exception as e:\n            print(f\"Erreur génération: {e}\")\n            return \"Contenu généré automatiquement non disponible.\"\n\n    def generate_rfp_response(self, company_info: Dict) -> str:\n        \"\"\"Génère la réponse RFP complète en Markdown\"\"\"\n\n        current_date = datetime.now().strftime(\"%d/%m/%Y\")\n\n        markdown_content = f\"\"\"# Request for Proposal (RFP) Response Form\n\n**{company_info['company_name']}**\n*Excellence Technique et Innovation Stratégique*\n\n---\n\n**Date de cette Proposition:** {current_date}\n**En réponse à:** [Référence RFP]\n**Par:** {company_info['company_name']}\n\n---\n\n## SECTION 1: About the Respondent\n\n### 1.1 Our Profile\n\nCette proposition est soumise par **{company_info['company_name']}** (le Répondant) pour fournir les exigences spécifiées.\n\n| Item | Detail |\n|------|---------|\n| **Nom légal complet** | {company_info['company_name']} |\n| **Nom commercial** | {company_info.get('trading_name', 'N/A')} |\n| **Adresse physique** | {company_info['address']} |\n| **Site web** | {company_info['website']} |\n| **Type d'entité** | {company_info['entity_type']} |\n| **Pays de résidence** | {company_info['country']} |\n\n### 1.2 Our Point of Contact\n\n| Item | Detail |\n|------|---------|\n| **Personne de contact** | {company_info['contact_name']} |\n| **Position** | {company_info['contact_position']} |\n| **Téléphone** | {company_info['phone']} |\n| **Email** | {company_info['email']} |\n\n---\n\n## SECTION 2: Response to the Requirements\n\n### 2.1 Pre-conditions\n\n| # | Pre-condition | Meets |\n|---|---------------|-------|\n| 1 | Capacité technique démontrée | **Oui** |\n| 2 | Équipe qualifiée et certifiée | **Oui** |\n| 3 | Infrastructure opérationnelle | **Oui** |\n\n### 2.2 Overview of Our Solution\n\n{self.generate_professional_content(\n    \"Rédigez un aperçu complet de notre solution technique en mettant l'accent sur nos modules opérationnels, notre expertise et notre approche innovante.\",\n    f\"Nous avons {len(self.strategic_report['modules_operationnels'])} modules opérationnels en production, une équipe de {self.strategic_report['equipe_size']} experts, et un budget d'investissement stratégique de {self.strategic_report['budget_total']}€.\"\n)}\n\n---\n\n## SECTION 3: Evaluation Criteria and Price\n\n### Part A – Non-Price Evaluation Criteria\n\n#### 1. Track Record (Weighting: 30%)\n\n**a. Experience de notre organisation dans la livraison des services requis**\n\n{self.generate_professional_content(\n    \"Décrivez notre expérience approfondie dans la livraison de solutions techniques similaires, en mettant l'accent sur nos modules opérationnels et notre expertise.\",\n    f\"Modules opérationnels: {', '.join([m['name'] for m in self.strategic_report['modules_operationnels']])}. Technologies maîtrisées: {', '.join(self.strategic_report['technologies'][:8])}.\"\n)}\n\n**b. Expérience spécifique pertinente pour cette opportunité**\n\n{self.generate_professional_content(\n    \"Détaillez notre expérience spécifique qui nous rend uniques pour ce projet, incluant notre approche d'optimisation continue et notre capacité d'adaptation.\",\n    f\"Modules en optimisation continue: {len(self.strategic_report['modules_optimisation'])} modules. Timeline d'optimisation: {self.strategic_report['timeline']} semaines.\"\n)}\n\n**c. Trois exemples de contrats précédents démontrant notre capacité**\n\n{self.generate_professional_content(\n    \"Présentez trois projets de référence qui illustrent parfaitement notre expertise technique, notre capacité de livraison et notre approche de gestion de la qualité.\",\n    \"Projets incluant des systèmes d'authentification, pipelines de données, et solutions ML en production avec des clients de premier plan.\"\n)}\n\n#### 2. Capability of the Respondent to Deliver (Weighting: 25%)\n\n**a. Équipements et infrastructures pour la livraison**\n\n{self.generate_professional_content(\n    \"Décrivez notre infrastructure technique robuste et nos équipements de pointe qui garantissent une livraison de qualité supérieure.\",\n    f\"Technologies de production: {', '.join(self.strategic_report['technologies'][:6])}. Modules opérationnels: {len(self.strategic_report['modules_operationnels'])} en production.\"\n)}\n\n**b. Équipe clé et qualifications**\n\n{self.generate_professional_content(\n    \"Présentez notre équipe d'experts hautement qualifiés et leur expertise technique approfondie dans les domaines critiques du projet.\",\n    f\"Équipe de {self.strategic_report['equipe_size']} experts techniques. Compétences expertes en Python Development (5 personnes), DevOps/Docker (3 personnes), API Design (4 personnes).\"\n)}\n\n**c. Développement et maintien des compétences techniques**\n\n{self.generate_professional_content(\n    \"Décrivez notre approche proactive de formation continue et d'investissement dans les compétences stratégiques de notre équipe.\",\n    f\"Investissement formation: {sum([int(comp['investment'].replace('€', '')) for comp in self.strategic_report['competences_strategiques']])}€ en compétences stratégiques.\"\n)}\n\n**d. Réseau de sous-traitants spécialisés**\n\n{self.generate_professional_content(\n    \"Présentez notre réseau stratégique de partenaires techniques spécialisés qui complètent parfaitement nos compétences internes.\",\n    \"Réseau de partenaires experts en blockchain, deep learning, et ingénierie de fiabilité des systèmes.\"\n)}\n\n#### 3. Capacity of the Respondent to Deliver (Weighting: 20%)\n\n**a. Historique de livraison de services similaires**\n\n{self.generate_professional_content(\n    \"Démontrez notre track record exceptionnel de livraison dans les délais, selon les spécifications et dans le budget imparti.\",\n    f\"Timeline optimisée de {self.strategic_report['timeline']} semaines. Budget maîtrisé de {self.strategic_report['budget_total']}€.\"\n)}\n\n**b. Interaction avec les parties prenantes clés**\n\n{self.generate_professional_content(\n    \"Décrivez notre approche collaborative et notre structure organisationnelle optimisée pour une communication efficace avec tous les stakeholders.\",\n    f\"Équipe structurée de {self.strategic_report['equipe_size']} experts avec des rôles clairement définis et des processus de communication standardisés.\"\n)}\n\n**c. Gestion des travaux hors périmètre**\n\n{self.generate_professional_content(\n    \"Expliquez notre approche flexible et réactive pour gérer les demandes additionnelles tout en maintenant la qualité et les délais.\",\n    \"Processus agiles et équipe extensible avec des partenaires stratégiques pour une réactivité maximale.\"\n)}\n\n**d. Structure et capacité organisationnelle**\n\n{self.generate_professional_content(\n    \"Présentez la robustesse de notre organisation, notre structure financière solide et notre capacité à livrer des projets complexes.\",\n    f\"Structure organisationnelle avec {self.strategic_report['equipe_size']} experts techniques. Budget projet de {self.strategic_report['budget_total']}€ démontrant notre capacité financière.\"\n)}\n\n**e. Systèmes opérationnels et financiers**\n\n{self.generate_professional_content(\n    \"Décrivez nos systèmes de gestion avancés qui assurent un suivi précis et une livraison optimisée de tous nos projets.\",\n    \"Systèmes de tracking et de gestion intégrés avec nos modules opérationnels pour une visibilité complète.\"\n)}\n\n#### 4. Proposed Solution (Weighting: 25%)\n\n**a. Comment notre solution répond ou dépasse vos exigences**\n\n{self.generate_professional_content(\n    \"Démontrez comment notre solution technique innovante non seulement répond parfaitement aux exigences mais les dépasse significativement.\",\n    f\"Modules opérationnels: {', '.join([m['name'] for m in self.strategic_report['modules_operationnels']])}. Modules d'optimisation: {', '.join([m['name'] for m in self.strategic_report['modules_optimisation']])}.\"\n)}\n\n**b. Mesure de la qualité dans notre approche**\n\n{self.generate_professional_content(\n    \"Expliquez nos métriques de qualité rigoureuses et nos processus d'assurance qualité qui garantissent une livraison d'excellence.\",\n    \"Processus d'optimisation continue sur nos modules et métriques de performance avancées.\"\n)}\n\n**c. Idées nouvelles et processus innovants**\n\n{self.generate_professional_content(\n    \"Présentez nos innovations techniques uniques et les bénéfices mesurables qu'elles apportent en termes d'efficacité et de qualité.\",\n    f\"Technologies de pointe: {', '.join(self.strategic_report['technologies'][-6:])}. Approche d'optimisation continue sur {self.strategic_report['timeline']} semaines.\"\n)}\n\n**d. Gestion des risques et mitigation**\n\n{self.generate_professional_content(\n    \"Détaillez notre approche proactive de gestion des risques et nos stratégies de mitigation éprouvées.\",\n    \"Modules opérationnels en production garantissant la stabilité. Processus d'optimisation continue pour l'amélioration permanente.\"\n)}\n\n### Part B – Price\n\n#### 3.2 Price as a Weighted criterion\n\n**Public Value (based on whole-of-life cost)**\n\nNotre proposition représente une valeur exceptionnelle avec un investissement total de **{self.strategic_report['budget_total']:,}€** réparti stratégiquement sur {self.strategic_report['timeline']} semaines.\n\n**Répartition budgétaire optimisée:**\n- Développement technique: 150,000€\n- Formation et montée en compétences: 30,000€\n- Recrutement stratégique: 150,000€\n- Infrastructure: 30,000€\n\nCette structure budgétaire garantit un ROI optimal et une livraison dans les délais impartis.\n\n#### 3.3 Pricing Schedule\n\n| Milestone | Date Estimée | Montant (HT) |\n|-----------|--------------|--------------|\n| Kick-off et analyse détaillée | Semaine 2 | €72,000 |\n| Développement modules critiques | Semaine 12 | €144,000 |\n| Optimisation et tests | Semaine 20 | €72,000 |\n| Livraison finale et formation | Semaine 24 | €72,000 |\n| **TOTAL** | | **€360,000** |\n\n#### 3.4 Assumptions\n\nNos estimations sont basées sur:\n- Accès aux environnements de développement dans les délais convenus\n- Disponibilité des parties prenantes clés selon le planning défini\n- Infrastructure technique existante compatible avec nos modules\n- Formation dispensée sur site ou en mode hybride selon les préférences\n\n---\n\n## SECTION 4: Proposed Contract\n\nAprès lecture et compréhension du Contrat Proposé dans la Section 5 du RFP, je confirme que ces termes et conditions sont acceptables. En cas de succès, j'accepte de signer un Contrat basé sur le Contrat Proposé, ou sur des termes et conditions de Contrat modifiés tels qu'ils seraient convenus avec l'Acheteur suite aux négociations.\n\n---\n\n## SECTION 5: Referees\n\n### Premier Référent\n- **Nom:** [Nom du référent technique senior]\n- **Organisation:** [Organisation cliente majeure]\n- **Services fournis:** Développement et déploiement de systèmes d'authentification et pipelines de données\n- **Date de prestation:** 2023-2024\n- **Téléphone:** [Numéro de téléphone]\n- **Email:** [Email professionnel]\n- **Relation:** Directeur Technique / Propriétaire du Contrat\n\n### Deuxième Référent\n- **Nom:** [Nom du référent projet]\n- **Organisation:** [Cliente enterprise]\n- **Services fournis:** Solutions ML et optimisation de performance\n- **Date de prestation:** 2023-2024\n- **Téléphone:** [Numéro de téléphone]\n- **Email:** [Email professionnel]\n- **Relation:** Chef de Projet / Contact Clé\n\n### Troisième Référent\n- **Nom:** [Nom du référent innovation]\n- **Organisation:** [Partenaire technologique]\n- **Services fournis:** Développement de modules innovants et formation technique\n- **Date de prestation:** 2024\n- **Téléphone:** [Numéro de téléphone]\n- **Email:** [Email professionnel]\n- **Relation:** Responsable Innovation / Contact Technique\n\n**Veuillez me contacter avant d'approcher un référent:** Oui\n\n---\n\n## SECTION 6: Our Declaration\n\n### Déclaration du Répondant\n\n| Sujet | Déclaration | Accord |\n|-------|-------------|--------|\n| **Termes RFP** | J'ai lu et compris entièrement ce RFP, incluant les Termes RFP. Je confirme que le Répondant accepte d'être lié par ceux-ci. | **Accord** |\n| **Collecte d'informations** | Le Répondant autorise l'Acheteur à collecter toute information pertinente depuis des tiers, incluant les référents, et à utiliser ces informations dans l'évaluation. | **Accord** |\n| **Exigences** | J'ai lu et compris la nature et l'étendue des Exigences de l'Acheteur. Je confirme que le Répondant a la capacité nécessaire pour pleinement satisfaire les Exigences. | **Accord** |\n| **Éthique** | Le Répondant garantit qu'il n'a pas conclu d'arrangements inappropriés avec des concurrents et n'a pas tenté d'influencer indûment des représentants de l'Acheteur. | **Accord** |\n| **Période de Validité** | Je confirme que cette Proposition reste ouverte pour acceptation pendant la Période de Validité de l'Offre. | **Accord** |\n| **Conflit d'Intérêts** | Le Répondant garantit qu'il n'a aucun Conflit d'Intérêts réel, potentiel ou perçu. | **Accord** |\n\n**Détails du conflit d'intérêts:** Non applicable\n\n### DÉCLARATION PAR LE RÉPONDANT\n\nJe déclare qu'en soumettant cette Proposition et cette déclaration:\n- Les informations fournies sont vraies, exactes et complètes\n- La Proposition ne contient aucun matériel qui enfreindrait les droits de propriété intellectuelle d'un tiers\n- J'ai sécurisé toutes les autorisations appropriées pour soumettre cette Proposition\n\n**Signature:** _______________________\n**Nom complet:** {company_info['signatory_name']}\n**Titre/Position:** {company_info['signatory_title']}\n**Nom de l'organisation:** {company_info['company_name']}\n**Date:** {current_date}\n\n---\n\n*Cette réponse RFP a été générée avec notre système d'intelligence artificielle avancé, démontrant notre capacité d'innovation et d'automatisation pour une efficacité optimale.*\n\"\"\"\n\n        return markdown_content\n\n# Exemple d'utilisation\ndef main():\n    # Configuration de l'entreprise (à personnaliser)\n    company_info = {\n        'company_name': 'TechExcellence Solutions',\n        'trading_name': 'TechExcel',\n        'address': '123 Innovation Street, Tech City',\n        'website': 'www.techexcellence.com',\n        'entity_type': 'Limited Liability Company',\n        'country': 'France',\n        'contact_name': 'Jean Dupont',\n        'contact_position': 'Directeur Technique',\n        'phone': '+33 1 23 45 67 89',\n        'email': 'j.dupont@techexcellence.com',\n        'signatory_name': 'Jean Dupont',\n        'signatory_title': 'Directeur Technique'\n    }\n\n    # Initialisation du générateur\n    generator = RFPResponseGenerator(markdown_file)  # Chemin vers votre rapport\n\n    # Génération de la réponse RFP\n    rfp_response = generator.generate_rfp_response(company_info)\n\n    # Sauvegarde en fichier Markdown\n    rfp_resp_file = f'RFP_Response_{datetime.now().strftime(\"%Y%m%d_%H%M\")}.md'\n    with open(rfp_resp_file, 'w', encoding='utf-8') as f:\n        f.write(rfp_response)\n\n    print(\"✅ Réponse RFP générée avec succès!\")\n    print(f\"📁 Fichier sauvegardé: \", rfp_resp_file)\n\n    return rfp_response, rfp_resp_file\n\nif __name__ == \"__main__\":\n    rfp_response, rfp_resp_file = main()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k_Q2RzpIpnMb","outputId":"559efc35-e537-47c0-ae37-f01e45a47e48","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:41:41.240199Z","iopub.execute_input":"2025-07-31T09:41:41.240509Z","iopub.status.idle":"2025-07-31T09:46:03.786055Z","shell.execute_reply.started":"2025-07-31T09:41:41.240472Z","shell.execute_reply":"2025-07-31T09:46:03.785395Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/608 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47528c2edc4a458e826faeb48fecae89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.20G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08e8e26261634752b91f9742a1e77022"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a592d1bf097b4c1b8cd11cfafbae8cbf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e0b304e86bba45b2ac5cf9ea7e74f731"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10936655433743bbb1d25636b790f5a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"436e286a173845909a859baeb56b2d99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/551 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c8d5dab20d24e3cadac8d8cd682ae77"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda:0\nYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"},{"name":"stdout","text":"✅ Réponse RFP générée avec succès!\n📁 Fichier sauvegardé:  RFP_Response_20250731_0946.md\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class MarkdownToPDFConverter:\n    \"\"\"Convert Markdown files to PDF with professional styling and summary page\"\"\"\n    \n    def __init__(self):\n        self.css_styles = \"\"\"\n        @page {\n            size: A4;\n            margin: 2.5cm 2cm 2cm 2cm;\n            @top-center {\n                content: \"TechExcellence Solutions - RFP Response\";\n                font-size: 10px;\n                color: #666;\n            }\n            @bottom-center {\n                content: \"Page \" counter(page) \" of \" counter(pages);\n                font-size: 10px;\n                color: #666;\n            }\n        }\n        \n        body {\n            font-family: 'DejaVu Sans', Arial, sans-serif;\n            font-size: 11px;\n            line-height: 1.4;\n            color: #333;\n            max-width: none;\n        }\n        \n        h1 {\n            color: #2c3e50;\n            font-size: 24px;\n            font-weight: bold;\n            margin-top: 30px;\n            margin-bottom: 20px;\n            page-break-after: avoid;\n            border-bottom: 3px solid #3498db;\n            padding-bottom: 10px;\n        }\n        \n        h2 {\n            color: #34495e;\n            font-size: 18px;\n            font-weight: bold;\n            margin-top: 25px;\n            margin-bottom: 15px;\n            page-break-after: avoid;\n            border-bottom: 2px solid #95a5a6;\n            padding-bottom: 5px;\n        }\n        \n        h3 {\n            color: #2c3e50;\n            font-size: 14px;\n            font-weight: bold;\n            margin-top: 20px;\n            margin-bottom: 10px;\n            page-break-after: avoid;\n        }\n        \n        h4 {\n            color: #34495e;\n            font-size: 12px;\n            font-weight: bold;\n            margin-top: 15px;\n            margin-bottom: 8px;\n            page-break-after: avoid;\n        }\n        \n        p {\n            margin-bottom: 12px;\n            text-align: justify;\n            orphans: 2;\n            widows: 2;\n        }\n        \n        table {\n            width: 100%;\n            border-collapse: collapse;\n            margin: 15px 0;\n            font-size: 10px;\n            page-break-inside: avoid;\n        }\n        \n        th, td {\n            border: 1px solid #bdc3c7;\n            padding: 8px;\n            text-align: left;\n            vertical-align: top;\n        }\n        \n        th {\n            background-color: #ecf0f1;\n            font-weight: bold;\n            color: #2c3e50;\n        }\n        \n        tr:nth-child(even) {\n            background-color: #f8f9fa;\n        }\n        \n        .company-header {\n            text-align: center;\n            margin-bottom: 30px;\n            page-break-after: avoid;\n        }\n        \n        .company-title {\n            font-size: 28px;\n            font-weight: bold;\n            color: #2c3e50;\n            margin-bottom: 5px;\n        }\n        \n        .company-subtitle {\n            font-size: 14px;\n            color: #7f8c8d;\n            font-style: italic;\n            margin-bottom: 20px;\n        }\n        \n        .summary-page {\n            page-break-after: always;\n            padding: 20px 0;\n        }\n        \n        .summary-title {\n            font-size: 22px;\n            font-weight: bold;\n            color: #2c3e50;\n            text-align: center;\n            margin-bottom: 30px;\n            border-bottom: 3px solid #3498db;\n            padding-bottom: 15px;\n        }\n        \n        .summary-table {\n            width: 100%;\n            border-collapse: collapse;\n            margin: 20px 0;\n            font-size: 11px;\n        }\n        \n        .summary-table th {\n            background-color: #2c3e50;\n            color: white;\n            padding: 12px;\n            text-align: left;\n            font-weight: bold;\n        }\n        \n        .summary-table td {\n            padding: 10px 12px;\n            border-bottom: 1px solid #ecf0f1;\n            vertical-align: top;\n        }\n        \n        .summary-table .section-number {\n            font-weight: bold;\n            color: #3498db;\n            width: 15%;\n            text-align: center;\n        }\n        \n        .summary-table .section-title {\n            font-weight: bold;\n            color: #2c3e50;\n            width: 35%;\n        }\n        \n        .summary-table .section-description {\n            color: #555;\n            width: 50%;\n            line-height: 1.3;\n        }\n        \n        .summary-overview {\n            background-color: #f8f9fa;\n            border-left: 4px solid #3498db;\n            padding: 20px;\n            margin: 20px 0;\n            border-radius: 5px;\n        }\n        \n        .summary-overview h3 {\n            color: #2c3e50;\n            margin-top: 0;\n            margin-bottom: 15px;\n        }\n        \n        .summary-stats {\n            display: flex;\n            justify-content: space-around;\n            margin: 20px 0;\n            text-align: center;\n        }\n        \n        .stat-box {\n            background-color: #ecf0f1;\n            padding: 15px;\n            border-radius: 5px;\n            flex: 1;\n            margin: 0 10px;\n        }\n        \n        .stat-number {\n            font-size: 24px;\n            font-weight: bold;\n            color: #3498db;\n            display: block;\n        }\n        \n        .stat-label {\n            font-size: 12px;\n            color: #7f8c8d;\n            margin-top: 5px;\n        }\n        \n        .section-divider {\n            border-top: 2px solid #3498db;\n            margin: 30px 0;\n            page-break-before: auto;\n        }\n        \n        .highlight {\n            background-color: #fff3cd;\n            padding: 10px;\n            border-left: 4px solid #ffc107;\n            margin: 15px 0;\n        }\n        \n        .price-box {\n            background-color: #e8f5e8;\n            border: 2px solid #28a745;\n            padding: 15px;\n            text-align: center;\n            font-weight: bold;\n            font-size: 14px;\n            margin: 20px 0;\n        }\n        \n        ul, ol {\n            margin-bottom: 15px;\n            padding-left: 25px;\n        }\n        \n        li {\n            margin-bottom: 5px;\n        }\n        \n        blockquote {\n            border-left: 4px solid #3498db;\n            padding-left: 15px;\n            margin: 15px 0;\n            font-style: italic;\n            color: #555;\n        }\n        \n        code {\n            background-color: #f8f9fa;\n            padding: 2px 4px;\n            border-radius: 3px;\n            font-family: 'Courier New', monospace;\n            font-size: 90%;\n        }\n        \n        .page-break {\n            page-break-before: always;\n        }\n        \n        .no-break {\n            page-break-inside: avoid;\n        }\n        \n        .footer-signature {\n            margin-top: 40px;\n            page-break-inside: avoid;\n        }\n        \n        strong {\n            font-weight: bold;\n            color: #2c3e50;\n        }\n        \n        em {\n            font-style: italic;\n        }\n        \"\"\"\n        \n        # Define the sections structure\n        self.sections = [\n            {\n                \"number\": \"1\",\n                \"title\": \"Executive Summary\",\n                \"description\": \"Comprehensive overview of our proposal, key benefits, and strategic approach to meet your requirements.\"\n            },\n            {\n                \"number\": \"2\",\n                \"title\": \"Response to Requirements\",\n                \"description\": \"Detailed technical and functional responses addressing each requirement specified in the RFP.\"\n            },\n            {\n                \"number\": \"3\",\n                \"title\": \"Evaluation Criteria and Pricing\",\n                \"description\": \"Transparent pricing structure, cost breakdown, and alignment with evaluation criteria.\"\n            },\n            {\n                \"number\": \"4\",\n                \"title\": \"Proposed Contract Terms\",\n                \"description\": \"Contract structure, delivery milestones, payment terms, and service level agreements.\"\n            },\n            {\n                \"number\": \"5\",\n                \"title\": \"References\",\n                \"description\": \"Client testimonials, case studies, and references demonstrating our proven track record.\"\n            },\n            {\n                \"number\": \"6\",\n                \"title\": \"Company Declaration\",\n                \"description\": \"Legal declarations, certifications, compliance statements, and company commitments.\"\n            }\n        ]\n    \n    def generate_summary_page(self) -> str:\n        \"\"\"Generate HTML for the summary page\"\"\"\n        \n        # Calculate some basic stats (you can customize these)\n        total_sections = len(self.sections)\n        estimated_pages = 25  # You can calculate this dynamically if needed\n        project_value = \"€360,000\"\n        \n        summary_html = f\"\"\"\n        <div class=\"summary-page\">\n            <div class=\"summary-title\">Document Summary</div>\n            \n            <div class=\"summary-overview\">\n                <h3>RFP Response Overview</h3>\n                <p>This comprehensive response document addresses all requirements outlined in your Request for Proposal. \n                Our solution demonstrates technical excellence, strategic thinking, and competitive pricing while ensuring \n                full compliance with your specifications.</p>\n            </div>\n            \n            <div class=\"summary-stats\" style=\"display: table; width: 100%; margin: 20px 0;\">\n                <div style=\"display: table-row;\">\n                    <div class=\"stat-box\" style=\"display: table-cell; padding: 15px; text-align: center; background-color: #ecf0f1; border-radius: 5px; margin: 0 5px;\">\n                        <span class=\"stat-number\">{total_sections}</span>\n                        <div class=\"stat-label\">Sections</div>\n                    </div>\n                    <div class=\"stat-box\" style=\"display: table-cell; padding: 15px; text-align: center; background-color: #ecf0f1; border-radius: 5px; margin: 0 5px;\">\n                        <span class=\"stat-number\">~{estimated_pages}</span>\n                        <div class=\"stat-label\">Pages</div>\n                    </div>\n                    <div class=\"stat-box\" style=\"display: table-cell; padding: 15px; text-align: center; background-color: #ecf0f1; border-radius: 5px; margin: 0 5px;\">\n                        <span class=\"stat-number\">{project_value}</span>\n                        <div class=\"stat-label\">Project Value</div>\n                    </div>\n                </div>\n            </div>\n            \n            <table class=\"summary-table\">\n                <thead>\n                    <tr>\n                        <th>Section</th>\n                        <th>Title</th>\n                        <th>Description</th>\n                    </tr>\n                </thead>\n                <tbody>\n        \"\"\"\n        \n        for section in self.sections:\n            summary_html += f\"\"\"\n                    <tr>\n                        <td class=\"section-number\">{section['number']}</td>\n                        <td class=\"section-title\">{section['title']}</td>\n                        <td class=\"section-description\">{section['description']}</td>\n                    </tr>\n            \"\"\"\n        \n        summary_html += \"\"\"\n                </tbody>\n            </table>\n            \n            <div class=\"summary-overview\" style=\"margin-top: 30px;\">\n                <h3>Key Highlights</h3>\n                <ul style=\"margin: 0; padding-left: 20px;\">\n                    <li><strong>Competitive Pricing:</strong> Transparent cost structure with excellent value proposition</li>\n                    <li><strong>Proven Expertise:</strong> Demonstrated experience with similar projects and technologies</li>\n                    <li><strong>Quality Assurance:</strong> Comprehensive testing and quality control processes</li>\n                    <li><strong>Timely Delivery:</strong> Realistic timeline with built-in contingencies</li>\n                    <li><strong>Ongoing Support:</strong> Dedicated support team and maintenance services</li>\n                </ul>\n            </div>\n        </div>\n        \"\"\"\n        \n        return summary_html\n    \n    def preprocess_markdown(self, content: str) -> str:\n        \"\"\"Preprocess markdown content for better PDF formatting\"\"\"\n        \n        # Add CSS classes for special sections\n        content = content.replace('**TechExcellence Solutions**', \n                                '<div class=\"company-header\"><div class=\"company-title\">TechExcellence Solutions</div>')\n        content = content.replace('*Excellence Technique et Innovation Stratégique*', \n                                '<div class=\"company-subtitle\">Excellence Technique et Innovation Stratégique</div></div>')\n        \n        # Add page breaks before major sections\n        sections_for_page_break = [\n            '## SECTION 2: Response to the Requirements',\n            '## SECTION 3: Evaluation Criteria and Price',\n            '## SECTION 4: Proposed Contract',\n            '## SECTION 5: Referees',\n            '## SECTION 6: Our Declaration'\n        ]\n        \n        for section in sections_for_page_break:\n            content = content.replace(section, f'<div class=\"page-break\"></div>\\n\\n{section}')\n        \n        # Highlight price information\n        content = content.replace('**360,000€**', '<div class=\"price-box\">360,000€</div>')\n        content = content.replace('**€360,000**', '<div class=\"price-box\">€360,000</div>')\n        \n        # Add no-break class to important tables\n        content = content.replace('| Milestone | Date Estimée | Montant (HT) |', \n                                '<div class=\"no-break\">\\n\\n| Milestone | Date Estimée | Montant (HT) |')\n        content = content.replace('| **TOTAL** | | **€360,000** |', \n                                '| **TOTAL** | | **€360,000** |\\n\\n</div>')\n        \n        return content\n    \n    def convert_to_pdf(self, markdown_file: str, output_file: Optional[str] = None, include_summary: bool = True) -> str:\n        \"\"\"Convert markdown file to PDF with optional summary page\"\"\"\n        \n        # Validate input file\n        if not os.path.exists(markdown_file):\n            raise FileNotFoundError(f\"Markdown file not found: {markdown_file}\")\n        \n        # Generate output filename if not provided\n        if output_file is None:\n            output_file = os.path.splitext(markdown_file)[0] + '.pdf'\n        \n        logger.info(f\"Converting {markdown_file} to {output_file}\")\n        \n        try:\n            # Read markdown content\n            with open(markdown_file, 'r', encoding='utf-8') as f:\n                markdown_content = f.read()\n            \n            # Preprocess content\n            markdown_content = self.preprocess_markdown(markdown_content)\n            \n            # Configure markdown with extensions\n            md = markdown.Markdown(\n                extensions=[\n                    'tables',\n                    'toc',\n                    'attr_list',\n                    'def_list',\n                    'fenced_code',\n                    'codehilite'\n                ],\n                extension_configs={\n                    'toc': {\n                        'title': 'Table des Matières'\n                    }\n                }\n            )\n            \n            # Convert markdown to HTML\n            html_content = md.convert(markdown_content)\n            \n            # Generate summary page HTML if requested\n            summary_html = \"\"\n            if include_summary:\n                summary_html = self.generate_summary_page()\n            \n            # Create complete HTML document\n            full_html = f\"\"\"\n            <!DOCTYPE html>\n            <html lang=\"fr\">\n            <head>\n                <meta charset=\"UTF-8\">\n                <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n                <title>TechExcellence Solutions - RFP Response</title>\n            </head>\n            <body>\n                {summary_html}\n                {html_content}\n            </body>\n            </html>\n            \"\"\"\n            \n            # Convert HTML to PDF using WeasyPrint\n            html_doc = HTML(string=full_html)\n            css_doc = CSS(string=self.css_styles)\n            \n            # Generate PDF\n            html_doc.write_pdf(output_file, stylesheets=[css_doc])\n            \n            logger.info(f\"PDF successfully created: {output_file}\")\n            return output_file\n            \n        except Exception as e:\n            logger.error(f\"Error converting markdown to PDF: {e}\")\n            raise\n\n    def update_sections(self, sections_list: list):\n        \"\"\"Update the sections list for custom RFP structures\n        \n        Args:\n            sections_list: List of dictionaries with 'number', 'title', 'description' keys\n        \"\"\"\n        self.sections = sections_list\n\ndef main():\n    \"\"\"Main function for Colab usage\"\"\"\n    # For Colab, we'll create a simple function to convert the file\n    print(\"🚀 Enhanced Markdown to PDF Converter with Summary Page\")\n    print(\"=\" * 60)\n    \n    # Check if the markdown file exists\n    md_file = rfp_resp_file\n    \n    try:\n        converter = MarkdownToPDFConverter()\n        output_file = converter.convert_to_pdf(md_file, include_summary=True)\n        print(f\"✅ Successfully converted to PDF with summary page: {output_file}\")\n        print(f\"📁 You can download the file from the Colab file browser\")\n        \n        # Display file info\n        file_size = os.path.getsize(output_file) / 1024  # KB\n        print(f\"📊 File size: {file_size:.1f} KB\")\n        print(f\"📄 Summary page included with section overview\")\n        \n    except Exception as e:\n        print(f\"❌ Error: {e}\")\n\n# Colab-friendly conversion function\ndef convert_markdown_to_pdf(input_file, output_file=\"RFP_response.pdf\", include_summary=True, custom_sections=None):\n    \"\"\"\n    Convert markdown file to PDF with summary page - Colab friendly function\n    \n    Args:\n        input_file (str): Path to markdown file\n        output_file (str): Output PDF path (optional)\n        include_summary (bool): Whether to include summary page\n        custom_sections (list): Custom sections list (optional)\n    \n    Returns:\n        str: Path to generated PDF file\n    \"\"\"\n    try:\n        converter = MarkdownToPDFConverter()\n        \n        # Update sections if custom ones provided\n        if custom_sections:\n            converter.update_sections(custom_sections)\n        \n        output_path = converter.convert_to_pdf(input_file, output_file, include_summary)\n        \n        if include_summary:\n            print(f\"✅ PDF with summary page created successfully: {output_path}\")\n        else:\n            print(f\"✅ PDF created successfully: {output_path}\")\n            \n        return output_path\n    except Exception as e:\n        print(f\"❌ Conversion failed: {e}\")\n        return None\n\n# Example of how to customize sections\ndef create_custom_sections_example():\n    \"\"\"Example of how to create custom sections for different RFP types\"\"\"\n    \n    custom_sections = [\n        {\n            \"number\": \"1\",\n            \"title\": \"Project Understanding\",\n            \"description\": \"Our interpretation and understanding of the project requirements and objectives.\"\n        },\n        {\n            \"number\": \"2\",\n            \"title\": \"Technical Approach\",\n            \"description\": \"Detailed technical methodology and implementation strategy for the proposed solution.\"\n        },\n        {\n            \"number\": \"3\",\n            \"title\": \"Team & Resources\",\n            \"description\": \"Project team composition, roles, responsibilities, and resource allocation.\"\n        },\n        {\n            \"number\": \"4\",\n            \"title\": \"Timeline & Milestones\",\n            \"description\": \"Project schedule, key milestones, deliverables, and critical path analysis.\"\n        },\n        {\n            \"number\": \"5\",\n            \"title\": \"Risk Management\",\n            \"description\": \"Risk assessment, mitigation strategies, and contingency planning.\"\n        },\n        {\n            \"number\": \"6\",\n            \"title\": \"Quality Assurance\",\n            \"description\": \"Quality control processes, testing procedures, and compliance measures.\"\n        }\n    ]\n    \n    return custom_sections\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T09:46:03.787398Z","iopub.execute_input":"2025-07-31T09:46:03.787681Z","iopub.status.idle":"2025-07-31T09:46:04.827938Z","shell.execute_reply.started":"2025-07-31T09:46:03.787661Z","shell.execute_reply":"2025-07-31T09:46:04.827265Z"}},"outputs":[{"name":"stdout","text":"🚀 Enhanced Markdown to PDF Converter with Summary Page\n============================================================\n✅ Successfully converted to PDF with summary page: RFP_Response_20250731_0946.pdf\n📁 You can download the file from the Colab file browser\n📊 File size: 69.0 KB\n📄 Summary page included with section overview\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"oBYFpMg-oWiZ","outputId":"6aa6b297-c9b6-488c-8336-6aa50eddd8a8","trusted":true},"outputs":[],"execution_count":null}]}