{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12600200,"sourceType":"datasetVersion","datasetId":7958376}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch transformers accelerate pandas numpy nltk scikit-learn reportlab PyPDF2 pdfplumber","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T08:40:58.933196Z","iopub.execute_input":"2025-07-29T08:40:58.933920Z","iopub.status.idle":"2025-07-29T08:41:02.286268Z","shell.execute_reply.started":"2025-07-29T08:40:58.933893Z","shell.execute_reply":"2025-07-29T08:41:02.285542Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: reportlab in /usr/local/lib/python3.11/dist-packages (4.4.3)\nRequirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\nRequirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.7)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.4)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from reportlab) (11.2.1)\nRequirement already satisfied: charset-normalizer in /usr/local/lib/python3.11/dist-packages (from reportlab) (3.4.2)\nRequirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20250506)\nRequirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.0)\nRequirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20250506->pdfplumber) (44.0.3)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\nRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (1.17.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.22)\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import os\nimport json\nimport pandas as pd\nfrom typing import Dict, List, Any, Optional\ntry:\n    from typing import Tuple\nexcept ImportError:\n    # For older Python versions\n    Tuple = tuple\nfrom dataclasses import dataclass, field\nfrom datetime import datetime\nimport re\nfrom collections import Counter, defaultdict\nimport numpy as np\nimport torch\n\n# PDF generation\nfrom reportlab.lib.pagesizes import letter, A4\nfrom reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle, PageBreak, KeepTogether\nfrom reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\nfrom reportlab.lib.units import inch\nfrom reportlab.lib import colors\nfrom reportlab.lib.enums import TA_CENTER, TA_LEFT, TA_JUSTIFY, TA_RIGHT\n\n# Natural Language Processing\nimport nltk\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# PDF reading\nimport PyPDF2\nimport pdfplumber\n\n# HuggingFace Transformers for LLM integration\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-29T08:41:02.287893Z","iopub.execute_input":"2025-07-29T08:41:02.288130Z","iopub.status.idle":"2025-07-29T08:41:02.295320Z","shell.execute_reply.started":"2025-07-29T08:41:02.288109Z","shell.execute_reply":"2025-07-29T08:41:02.294608Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"try:\n    nltk.data.find('tokenizers/punkt')\nexcept LookupError:\n    nltk.download('punkt')\n\ntry:\n    nltk.data.find('corpora/stopwords')\nexcept LookupError:\n    nltk.download('stopwords')\n\ntry:\n    nltk.data.find('vader_lexicon')\nexcept LookupError:\n    nltk.download('vader_lexicon')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T08:41:02.296044Z","iopub.execute_input":"2025-07-29T08:41:02.296305Z","iopub.status.idle":"2025-07-29T08:41:02.323346Z","shell.execute_reply.started":"2025-07-29T08:41:02.296288Z","shell.execute_reply":"2025-07-29T08:41:02.322719Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# ## 4. Define Enhanced Data Classes\n@dataclass\nclass ModuleMapping:\n    \"\"\"Represents a module and its coverage status\"\"\"\n    module_name: str\n    module_code: str = \"\"\n    required: bool = False\n    available: bool = False\n    coverage_percentage: float = 0.0\n    status: str = \"Unknown\"  # Available, Partial, Missing, In Development\n    notes: str = \"\"\n    client_priority: str = \"Medium\"  # High, Medium, Low\n\n@dataclass\nclass GapItem:\n    \"\"\"Represents a specific gap\"\"\"\n    gap_type: str  # Technical, Resource, Compliance, Process, Functional\n    description: str\n    severity: str  # Critical, High, Medium, Low\n    business_impact: str\n    mitigation_strategy: str\n    effort_required: str  # Days/weeks/months\n    cost_estimate: str\n    dependencies: List[str] = field(default_factory=list)\n    risk_if_unaddressed: str = \"\"\n\n@dataclass\nclass WinLossFactors:\n    \"\"\"Factors from win/loss analysis\"\"\"\n    factor_type: str  # Win or Loss\n    category: str  # Technical, Price, Relationship, Process, Competition\n    description: str\n    frequency: int  # How often this appears\n    impact_level: str  # High, Medium, Low\n    specific_examples: List[str] = field(default_factory=list)\n    lessons_learned: str = \"\"\n\n@dataclass\nclass CustomerRequirement:\n    \"\"\"Specific customer requirement\"\"\"\n    requirement_id: str\n    requirement_type: str  # Functional, Technical, Compliance, Performance\n    description: str\n    priority: str  # Must Have, Nice to Have, Optional\n    our_capability: str  # Full, Partial, None, In Development\n    gap_description: str = \"\"\n    effort_to_meet: str = \"\"\n    notes: str = \"\"\n\n@dataclass\nclass CompetitiveAnalysis:\n    \"\"\"Competitive positioning analysis\"\"\"\n    competitor_name: str\n    strengths: List[str]\n    weaknesses: List[str]\n    win_rate_against: float\n    typical_strategy: str\n    our_advantages: List[str]\n    our_disadvantages: List[str]\n\n@dataclass\nclass RiskAssessment:\n    \"\"\"Risk assessment for RFP response\"\"\"\n    risk_type: str  # Technical, Commercial, Delivery, Compliance\n    description: str\n    probability: str  # High, Medium, Low\n    impact: str  # High, Medium, Low\n    mitigation_plan: str\n    owner: str = \"TBD\"\n    due_date: str = \"TBD\"\n\n@dataclass\nclass RFPFeasibilityAssessment:\n    \"\"\"Overall RFP response feasibility\"\"\"\n    can_respond: bool\n    confidence_score: float  # 0-100\n    win_probability: float  # 0-100\n    \n    # Detailed assessments\n    total_modules: int = 0\n    available_modules: int = 0\n    partial_modules: int = 0\n    missing_modules: int = 0\n    \n    critical_gaps: List[GapItem] = field(default_factory=list)\n    all_gaps: List[GapItem] = field(default_factory=list)\n    \n    strengths: List[str] = field(default_factory=list)\n    weaknesses: List[str] = field(default_factory=list)\n    opportunities: List[str] = field(default_factory=list)\n    threats: List[str] = field(default_factory=list)\n    \n    required_actions: List[tuple] = field(default_factory=list)  # (action, priority, timeline, owner)\n    risks: List[RiskAssessment] = field(default_factory=list)\n    \n    investment_required: str = \"\"\n    timeline_estimate: str = \"\"\n    resource_requirements: str = \"\"\n    \n    executive_summary: str = \"\"\n    detailed_rationale: str = \"\"\n    competitive_positioning: str = \"\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T08:41:02.324642Z","iopub.execute_input":"2025-07-29T08:41:02.324838Z","iopub.status.idle":"2025-07-29T08:41:02.343724Z","shell.execute_reply.started":"2025-07-29T08:41:02.324823Z","shell.execute_reply":"2025-07-29T08:41:02.343079Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"# ## 5. Enhanced Document Processor\nclass DocumentProcessor:\n    \"\"\"Processes documents and extracts structured information\"\"\"\n    \n    def __init__(self):\n        self.stop_words = set(stopwords.words('english'))\n        \n    def extract_text_from_pdf(self, file_path: str) -> str:\n        \"\"\"Extract text from PDF files with better handling\"\"\"\n        text = \"\"\n        \n        # Try pdfplumber first (usually better for complex PDFs)\n        try:\n            with pdfplumber.open(file_path) as pdf:\n                for page in pdf.pages:\n                    # Extract text with better layout preservation\n                    page_text = page.extract_text(x_tolerance=2, y_tolerance=3)\n                    if page_text:\n                        # Clean up common PDF extraction issues\n                        page_text = page_text.replace('\\n\\n', '\\n')\n                        page_text = re.sub(r'(\\w)-\\n(\\w)', r'\\1\\2', page_text)  # Fix hyphenated words\n                        page_text = re.sub(r'\\s+', ' ', page_text)  # Normalize whitespace\n                        text += page_text + \"\\n\\n\"\n            \n            if text.strip():\n                print(f\"âœ“ Extracted {len(text)} characters using pdfplumber\")\n                return text\n        except Exception as e:\n            print(f\"pdfplumber failed: {e}\")\n        \n        # Fallback to PyPDF2\n        try:\n            with open(file_path, 'rb') as file:\n                pdf_reader = PyPDF2.PdfReader(file)\n                for page_num in range(len(pdf_reader.pages)):\n                    page = pdf_reader.pages[page_num]\n                    page_text = page.extract_text()\n                    if page_text:\n                        # Clean up text\n                        page_text = re.sub(r'(\\w)-\\n(\\w)', r'\\1\\2', page_text)\n                        page_text = re.sub(r'\\s+', ' ', page_text)\n                        text += page_text + \"\\n\\n\"\n            \n            if text.strip():\n                print(f\"âœ“ Extracted {len(text)} characters using PyPDF2\")\n                return text\n        except Exception as e:\n            print(f\"PyPDF2 failed: {e}\")\n        \n        return \"\"\n        \n    def clean_text(self, text: str) -> str:\n        \"\"\"Clean and normalize text for better extraction\"\"\"\n        # Fix common PDF extraction issues\n        text = re.sub(r'(\\w)-\\n(\\w)', r'\\1\\2', text)  # Fix hyphenated words at line breaks\n        text = re.sub(r'(\\w)-\\s+(\\w)', r'\\1\\2', text)  # Fix hyphenated words with spaces\n        text = re.sub(r'\\n+', '\\n', text)  # Normalize line breaks\n        text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace\n        text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)  # Remove non-ASCII characters\n        \n        # Fix common OCR/extraction errors\n        text = text.replace('â– ', 'fi')  # Common ligature issue\n        text = text.replace('â—', 'â€¢')  # Normalize bullet points\n        \n        return text\n    \n    def extract_text_from_file(self, file_path: str) -> str:\n        \"\"\"Extract text from various file formats\"\"\"\n        if not os.path.exists(file_path):\n            return \"\"\n            \n        _, ext = os.path.splitext(file_path.lower())\n        \n        if ext == '.txt':\n            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n                text = f.read()\n                return self.clean_text(text)\n        elif ext == '.csv':\n            df = pd.read_csv(file_path)\n            text = df.to_string()\n            return self.clean_text(text)\n        elif ext == '.json':\n            with open(file_path, 'r', encoding='utf-8') as f:\n                data = json.load(f)\n                text = json.dumps(data, indent=2)\n                return self.clean_text(text)\n        elif ext == '.pdf':\n            text = self.extract_text_from_pdf(file_path)\n            return self.clean_text(text)\n        \n        return \"\"\n    \n    def extract_key_information(self, text: str, info_type: str) -> Dict[str, Any]:\n        \"\"\"Extract specific types of information from text\"\"\"\n        results = {\n            'raw_extracts': [],\n            'structured_data': [],\n            'statistics': {}\n        }\n        \n        # Define extraction patterns based on info type\n        patterns = {\n            'modules': {\n                'patterns': [\n                    r'(?:Module|module)\\s+([A-Z0-9]+)(?:\\s*[:-]?\\s*)([^\\.;\\n]+)',\n                    r'([A-Z][A-Za-z\\s]+)\\s+Module(?:\\s*[:-]?\\s*)([^\\.;\\n]+)',\n                    r'(?:Available|Required|Missing)\\s+modules?:?\\s*([^\\.;\\n]+)',\n                    r'(\\w+)\\s+(?:module|Module)\\s*-\\s*(Available|Partial|Missing|Required)',\n                ],\n                'keywords': ['module', 'component', 'system', 'functionality', 'feature']\n            },\n            'gaps': {\n                'patterns': [\n                    r'(?:Gap|gap|Missing|Lacking)\\s*[:-]?\\s*([^\\.;\\n]+)',\n                    r'(?:Need|Require|Must have)\\s+(?:to|for)?\\s*([^\\.;\\n]+)',\n                    r'(?:Cannot|Unable to|Lack of)\\s+([^\\.;\\n]+)',\n                    r'(?:Issue|Problem|Challenge)\\s*[:-]?\\s*([^\\.;\\n]+)',\n                ],\n                'keywords': ['gap', 'missing', 'lack', 'need', 'require', 'issue', 'problem']\n            },\n            'requirements': {\n                'patterns': [\n                    r'(?:Requirement|Required)\\s*[:-]?\\s*([^\\.;\\n]+)',\n                    r'(?:Client|Customer)\\s+(?:needs?|wants?|requires?)\\s*[:-]?\\s*([^\\.;\\n]+)',\n                    r'(?:Must|Should|Shall)\\s+(?:have|support|provide)\\s*([^\\.;\\n]+)',\n                    r'(?:Functional|Technical|Performance)\\s+requirement\\s*[:-]?\\s*([^\\.;\\n]+)',\n                ],\n                'keywords': ['requirement', 'need', 'must have', 'should have', 'specification']\n            },\n            'wins_losses': {\n                'patterns': [\n                    r'(?:Won|Lost|Win|Loss)\\s+(?:because|due to)\\s*[:-]?\\s*([^\\.;\\n]+)',\n                    r'(?:Success|Failure)\\s+factor\\s*[:-]?\\s*([^\\.;\\n]+)',\n                    r'(?:Strength|Weakness)\\s*[:-]?\\s*([^\\.;\\n]+)',\n                    r'(?:Competitive advantage|disadvantage)\\s*[:-]?\\s*([^\\.;\\n]+)',\n                ],\n                'keywords': ['won', 'lost', 'win', 'loss', 'success', 'failure', 'strength', 'weakness']\n            }\n        }\n        \n        if info_type in patterns:\n            # Extract using patterns\n            for pattern in patterns[info_type]['patterns']:\n                matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n                results['raw_extracts'].extend(matches)\n            \n            # Extract sections containing keywords\n            sentences = sent_tokenize(text)\n            for sentence in sentences:\n                if any(keyword in sentence.lower() for keyword in patterns[info_type]['keywords']):\n                    results['structured_data'].append(sentence.strip())\n            \n            # Calculate statistics\n            results['statistics'] = {\n                'total_matches': len(results['raw_extracts']),\n                'unique_items': len(set(str(m) for m in results['raw_extracts'])),\n                'keyword_sentences': len(results['structured_data'])\n            }\n        \n        return results\n    \n    def parse_modules_enhanced(self, text: str) -> List[ModuleMapping]:\n        \"\"\"Enhanced module extraction with better text cleaning\"\"\"\n        modules = []\n        module_dict = {}  # To avoid duplicates\n        \n        # Clean the text first\n        text = re.sub(r'\\s+', ' ', text)  # Normalize whitespace\n        text = re.sub(r'(\\w)-\\s+(\\w)', r'\\1\\2', text)  # Fix split words\n        \n        # Extract module information using more specific patterns\n        module_patterns = [\n            # Pattern for \"Module X: Name - Description\"\n            r'Module\\s+([A-Z0-9]+):\\s*([^-\\n]+?)(?:\\s*[-â€“]\\s*([^\\n]+))?',\n            # Pattern for numbered modules\n            r'(\\d+)\\.\\s*([A-Za-z][A-Za-z0-9\\s]+?)(?:\\s*[-â€“:]\\s*([^\\n]+))?',\n            # Pattern for module listings\n            r'([A-Z][A-Za-z0-9\\s]+?)\\s+Module(?:\\s*[-â€“:]\\s*([^\\n]+))?',\n            # Pattern for availability statements\n            r'([A-Za-z][A-Za-z0-9\\s]+?)\\s+(?:is\\s+)?(Available|Partial|Missing|Required|In Development)',\n        ]\n        \n        # First, try to find module sections in the text\n        module_section_pattern = r'(?:Module|MODULES?|Available Modules?|Required Modules?)[:\\s]*\\n([^=]+?)(?:\\n\\n|$)'\n        module_sections = re.findall(module_section_pattern, text, re.IGNORECASE | re.MULTILINE)\n        \n        # Process module sections if found\n        for section in module_sections:\n            lines = section.strip().split('\\n')\n            for line in lines:\n                line = line.strip()\n                if len(line) > 5 and not line.startswith(('Note:', 'Total:', 'Summary:')):\n                    # Try to parse module info from line\n                    # Remove common prefixes\n                    clean_line = re.sub(r'^\\d+\\.\\s*', '', line)\n                    clean_line = re.sub(r'^[-â€¢]\\s*', '', clean_line)\n                    \n                    # Extract module name and details\n                    parts = re.split(r'[-â€“:]', clean_line, 1)\n                    if parts:\n                        module_name = parts[0].strip()\n                        module_desc = parts[1].strip() if len(parts) > 1 else \"\"\n                        \n                        # Clean module name\n                        module_name = re.sub(r'\\s+', ' ', module_name)\n                        module_name = module_name.replace('Module', '').strip()\n                        \n                        if module_name and len(module_name) > 2 and module_name not in module_dict:\n                            # Determine status from description\n                            status = \"Unknown\"\n                            available = False\n                            if any(word in line.lower() for word in ['available', 'existing', 'implemented', 'have']):\n                                status = \"Available\"\n                                available = True\n                            elif any(word in line.lower() for word in ['partial', 'limited']):\n                                status = \"Partial\"\n                                available = True\n                            elif any(word in line.lower() for word in ['missing', 'gap', 'not available', 'need']):\n                                status = \"Missing\"\n                            elif any(word in line.lower() for word in ['development', 'developing', 'building']):\n                                status = \"In Development\"\n                            \n                            module = ModuleMapping(\n                                module_name=module_name,\n                                module_code=f\"MOD-{len(modules)+1:03d}\",\n                                required='required' in line.lower() or 'must' in line.lower(),\n                                available=available,\n                                coverage_percentage=100.0 if status == \"Available\" else 50.0 if status == \"Partial\" else 0.0,\n                                status=status,\n                                notes=module_desc[:200],\n                                client_priority=\"High\" if any(word in line.lower() for word in ['critical', 'essential', 'must']) else \"Medium\"\n                            )\n                            module_dict[module_name] = module\n                            modules.append(module)\n        \n        # Also try pattern matching on full text\n        for pattern in module_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n            for match in matches:\n                if isinstance(match, tuple):\n                    # Extract parts based on match groups\n                    if len(match) >= 2:\n                        module_name = match[1].strip() if len(match) > 1 and match[1] else match[0].strip()\n                        module_desc = match[2].strip() if len(match) > 2 and match[2] else \"\"\n                    else:\n                        module_name = match[0].strip()\n                        module_desc = \"\"\n                else:\n                    module_name = str(match).strip()\n                    module_desc = \"\"\n                \n                # Clean module name\n                module_name = re.sub(r'\\s+', ' ', module_name)\n                module_name = module_name.replace('Module', '').strip()\n                \n                # Skip if too short or already added\n                if not module_name or len(module_name) < 3 or module_name in module_dict:\n                    continue\n                \n                # Skip common false positives\n                if module_name.lower() in ['the', 'and', 'for', 'with', 'that', 'this', 'from']:\n                    continue\n                \n                # Create module entry\n                module = ModuleMapping(\n                    module_name=module_name,\n                    module_code=f\"MOD-{len(modules)+1:03d}\",\n                    status=\"Unknown\",\n                    notes=module_desc[:200] if module_desc else \"Identified from document scan\"\n                )\n                module_dict[module_name] = module\n                modules.append(module)\n        \n        # If we found very few modules, try a more aggressive extraction\n        if len(modules) < 10:\n            # Look for lists of capabilities or features\n            capability_patterns = [\n                r'(?:Capability|Feature|Component|System|Function):\\s*([A-Za-z][A-Za-z0-9\\s]+)',\n                r'(?:â€¢|[-*])\\s*([A-Za-z][A-Za-z0-9\\s]+?)(?:\\s*[-â€“:]\\s*[^\\n]+)?',\n            ]\n            \n            for pattern in capability_patterns:\n                matches = re.findall(pattern, text, re.IGNORECASE)\n                for match in matches[:20]:  # Limit to avoid noise\n                    module_name = match.strip()\n                    module_name = re.sub(r'\\s+', ' ', module_name)\n                    \n                    if module_name and len(module_name) > 5 and module_name not in module_dict:\n                        module = ModuleMapping(\n                            module_name=module_name,\n                            module_code=f\"MOD-{len(modules)+1:03d}\",\n                            status=\"Unknown\",\n                            notes=\"Potential module/capability identified\"\n                        )\n                        module_dict[module_name] = module\n                        modules.append(module)\n        \n        return modules\n    \n    def parse_gaps_enhanced(self, text: str) -> List[GapItem]:\n        \"\"\"Enhanced gap extraction with better text handling\"\"\"\n        gaps = []\n        seen_gaps = set()  # To avoid duplicates\n        \n        # Clean the text\n        text = re.sub(r'\\s+', ' ', text)\n        text = re.sub(r'(\\w)-\\s+(\\w)', r'\\1\\2', text)\n        \n        # Look for gap sections first\n        gap_section_patterns = [\n            r'(?:Gaps?|Missing|Lacking|Issues?)[:\\s]*\\n([^=]+?)(?:\\n\\n|$)',\n            r'(?:Gap Analysis|Capability Gaps?)[:\\s]*\\n([^=]+?)(?:\\n\\n|$)',\n            r'(?:What we need|Requirements? not met)[:\\s]*\\n([^=]+?)(?:\\n\\n|$)'\n        ]\n        \n        for pattern in gap_section_patterns:\n            sections = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n            for section in sections:\n                lines = section.strip().split('\\n')\n                for line in lines:\n                    line = line.strip()\n                    if len(line) > 10 and line not in seen_gaps:\n                        seen_gaps.add(line)\n                        \n                        # Determine gap type and severity\n                        gap_type = \"Technical\"\n                        severity = \"Medium\"\n                        \n                        line_lower = line.lower()\n                        if any(word in line_lower for word in ['compliance', 'regulation', 'standard', 'certification']):\n                            gap_type = \"Compliance\"\n                        elif any(word in line_lower for word in ['resource', 'staff', 'team', 'personnel']):\n                            gap_type = \"Resource\"\n                        elif any(word in line_lower for word in ['process', 'procedure', 'workflow', 'methodology']):\n                            gap_type = \"Process\"\n                        elif any(word in line_lower for word in ['function', 'feature', 'capability', 'module']):\n                            gap_type = \"Functional\"\n                        \n                        if any(word in line_lower for word in ['critical', 'urgent', 'immediate', 'blocker']):\n                            severity = \"Critical\"\n                        elif any(word in line_lower for word in ['high', 'important', 'significant', 'major']):\n                            severity = \"High\"\n                        elif any(word in line_lower for word in ['low', 'minor', 'small', 'nice to have']):\n                            severity = \"Low\"\n                        \n                        # Extract mitigation if mentioned\n                        mitigation = \"Develop action plan to address this gap\"\n                        if 'recommend' in line_lower or 'suggest' in line_lower or 'should' in line_lower:\n                            # Try to extract recommendation\n                            parts = re.split(r'(?:recommend|suggest|should)', line, flags=re.IGNORECASE)\n                            if len(parts) > 1:\n                                mitigation = parts[1].strip()[:100]\n                        \n                        gaps.append(GapItem(\n                            gap_type=gap_type,\n                            description=line[:200],\n                            severity=severity,\n                            business_impact=f\"{severity} impact on RFP response capability\",\n                            mitigation_strategy=mitigation,\n                            effort_required=\"1-2 weeks\" if severity == \"Critical\" else \"2-4 weeks\" if severity == \"High\" else \"1-2 months\",\n                            cost_estimate=\"TBD - requires detailed analysis\",\n                            risk_if_unaddressed=f\"May result in RFP disqualification\" if severity in [\"Critical\", \"High\"] else \"May reduce competitiveness\"\n                        ))\n        \n        # Also look for specific gap patterns\n        gap_patterns = [\n            r'(?:Gap|Missing|Lack(?:ing)?|Need)\\s*[:â€“]\\s*([^.;\\n]+)',\n            r'(?:We do not have|Cannot provide|Unable to)\\s+([^.;\\n]+)',\n            r'(?:Must develop|Need to implement|Should acquire)\\s+([^.;\\n]+)',\n            r'(?:Compliance gap|Technical gap|Resource gap)\\s*[:â€“]\\s*([^.;\\n]+)',\n        ]\n        \n        for pattern in gap_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE)\n            for match in matches[:20]:  # Limit to avoid noise\n                gap_desc = match.strip()\n                if len(gap_desc) > 10 and gap_desc not in seen_gaps:\n                    seen_gaps.add(gap_desc)\n                    \n                    gaps.append(GapItem(\n                        gap_type=\"Technical\",\n                        description=gap_desc[:200],\n                        severity=\"Medium\",\n                        business_impact=\"Medium impact on RFP response capability\",\n                        mitigation_strategy=\"Develop action plan to address this gap\",\n                        effort_required=\"2-4 weeks\",\n                        cost_estimate=\"TBD - requires detailed analysis\",\n                        risk_if_unaddressed=\"May reduce competitiveness\"\n                    ))\n        \n        return gaps\n    \n    def parse_requirements_enhanced(self, text: str) -> List[CustomerRequirement]:\n        \"\"\"Enhanced requirement extraction with better parsing\"\"\"\n        requirements = []\n        seen_requirements = set()\n        \n        # Clean the text\n        text = re.sub(r'\\s+', ' ', text)\n        text = re.sub(r'(\\w)-\\s+(\\w)', r'\\1\\2', text)\n        \n        # Look for requirements sections\n        req_section_patterns = [\n            r'(?:Requirements?|Customer Needs?|Client Requirements?)[:\\s]*\\n([^=]+?)(?:\\n\\n|$)',\n            r'(?:Must have|Should have|Functional requirements?)[:\\s]*\\n([^=]+?)(?:\\n\\n|$)',\n            r'(?:Technical specifications?|Performance requirements?)[:\\s]*\\n([^=]+?)(?:\\n\\n|$)'\n        ]\n        \n        req_counter = 0\n        for pattern in req_section_patterns:\n            sections = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n            for section in sections:\n                lines = section.strip().split('\\n')\n                for line in lines:\n                    line = line.strip()\n                    # Remove common list markers\n                    line = re.sub(r'^[\\d\\-â€¢*]+\\s*', '', line)\n                    \n                    if len(line) > 10 and line not in seen_requirements:\n                        seen_requirements.add(line)\n                        req_counter += 1\n                        \n                        # Determine requirement type\n                        req_type = \"Functional\"\n                        line_lower = line.lower()\n                        if any(word in line_lower for word in ['technical', 'technology', 'system', 'architecture']):\n                            req_type = \"Technical\"\n                        elif any(word in line_lower for word in ['compliance', 'regulation', 'standard', 'certification']):\n                            req_type = \"Compliance\"\n                        elif any(word in line_lower for word in ['performance', 'speed', 'capacity', 'scalability']):\n                            req_type = \"Performance\"\n                        elif any(word in line_lower for word in ['business', 'process', 'workflow']):\n                            req_type = \"Business\"\n                        \n                        # Determine priority\n                        priority = \"Nice to Have\"\n                        if any(word in line_lower for word in ['must', 'mandatory', 'required', 'critical', 'essential']):\n                            priority = \"Must Have\"\n                        elif any(word in line_lower for word in ['should', 'important', 'needed']):\n                            priority = \"Nice to Have\"\n                        elif any(word in line_lower for word in ['optional', 'desirable', 'preferred', 'could']):\n                            priority = \"Optional\"\n                        \n                        # Assess our capability\n                        capability = \"Partial\"\n                        if any(word in line_lower for word in ['we have', 'available', 'existing', 'current', 'already']):\n                            capability = \"Full\"\n                        elif any(word in line_lower for word in ['developing', 'building', 'in progress']):\n                            capability = \"In Development\"\n                        elif any(word in line_lower for word in ['missing', 'gap', 'need', 'require', 'cannot']):\n                            capability = \"None\"\n                        \n                        requirement = CustomerRequirement(\n                            requirement_id=f\"REQ-{req_counter:03d}\",\n                            requirement_type=req_type,\n                            description=line[:200],\n                            priority=priority,\n                            our_capability=capability,\n                            gap_description=\"Gap exists - needs development\" if capability in [\"None\", \"Partial\"] else \"\",\n                            effort_to_meet=\"1-2 weeks\" if capability == \"Partial\" else \"2-4 weeks\" if capability == \"None\" else \"Already met\",\n                            notes=\"Extracted from document analysis\"\n                        )\n                        requirements.append(requirement)\n        \n        # Also look for specific requirement patterns\n        req_patterns = [\n            r'(?:The client requires?|Customer needs?|Must provide)\\s+([^.;\\n]+)',\n            r'(?:System must|Solution should|Platform needs to)\\s+([^.;\\n]+)',\n            r'(?:Requirement \\d+\\s*[:â€“]|REQ\\d+\\s*[:â€“])\\s*([^.;\\n]+)',\n            r'(?:Functional requirement|Technical requirement)\\s*[:â€“]\\s*([^.;\\n]+)',\n        ]\n        \n        for pattern in req_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE)\n            for match in matches[:15]:\n                req_desc = match.strip()\n                if len(req_desc) > 10 and req_desc not in seen_requirements:\n                    seen_requirements.add(req_desc)\n                    req_counter += 1\n                    \n                    requirements.append(CustomerRequirement(\n                        requirement_id=f\"REQ-{req_counter:03d}\",\n                        requirement_type=\"Functional\",\n                        description=req_desc[:200],\n                        priority=\"Nice to Have\",\n                        our_capability=\"Partial\",\n                        gap_description=\"To be assessed\",\n                        effort_to_meet=\"TBD\",\n                        notes=\"Identified from pattern matching\"\n                    ))\n        \n        return requirements\n    \n    def parse_win_loss_enhanced(self, text: str) -> List[WinLossFactors]:\n        \"\"\"Enhanced win/loss factor extraction with better text parsing\"\"\"\n        factors = []\n        seen_factors = set()  # To avoid duplicates\n        \n        # Clean the text\n        text = re.sub(r'\\s+', ' ', text)\n        text = re.sub(r'(\\w)-\\s+(\\w)', r'\\1\\2', text)\n        \n        # Look for win/loss sections\n        win_section_patterns = [\n            r'(?:Why we won|Success factors?|Winning factors?|Strengths?)[:\\s]*\\n([^=]+?)(?:\\n\\n|$)',\n            r'(?:Competitive advantages?|Key differentiators?)[:\\s]*\\n([^=]+?)(?:\\n\\n|$)'\n        ]\n        \n        loss_section_patterns = [\n            r'(?:Why we lost|Loss factors?|Failure reasons?|Weaknesses?)[:\\s]*\\n([^=]+?)(?:\\n\\n|$)',\n            r'(?:Competitive disadvantages?|Areas for improvement)[:\\s]*\\n([^=]+?)(?:\\n\\n|$)'\n        ]\n        \n        # Extract win factors\n        for pattern in win_section_patterns:\n            sections = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n            for section in sections:\n                lines = section.strip().split('\\n')\n                for line in lines:\n                    line = line.strip()\n                    if len(line) > 10 and line not in seen_factors:\n                        seen_factors.add(line)\n                        \n                        # Determine category\n                        category = \"Technical\"\n                        line_lower = line.lower()\n                        if any(word in line_lower for word in ['price', 'cost', 'budget', 'pricing']):\n                            category = \"Price\"\n                        elif any(word in line_lower for word in ['relationship', 'trust', 'partnership', 'client']):\n                            category = \"Relationship\"\n                        elif any(word in line_lower for word in ['process', 'delivery', 'implementation', 'methodology']):\n                            category = \"Process\"\n                        elif any(word in line_lower for word in ['competition', 'competitor', 'competitive']):\n                            category = \"Competition\"\n                        \n                        factors.append(WinLossFactors(\n                            factor_type=\"Win\",\n                            category=category,\n                            description=line[:150],\n                            frequency=1,\n                            impact_level=\"High\",\n                            lessons_learned=\"Leverage this strength in future RFPs\"\n                        ))\n        \n        # Extract loss factors\n        for pattern in loss_section_patterns:\n            sections = re.findall(pattern, text, re.IGNORECASE | re.MULTILINE)\n            for section in sections:\n                lines = section.strip().split('\\n')\n                for line in lines:\n                    line = line.strip()\n                    if len(line) > 10 and line not in seen_factors:\n                        seen_factors.add(line)\n                        \n                        # Determine category\n                        category = \"Technical\"\n                        line_lower = line.lower()\n                        if any(word in line_lower for word in ['price', 'cost', 'budget', 'expensive']):\n                            category = \"Price\"\n                        elif any(word in line_lower for word in ['relationship', 'trust', 'communication']):\n                            category = \"Relationship\"\n                        elif any(word in line_lower for word in ['process', 'delivery', 'delay', 'timeline']):\n                            category = \"Process\"\n                        elif any(word in line_lower for word in ['competition', 'competitor', 'lost to']):\n                            category = \"Competition\"\n                        \n                        factors.append(WinLossFactors(\n                            factor_type=\"Loss\",\n                            category=category,\n                            description=line[:150],\n                            frequency=1,\n                            impact_level=\"High\",\n                            lessons_learned=\"Address this weakness to improve win rate\"\n                        ))\n        \n        # Also look for specific patterns\n        win_patterns = [\n            r'(?:Won|Success|Strength)\\s+(?:because|due to|factor)\\s*[:â€“]?\\s*([^.;\\n]+)',\n            r'(?:Client appreciated|Customer liked|Positive feedback on)\\s+([^.;\\n]+)',\n            r'(?:Our advantage|We excel at|Strong in)\\s+([^.;\\n]+)',\n        ]\n        \n        loss_patterns = [\n            r'(?:Lost|Failed|Weakness)\\s+(?:because|due to|factor)\\s*[:â€“]?\\s*([^.;\\n]+)',\n            r'(?:Client concerned about|Customer disliked|Negative feedback on)\\s+([^.;\\n]+)',\n            r'(?:Our weakness|We lack|Need improvement in)\\s+([^.;\\n]+)',\n        ]\n        \n        # Process win patterns\n        for pattern in win_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE)\n            for match in matches[:10]:\n                factor_desc = match.strip()\n                if len(factor_desc) > 10 and factor_desc not in seen_factors:\n                    seen_factors.add(factor_desc)\n                    factors.append(WinLossFactors(\n                        factor_type=\"Win\",\n                        category=\"Technical\",\n                        description=factor_desc[:150],\n                        frequency=1,\n                        impact_level=\"Medium\",\n                        lessons_learned=\"Continue to leverage this strength\"\n                    ))\n        \n        # Process loss patterns\n        for pattern in loss_patterns:\n            matches = re.findall(pattern, text, re.IGNORECASE)\n            for match in matches[:10]:\n                factor_desc = match.strip()\n                if len(factor_desc) > 10 and factor_desc not in seen_factors:\n                    seen_factors.add(factor_desc)\n                    factors.append(WinLossFactors(\n                        factor_type=\"Loss\",\n                        category=\"Technical\",\n                        description=factor_desc[:150],\n                        frequency=1,\n                        impact_level=\"Medium\",\n                        lessons_learned=\"Develop strategy to address this issue\"\n                    ))\n        \n        return factors","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T08:43:09.049918Z","iopub.execute_input":"2025-07-29T08:43:09.050230Z","iopub.status.idle":"2025-07-29T08:43:09.102596Z","shell.execute_reply.started":"2025-07-29T08:43:09.050189Z","shell.execute_reply":"2025-07-29T08:43:09.101861Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"class RFPFeasibilityAnalyzer:\n    \"\"\"Main analyzer that determines if we can respond to the RFP\"\"\"\n    \n    def __init__(self):\n        self.processor = DocumentProcessor()\n        self.modules = []\n        self.gaps = []\n        self.win_loss_factors = []\n        self.requirements = []\n        self.document_summaries = {}\n        \n    def load_and_analyze_documents(self, file_paths: Dict[str, str]) -> Dict[str, Any]:\n        \"\"\"Load documents and extract structured information\"\"\"\n        results = {\n            'documents_processed': 0,\n            'total_content_length': 0,\n            'extraction_summary': {}\n        }\n        \n        for doc_type, file_path in file_paths.items():\n            print(f\"\\nðŸ“„ Analyzing {doc_type}...\")\n            text = self.processor.extract_text_from_file(file_path)\n            \n            if not text:\n                print(f\"  âš ï¸  Warning: Could not extract text from {file_path}\")\n                continue\n            \n            print(f\"  âœ“ Extracted {len(text)} characters\")\n            results['documents_processed'] += 1\n            results['total_content_length'] += len(text)\n            \n            # Store document summary\n            self.document_summaries[doc_type] = {\n                'length': len(text),\n                'preview': text[:500],\n                'sentences': len(sent_tokenize(text))\n            }\n            \n            # Extract information based on document type\n            if doc_type == 'module_matching':\n                self.modules = self.processor.parse_modules_enhanced(text)\n                results['extraction_summary']['modules'] = len(self.modules)\n                print(f\"  âœ“ Extracted {len(self.modules)} modules\")\n                \n            elif doc_type == 'gap_analysis':\n                self.gaps = self.processor.parse_gaps_enhanced(text)\n                results['extraction_summary']['gaps'] = len(self.gaps)\n                print(f\"  âœ“ Extracted {len(self.gaps)} gaps\")\n                \n            elif doc_type == 'win_loss':\n                self.win_loss_factors = self.processor.parse_win_loss_enhanced(text)\n                results['extraction_summary']['win_loss_factors'] = len(self.win_loss_factors)\n                print(f\"  âœ“ Extracted {len(self.win_loss_factors)} win/loss factors\")\n                \n            elif doc_type == 'customer_needs':\n                self.requirements = self.processor.parse_requirements_enhanced(text)\n                results['extraction_summary']['requirements'] = len(self.requirements)\n                print(f\"  âœ“ Extracted {len(self.requirements)} requirements\")\n        \n        return results\n    \n    def calculate_feasibility(self) -> RFPFeasibilityAssessment:\n        \"\"\"Calculate overall feasibility of responding to RFP\"\"\"\n        \n        # Module analysis\n        total_modules = len(self.modules)\n        available_modules = len([m for m in self.modules if m.status in [\"Available\", \"Partial\"]])\n        partial_modules = len([m for m in self.modules if m.status == \"Partial\"])\n        missing_modules = len([m for m in self.modules if m.status in [\"Missing\", \"Unknown\"]])\n        \n        module_coverage = (available_modules / total_modules * 100) if total_modules > 0 else 0\n        \n        # Gap analysis\n        critical_gaps = [g for g in self.gaps if g.severity in ['Critical', 'High']]\n        medium_gaps = [g for g in self.gaps if g.severity == 'Medium']\n        low_gaps = [g for g in self.gaps if g.severity == 'Low']\n        \n        # Requirements analysis\n        must_have_reqs = [r for r in self.requirements if r.priority == 'Must Have']\n        met_must_haves = [r for r in must_have_reqs if r.our_capability in ['Full', 'Partial']]\n        requirement_coverage = (len(met_must_haves) / len(must_have_reqs) * 100) if must_have_reqs else 100\n        \n        # Win/Loss analysis\n        win_factors = [f for f in self.win_loss_factors if f.factor_type == 'Win']\n        loss_factors = [f for f in self.win_loss_factors if f.factor_type == 'Loss']\n        win_loss_ratio = len(win_factors) / (len(loss_factors) + 1)  # +1 to avoid division by zero\n        \n        # Calculate confidence score (0-100)\n        confidence_score = 0\n        \n        # Module coverage (30% weight)\n        confidence_score += module_coverage * 0.3\n        \n        # Requirement coverage (30% weight)\n        confidence_score += requirement_coverage * 0.3\n        \n        # Gap severity (20% weight - inverse)\n        gap_penalty = len(critical_gaps) * 10 + len(medium_gaps) * 5 + len(low_gaps) * 2\n        confidence_score += max(0, 20 - gap_penalty)\n        \n        # Win/Loss history (20% weight)\n        if win_loss_ratio > 2:\n            confidence_score += 20\n        elif win_loss_ratio > 1:\n            confidence_score += 15\n        elif win_loss_ratio > 0.5:\n            confidence_score += 10\n        else:\n            confidence_score += 5\n        \n        # Determine if we can respond\n        can_respond = confidence_score >= 60 and len(critical_gaps) <= 2\n        \n        # Calculate win probability (includes market factors)\n        win_probability = confidence_score * 0.8 if can_respond else confidence_score * 0.5\n        \n        # Generate SWOT analysis\n        strengths = [\n            f\"Strong win/loss ratio: {win_loss_ratio:.1f}\" if win_loss_ratio > 1 else None,\n            f\"{available_modules} modules already available\" if available_modules > 0 else None,\n            f\"{len(met_must_haves)} must-have requirements already met\" if met_must_haves else None,\n        ] + [f.description for f in win_factors[:3]]\n        strengths = [s for s in strengths if s]  # Remove None values\n        \n        weaknesses = [\n            f\"{missing_modules} modules missing or unknown\" if missing_modules > 0 else None,\n            f\"{len(critical_gaps)} critical gaps identified\" if critical_gaps else None,\n            f\"Low requirement coverage: {requirement_coverage:.0f}%\" if requirement_coverage < 70 else None,\n        ] + [f.description for f in loss_factors[:3]]\n        weaknesses = [w for w in weaknesses if w]  # Remove None values\n        \n        opportunities = [\n            \"Quick wins possible with partial modules\" if partial_modules > 0 else None,\n            \"Experience from previous wins can be leveraged\" if win_factors else None,\n            \"Gap mitigation strategies identified\" if self.gaps else None,\n        ]\n        opportunities = [o for o in opportunities if o]\n        \n        threats = [\n            \"Critical gaps may disqualify response\" if critical_gaps else None,\n            \"Previous loss factors still relevant\" if loss_factors else None,\n            \"Significant development effort required\" if missing_modules > total_modules * 0.3 else None,\n        ]\n        threats = [t for t in threats if t]\n        \n        # Generate required actions\n        required_actions = []\n        \n        # Add actions for critical gaps\n        for gap in critical_gaps[:3]:\n            required_actions.append((\n                f\"Address {gap.gap_type} gap: {gap.description[:50]}...\",\n                gap.severity,\n                gap.effort_required,\n                \"Gap Team\"\n            ))\n        \n        # Add actions for missing must-have requirements\n        unmet_must_haves = [r for r in must_have_reqs if r.our_capability in ['None', 'Partial']]\n        for req in unmet_must_haves[:2]:\n            required_actions.append((\n                f\"Develop capability for {req.requirement_type}: {req.description[:40]}...\",\n                \"High\",\n                req.effort_to_meet,\n                \"Development Team\"\n            ))\n        \n        # Add actions for missing modules\n        critical_missing_modules = [m for m in self.modules if m.status == \"Missing\" and m.client_priority == \"High\"]\n        for module in critical_missing_modules[:2]:\n            required_actions.append((\n                f\"Acquire/develop module: {module.module_name}\",\n                \"Critical\",\n                \"2-4 weeks\",\n                \"Technical Team\"\n            ))\n        \n        # Risk assessment\n        risks = []\n        if len(critical_gaps) > 0:\n            risks.append(RiskAssessment(\n                risk_type=\"Technical\",\n                description=f\"{len(critical_gaps)} critical technical gaps may prevent successful delivery\",\n                probability=\"High\" if len(critical_gaps) > 2 else \"Medium\",\n                impact=\"High\",\n                mitigation_plan=\"Fast-track gap closure with dedicated resources\"\n            ))\n        \n        if module_coverage < 70:\n            risks.append(RiskAssessment(\n                risk_type=\"Delivery\",\n                description=f\"Low module coverage ({module_coverage:.0f}%) risks delivery timeline\",\n                probability=\"High\",\n                impact=\"Medium\",\n                mitigation_plan=\"Partner or acquire missing modules\"\n            ))\n        \n        if requirement_coverage < 80:\n            risks.append(RiskAssessment(\n                risk_type=\"Commercial\",\n                description=f\"Requirement gaps may impact client satisfaction\",\n                probability=\"Medium\",\n                impact=\"High\",\n                mitigation_plan=\"Clearly communicate development roadmap to client\"\n            ))\n        \n        # Investment and timeline estimates\n        investment_parts = []\n        timeline_parts = []\n        \n        if missing_modules > 0:\n            investment_parts.append(f\"${missing_modules * 50}K-${missing_modules * 100}K for module development\")\n            timeline_parts.append(f\"{missing_modules * 2}-{missing_modules * 4} weeks for modules\")\n        \n        if len(critical_gaps) > 0:\n            investment_parts.append(f\"${len(critical_gaps) * 25}K-${len(critical_gaps) * 50}K for gap mitigation\")\n            timeline_parts.append(f\"{len(critical_gaps)}-{len(critical_gaps) * 2} weeks for critical gaps\")\n        \n        investment_required = \" + \".join(investment_parts) if investment_parts else \"Minimal investment required\"\n        timeline_estimate = \", \".join(timeline_parts) if timeline_parts else \"Can proceed immediately\"\n        \n        # Resource requirements\n        resource_needs = []\n        if missing_modules > 5:\n            resource_needs.append(f\"{missing_modules // 2} developers\")\n        if len(critical_gaps) > 3:\n            resource_needs.append(f\"{len(critical_gaps) // 2} architects\")\n        if len(unmet_must_haves) > 0:\n            resource_needs.append(\"1-2 business analysts\")\n        \n        resource_requirements = \", \".join(resource_needs) if resource_needs else \"Existing team sufficient\"\n        \n        # Generate detailed rationale\n        detailed_rationale = f\"\"\"\n## Feasibility Analysis Details\n\n### Module Readiness\n- Total Modules Analyzed: {total_modules}\n- Available: {available_modules} ({available_modules/total_modules*100:.1f}%)\n- Partial: {partial_modules} ({partial_modules/total_modules*100:.1f}%)\n- Missing: {missing_modules} ({missing_modules/total_modules*100:.1f}%)\n\n### Requirements Coverage\n- Must-Have Requirements: {len(must_have_reqs)}\n- Currently Met: {len(met_must_haves)} ({requirement_coverage:.1f}%)\n- Gap to Close: {len(unmet_must_haves)} requirements\n\n### Risk Assessment\n- Critical Gaps: {len(critical_gaps)}\n- Total Risks Identified: {len(risks)}\n- Highest Risk Area: {\"Technical\" if len(critical_gaps) > 2 else \"Delivery\" if module_coverage < 70 else \"Commercial\"}\n\n### Historical Performance\n- Win/Loss Ratio: {win_loss_ratio:.2f}\n- Key Success Factors: {len(win_factors)}\n- Known Challenges: {len(loss_factors)}\n\n### Investment & Timeline\n- Estimated Investment: {investment_required}\n- Timeline to RFP-Ready: {timeline_estimate}\n- Resources Needed: {resource_requirements}\n        \"\"\".strip()\n        \n        # Competitive positioning\n        competitive_positioning = f\"\"\"\nBased on our analysis:\n- Market Position: {\"Strong\" if win_loss_ratio > 1.5 else \"Average\" if win_loss_ratio > 0.7 else \"Weak\"}\n- Key Differentiators: {', '.join([s[:30] + '...' for s in strengths[:3]]) if strengths else 'Limited differentiators identified'}\n- Competitive Gaps: {', '.join([w[:30] + '...' for w in weaknesses[:3]]) if weaknesses else 'No major gaps identified'}\n        \"\"\".strip()\n        \n        # Executive summary\n        executive_summary = f\"\"\"\n## RFP Response Feasibility Assessment\n\n**Decision: {\"GO - Proceed with Response\" if can_respond else \"NO-GO - Do Not Proceed\"}**\n\n### Key Metrics:\n- Overall Confidence: {confidence_score:.1f}%\n- Win Probability: {win_probability:.1f}%\n- Module Coverage: {module_coverage:.1f}%\n- Requirement Coverage: {requirement_coverage:.1f}%\n\n### Summary:\nBased on analysis of {len(self.document_summaries)} documents containing {sum(d['length'] for d in self.document_summaries.values())} characters of content:\n\n- **Modules**: {available_modules}/{total_modules} available ({module_coverage:.0f}% coverage)\n- **Requirements**: {len(met_must_haves)}/{len(must_have_reqs)} must-haves met ({requirement_coverage:.0f}% coverage)\n- **Gaps**: {len(critical_gaps)} critical, {len(medium_gaps)} medium, {len(low_gaps)} low severity\n- **Win/Loss**: Historical ratio of {win_loss_ratio:.1f} based on {len(self.win_loss_factors)} factors\n\n### Recommendation:\n{\"âœ… **Proceed with RFP response.** While there are gaps to address, our historical performance and current capabilities provide a solid foundation for a competitive response.\" if can_respond else \"âŒ **Do not proceed without significant preparation.** Critical gaps and low coverage indicate high risk of unsuccessful response or delivery failure.\"}\n\n### Next Steps:\n1. {required_actions[0][0] if required_actions else \"Proceed with standard RFP response process\"}\n2. {required_actions[1][0] if len(required_actions) > 1 else \"Allocate resources for response preparation\"}\n3. {required_actions[2][0] if len(required_actions) > 2 else \"Schedule stakeholder review meeting\"}\n        \"\"\".strip()\n        \n        return RFPFeasibilityAssessment(\n            can_respond=can_respond,\n            confidence_score=confidence_score,\n            win_probability=win_probability,\n            total_modules=total_modules,\n            available_modules=available_modules,\n            partial_modules=partial_modules,\n            missing_modules=missing_modules,\n            critical_gaps=critical_gaps,\n            all_gaps=self.gaps,\n            strengths=strengths,\n            weaknesses=weaknesses,\n            opportunities=opportunities,\n            threats=threats,\n            required_actions=required_actions,\n            risks=risks,\n            investment_required=investment_required,\n            timeline_estimate=timeline_estimate,\n            resource_requirements=resource_requirements,\n            executive_summary=executive_summary,\n            detailed_rationale=detailed_rationale,\n            competitive_positioning=competitive_positioning\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T08:43:09.104066Z","iopub.execute_input":"2025-07-29T08:43:09.104350Z","iopub.status.idle":"2025-07-29T08:43:09.143363Z","shell.execute_reply.started":"2025-07-29T08:43:09.104333Z","shell.execute_reply":"2025-07-29T08:43:09.142623Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"class RFPFeasibilityAnalyzer:\n    \"\"\"Main analyzer that determines if we can respond to the RFP\"\"\"\n    \n    def __init__(self):\n        self.processor = DocumentProcessor()\n        self.modules = []\n        self.gaps = []\n        self.win_loss_factors = []\n        self.requirements = []\n        self.document_summaries = {}\n        \n    def load_and_analyze_documents(self, file_paths: Dict[str, str]) -> Dict[str, Any]:\n        \"\"\"Load documents and extract structured information\"\"\"\n        results = {\n            'documents_processed': 0,\n            'total_content_length': 0,\n            'extraction_summary': {}\n        }\n        \n        for doc_type, file_path in file_paths.items():\n            print(f\"\\nðŸ“„ Analyzing {doc_type}...\")\n            text = self.processor.extract_text_from_file(file_path)\n            \n            if not text:\n                print(f\"  âš ï¸  Warning: Could not extract text from {file_path}\")\n                continue\n            \n            print(f\"  âœ“ Extracted {len(text)} characters\")\n            results['documents_processed'] += 1\n            results['total_content_length'] += len(text)\n            \n            # Store document summary\n            self.document_summaries[doc_type] = {\n                'length': len(text),\n                'preview': text[:500],\n                'sentences': len(sent_tokenize(text))\n            }\n            \n            # Extract information based on document type\n            if doc_type == 'module_matching':\n                self.modules = self.processor.parse_modules_enhanced(text)\n                results['extraction_summary']['modules'] = len(self.modules)\n                print(f\"  âœ“ Extracted {len(self.modules)} modules\")\n                \n            elif doc_type == 'gap_analysis':\n                self.gaps = self.processor.parse_gaps_enhanced(text)\n                results['extraction_summary']['gaps'] = len(self.gaps)\n                print(f\"  âœ“ Extracted {len(self.gaps)} gaps\")\n                \n            elif doc_type == 'win_loss':\n                self.win_loss_factors = self.processor.parse_win_loss_enhanced(text)\n                results['extraction_summary']['win_loss_factors'] = len(self.win_loss_factors)\n                print(f\"  âœ“ Extracted {len(self.win_loss_factors)} win/loss factors\")\n                \n            elif doc_type == 'customer_needs':\n                self.requirements = self.processor.parse_requirements_enhanced(text)\n                results['extraction_summary']['requirements'] = len(self.requirements)\n                print(f\"  âœ“ Extracted {len(self.requirements)} requirements\")\n        \n        return results\n    \n    def calculate_feasibility(self) -> RFPFeasibilityAssessment:\n        \"\"\"Calculate overall feasibility of responding to RFP\"\"\"\n        \n        # Module analysis\n        total_modules = len(self.modules)\n        available_modules = len([m for m in self.modules if m.status in [\"Available\", \"Partial\"]])\n        partial_modules = len([m for m in self.modules if m.status == \"Partial\"])\n        missing_modules = len([m for m in self.modules if m.status in [\"Missing\", \"Unknown\"]])\n        \n        module_coverage = (available_modules / total_modules * 100) if total_modules > 0 else 0\n        \n        # Gap analysis\n        critical_gaps = [g for g in self.gaps if g.severity in ['Critical', 'High']]\n        medium_gaps = [g for g in self.gaps if g.severity == 'Medium']\n        low_gaps = [g for g in self.gaps if g.severity == 'Low']\n        \n        # Requirements analysis\n        must_have_reqs = [r for r in self.requirements if r.priority == 'Must Have']\n        met_must_haves = [r for r in must_have_reqs if r.our_capability in ['Full', 'Partial']]\n        requirement_coverage = (len(met_must_haves) / len(must_have_reqs) * 100) if must_have_reqs else 100\n        \n        # Win/Loss analysis\n        win_factors = [f for f in self.win_loss_factors if f.factor_type == 'Win']\n        loss_factors = [f for f in self.win_loss_factors if f.factor_type == 'Loss']\n        win_loss_ratio = len(win_factors) / (len(loss_factors) + 1)  # +1 to avoid division by zero\n        \n        # Calculate confidence score (0-100)\n        confidence_score = 0\n        \n        # Module coverage (30% weight)\n        confidence_score += module_coverage * 0.3\n        \n        # Requirement coverage (30% weight)\n        confidence_score += requirement_coverage * 0.3\n        \n        # Gap severity (20% weight - inverse)\n        gap_penalty = len(critical_gaps) * 10 + len(medium_gaps) * 5 + len(low_gaps) * 2\n        confidence_score += max(0, 20 - gap_penalty)\n        \n        # Win/Loss history (20% weight)\n        if win_loss_ratio > 2:\n            confidence_score += 20\n        elif win_loss_ratio > 1:\n            confidence_score += 15\n        elif win_loss_ratio > 0.5:\n            confidence_score += 10\n        else:\n            confidence_score += 5\n        \n        # Determine if we can respond\n        can_respond = confidence_score >= 60 and len(critical_gaps) <= 2\n        \n        # Calculate win probability (includes market factors)\n        win_probability = confidence_score * 0.8 if can_respond else confidence_score * 0.5\n        \n        # Generate SWOT analysis\n        strengths = [\n            f\"Strong win/loss ratio: {win_loss_ratio:.1f}\" if win_loss_ratio > 1 else None,\n            f\"{available_modules} modules already available\" if available_modules > 0 else None,\n            f\"{len(met_must_haves)} must-have requirements already met\" if met_must_haves else None,\n        ] + [f.description for f in win_factors[:3]]\n        strengths = [s for s in strengths if s]  # Remove None values\n        \n        weaknesses = [\n            f\"{missing_modules} modules missing or unknown\" if missing_modules > 0 else None,\n            f\"{len(critical_gaps)} critical gaps identified\" if critical_gaps else None,\n            f\"Low requirement coverage: {requirement_coverage:.0f}%\" if requirement_coverage < 70 else None,\n        ] + [f.description for f in loss_factors[:3]]\n        weaknesses = [w for w in weaknesses if w]  # Remove None values\n        \n        opportunities = [\n            \"Quick wins possible with partial modules\" if partial_modules > 0 else None,\n            \"Experience from previous wins can be leveraged\" if win_factors else None,\n            \"Gap mitigation strategies identified\" if self.gaps else None,\n        ]\n        opportunities = [o for o in opportunities if o]\n        \n        threats = [\n            \"Critical gaps may disqualify response\" if critical_gaps else None,\n            \"Previous loss factors still relevant\" if loss_factors else None,\n            \"Significant development effort required\" if missing_modules > total_modules * 0.3 else None,\n        ]\n        threats = [t for t in threats if t]\n        \n        # Generate required actions\n        required_actions = []\n        \n        # Add actions for critical gaps\n        for gap in critical_gaps[:3]:\n            required_actions.append((\n                f\"Address {gap.gap_type} gap: {gap.description[:50]}...\",\n                gap.severity,\n                gap.effort_required,\n                \"Gap Team\"\n            ))\n        \n        # Add actions for missing must-have requirements\n        unmet_must_haves = [r for r in must_have_reqs if r.our_capability in ['None', 'Partial']]\n        for req in unmet_must_haves[:2]:\n            required_actions.append((\n                f\"Develop capability for {req.requirement_type}: {req.description[:40]}...\",\n                \"High\",\n                req.effort_to_meet,\n                \"Development Team\"\n            ))\n        \n        # Add actions for missing modules\n        critical_missing_modules = [m for m in self.modules if m.status == \"Missing\" and m.client_priority == \"High\"]\n        for module in critical_missing_modules[:2]:\n            required_actions.append((\n                f\"Acquire/develop module: {module.module_name}\",\n                \"Critical\",\n                \"2-4 weeks\",\n                \"Technical Team\"\n            ))\n        \n        # Risk assessment\n        risks = []\n        if len(critical_gaps) > 0:\n            risks.append(RiskAssessment(\n                risk_type=\"Technical\",\n                description=f\"{len(critical_gaps)} critical technical gaps may prevent successful delivery\",\n                probability=\"High\" if len(critical_gaps) > 2 else \"Medium\",\n                impact=\"High\",\n                mitigation_plan=\"Fast-track gap closure with dedicated resources\"\n            ))\n        \n        if module_coverage < 70:\n            risks.append(RiskAssessment(\n                risk_type=\"Delivery\",\n                description=f\"Low module coverage ({module_coverage:.0f}%) risks delivery timeline\",\n                probability=\"High\",\n                impact=\"Medium\",\n                mitigation_plan=\"Partner or acquire missing modules\"\n            ))\n        \n        if requirement_coverage < 80:\n            risks.append(RiskAssessment(\n                risk_type=\"Commercial\",\n                description=f\"Requirement gaps may impact client satisfaction\",\n                probability=\"Medium\",\n                impact=\"High\",\n                mitigation_plan=\"Clearly communicate development roadmap to client\"\n            ))\n        \n        # Investment and timeline estimates\n        investment_parts = []\n        timeline_parts = []\n        \n        if missing_modules > 0:\n            investment_parts.append(f\"${missing_modules * 50}K-${missing_modules * 100}K for module development\")\n            timeline_parts.append(f\"{missing_modules * 2}-{missing_modules * 4} weeks for modules\")\n        \n        if len(critical_gaps) > 0:\n            investment_parts.append(f\"${len(critical_gaps) * 25}K-${len(critical_gaps) * 50}K for gap mitigation\")\n            timeline_parts.append(f\"{len(critical_gaps)}-{len(critical_gaps) * 2} weeks for critical gaps\")\n        \n        investment_required = \" + \".join(investment_parts) if investment_parts else \"Minimal investment required\"\n        timeline_estimate = \", \".join(timeline_parts) if timeline_parts else \"Can proceed immediately\"\n        \n        # Resource requirements\n        resource_needs = []\n        if missing_modules > 5:\n            resource_needs.append(f\"{missing_modules // 2} developers\")\n        if len(critical_gaps) > 3:\n            resource_needs.append(f\"{len(critical_gaps) // 2} architects\")\n        if len(unmet_must_haves) > 0:\n            resource_needs.append(\"1-2 business analysts\")\n        \n        resource_requirements = \", \".join(resource_needs) if resource_needs else \"Existing team sufficient\"\n        \n        # Generate detailed rationale\n        detailed_rationale = f\"\"\"\n## Feasibility Analysis Details\n\n### Module Readiness\n- Total Modules Analyzed: {total_modules}\n- Available: {available_modules} ({available_modules/total_modules*100:.1f}%)\n- Partial: {partial_modules} ({partial_modules/total_modules*100:.1f}%)\n- Missing: {missing_modules} ({missing_modules/total_modules*100:.1f}%)\n\n### Requirements Coverage\n- Must-Have Requirements: {len(must_have_reqs)}\n- Currently Met: {len(met_must_haves)} ({requirement_coverage:.1f}%)\n- Gap to Close: {len(unmet_must_haves)} requirements\n\n### Risk Assessment\n- Critical Gaps: {len(critical_gaps)}\n- Total Risks Identified: {len(risks)}\n- Highest Risk Area: {\"Technical\" if len(critical_gaps) > 2 else \"Delivery\" if module_coverage < 70 else \"Commercial\"}\n\n### Historical Performance\n- Win/Loss Ratio: {win_loss_ratio:.2f}\n- Key Success Factors: {len(win_factors)}\n- Known Challenges: {len(loss_factors)}\n\n### Investment & Timeline\n- Estimated Investment: {investment_required}\n- Timeline to RFP-Ready: {timeline_estimate}\n- Resources Needed: {resource_requirements}\n        \"\"\".strip()\n        \n        # Competitive positioning\n        competitive_positioning = f\"\"\"\nBased on our analysis:\n- Market Position: {\"Strong\" if win_loss_ratio > 1.5 else \"Average\" if win_loss_ratio > 0.7 else \"Weak\"}\n- Key Differentiators: {', '.join([s[:30] + '...' for s in strengths[:3]]) if strengths else 'Limited differentiators identified'}\n- Competitive Gaps: {', '.join([w[:30] + '...' for w in weaknesses[:3]]) if weaknesses else 'No major gaps identified'}\n        \"\"\".strip()\n        \n        # Executive summary\n        executive_summary = f\"\"\"\n## RFP Response Feasibility Assessment\n\n**Decision: {\"GO - Proceed with Response\" if can_respond else \"NO-GO - Do Not Proceed\"}**\n\n### Key Metrics:\n- Overall Confidence: {confidence_score:.1f}%\n- Win Probability: {win_probability:.1f}%\n- Module Coverage: {module_coverage:.1f}%\n- Requirement Coverage: {requirement_coverage:.1f}%\n\n### Summary:\nBased on analysis of {len(self.document_summaries)} documents containing {sum(d['length'] for d in self.document_summaries.values())} characters of content:\n\n- **Modules**: {available_modules}/{total_modules} available ({module_coverage:.0f}% coverage)\n- **Requirements**: {len(met_must_haves)}/{len(must_have_reqs)} must-haves met ({requirement_coverage:.0f}% coverage)\n- **Gaps**: {len(critical_gaps)} critical, {len(medium_gaps)} medium, {len(low_gaps)} low severity\n- **Win/Loss**: Historical ratio of {win_loss_ratio:.1f} based on {len(self.win_loss_factors)} factors\n\n### Recommendation:\n{\"âœ… **Proceed with RFP response.** While there are gaps to address, our historical performance and current capabilities provide a solid foundation for a competitive response.\" if can_respond else \"âŒ **Do not proceed without significant preparation.** Critical gaps and low coverage indicate high risk of unsuccessful response or delivery failure.\"}\n\n### Next Steps:\n1. {required_actions[0][0] if required_actions else \"Proceed with standard RFP response process\"}\n2. {required_actions[1][0] if len(required_actions) > 1 else \"Allocate resources for response preparation\"}\n3. {required_actions[2][0] if len(required_actions) > 2 else \"Schedule stakeholder review meeting\"}\n        \"\"\".strip()\n        \n        return RFPFeasibilityAssessment(\n            can_respond=can_respond,\n            confidence_score=confidence_score,\n            win_probability=win_probability,\n            total_modules=total_modules,\n            available_modules=available_modules,\n            partial_modules=partial_modules,\n            missing_modules=missing_modules,\n            critical_gaps=critical_gaps,\n            all_gaps=self.gaps,\n            strengths=strengths,\n            weaknesses=weaknesses,\n            opportunities=opportunities,\n            threats=threats,\n            required_actions=required_actions,\n            risks=risks,\n            investment_required=investment_required,\n            timeline_estimate=timeline_estimate,\n            resource_requirements=resource_requirements,\n            executive_summary=executive_summary,\n            detailed_rationale=detailed_rationale,\n            competitive_positioning=competitive_positioning\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T08:43:09.151374Z","iopub.execute_input":"2025-07-29T08:43:09.151848Z","iopub.status.idle":"2025-07-29T08:43:09.182770Z","shell.execute_reply.started":"2025-07-29T08:43:09.151821Z","shell.execute_reply":"2025-07-29T08:43:09.182300Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"def main():\n    \"\"\"Main function to run the RFP feasibility analysis\"\"\"\n    \n    print(\"=\" * 70)\n    print(\"RFP RESPONSE FEASIBILITY ANALYZER v2.0\")\n    print(\"=\" * 70)\n    print(\"Comprehensive document analysis for RFP go/no-go decision making\")\n    print(\"-\" * 70)\n    \n    # Initialize the analyzer\n    analyzer = RFPFeasibilityAnalyzer()\n    \n    # Define file paths\n    file_paths = {\n        'module_matching': '/kaggle/input/input-reports-fr-agent/module-matching-report.pdf',\n        'win_loss': '/kaggle/input/input-reports-fr-agent/win_loss_analysis.pdf', \n        'gap_analysis': '/kaggle/input/input-reports-fr-agent/gap_analysis_report.pdf',\n        'customer_needs': '/kaggle/input/input-reports-fr-agent/customer_needs_report.pdf'\n    }\n    \n    print(\"\\nðŸ“ Input Documents:\")\n    for doc_type, path in file_paths.items():\n        print(f\"   â€¢ {doc_type.replace('_', ' ').title()}: {os.path.basename(path)}\")\n    \n    print(\"\\n\" + \"-\" * 70)\n    print(\"STARTING ANALYSIS...\")\n    print(\"-\" * 70)\n    \n    try:\n        # Load and analyze documents\n        results = analyzer.load_and_analyze_documents(file_paths)\n        \n        print(\"\\n\" + \"=\" * 70)\n        print(\"EXTRACTION SUMMARY\")\n        print(\"=\" * 70)\n        print(f\"Documents Processed: {results['documents_processed']}\")\n        print(f\"Total Content Analyzed: {results['total_content_length']:,} characters\")\n        print(\"\\nExtracted Items:\")\n        for item_type, count in results['extraction_summary'].items():\n            print(f\"   â€¢ {item_type.replace('_', ' ').title()}: {count}\")\n        \n        # Calculate feasibility\n        print(\"\\n\" + \"-\" * 70)\n        print(\"CALCULATING FEASIBILITY...\")\n        print(\"-\" * 70)\n        \n        assessment = analyzer.calculate_feasibility()\n        \n        # Display results\n        print(\"\\n\" + \"=\" * 70)\n        print(\"FEASIBILITY ASSESSMENT RESULTS\")\n        print(\"=\" * 70)\n        print(f\"\\n{'âœ… GO' if assessment.can_respond else 'âŒ NO-GO'} - {'Proceed with RFP Response' if assessment.can_respond else 'Do Not Proceed'}\")\n        print(f\"\\nConfidence Score: {assessment.confidence_score:.1f}%\")\n        print(f\"Win Probability: {assessment.win_probability:.1f}%\")\n        print(f\"\\nModule Coverage: {assessment.available_modules}/{assessment.total_modules} ({(assessment.available_modules/assessment.total_modules*100) if assessment.total_modules > 0 else 0:.0f}%)\")\n        print(f\"Critical Gaps: {len(assessment.critical_gaps)}\")\n        print(f\"Total Risks: {len(assessment.risks)}\")\n        \n        # Investment summary\n        print(f\"\\nInvestment Required: {assessment.investment_required}\")\n        print(f\"Timeline Estimate: {assessment.timeline_estimate}\")\n        print(f\"Resources Needed: {assessment.resource_requirements}\")\n        \n        # Top actions\n        if assessment.required_actions:\n            print(\"\\nðŸŽ¯ TOP PRIORITY ACTIONS:\")\n            for i, (action, priority, timeline, owner) in enumerate(assessment.required_actions[:3], 1):\n                print(f\"   {i}. [{priority}] {action}\")\n                print(f\"      Timeline: {timeline} | Owner: {owner}\")\n        \n        # Generate PDF report\n        output_path = \"/kaggle/working/rfp_feasibility_report_enhanced.pdf\"\n        print(\"\\n\" + \"-\" * 70)\n        print(\"GENERATING COMPREHENSIVE REPORT...\")\n        print(\"-\" * 70)\n        \n        generator = RFPFeasibilityReportGenerator()\n        generator.generate_report(analyzer, assessment, output_path)\n        \n        print(\"\\n\" + \"=\" * 70)\n        print(\"âœ… ANALYSIS COMPLETE!\")\n        print(\"=\" * 70)\n        print(f\"ðŸ“Š Detailed report saved to: {output_path}\")\n        print(f\"ðŸ“ˆ Total analysis time: ~{datetime.now().strftime('%S')} seconds\")\n        \n    except Exception as e:\n        print(f\"\\nâŒ ERROR during analysis: {e}\")\n        import traceback\n        traceback.print_exc()\n        print(\"\\nPlease check that all input files exist and are readable.\")\n\n# ## 9. Run the Analysis\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-29T08:43:09.296502Z","iopub.execute_input":"2025-07-29T08:43:09.296689Z","iopub.status.idle":"2025-07-29T08:43:10.836845Z","shell.execute_reply.started":"2025-07-29T08:43:09.296675Z","shell.execute_reply":"2025-07-29T08:43:10.836236Z"}},"outputs":[{"name":"stdout","text":"======================================================================\nRFP RESPONSE FEASIBILITY ANALYZER v2.0\n======================================================================\nComprehensive document analysis for RFP go/no-go decision making\n----------------------------------------------------------------------\n\nðŸ“ Input Documents:\n   â€¢ Module Matching: module-matching-report.pdf\n   â€¢ Win Loss: win_loss_analysis.pdf\n   â€¢ Gap Analysis: gap_analysis_report.pdf\n   â€¢ Customer Needs: customer_needs_report.pdf\n\n----------------------------------------------------------------------\nSTARTING ANALYSIS...\n----------------------------------------------------------------------\n\nðŸ“„ Analyzing module_matching...\nâœ“ Extracted 17155 characters using pdfplumber\n  âœ“ Extracted 17141 characters\n  âœ“ Extracted 11 modules\n\nðŸ“„ Analyzing win_loss...\nâœ“ Extracted 11687 characters using pdfplumber\n  âœ“ Extracted 11669 characters\n  âœ“ Extracted 1 win/loss factors\n\nðŸ“„ Analyzing gap_analysis...\nâœ“ Extracted 3815 characters using pdfplumber\n  âœ“ Extracted 3813 characters\n  âœ“ Extracted 0 gaps\n\nðŸ“„ Analyzing customer_needs...\nâœ“ Extracted 2804 characters using pdfplumber\n  âœ“ Extracted 2802 characters\n  âœ“ Extracted 1 requirements\n\n======================================================================\nEXTRACTION SUMMARY\n======================================================================\nDocuments Processed: 4\nTotal Content Analyzed: 35,425 characters\n\nExtracted Items:\n   â€¢ Modules: 11\n   â€¢ Win Loss Factors: 1\n   â€¢ Gaps: 0\n   â€¢ Requirements: 1\n\n----------------------------------------------------------------------\nCALCULATING FEASIBILITY...\n----------------------------------------------------------------------\n\n======================================================================\nFEASIBILITY ASSESSMENT RESULTS\n======================================================================\n\nâœ… GO - Proceed with RFP Response\n\nConfidence Score: 60.0%\nWin Probability: 48.0%\n\nModule Coverage: 0/11 (0%)\nCritical Gaps: 0\nTotal Risks: 1\n\nInvestment Required: $550K-$1100K for module development\nTimeline Estimate: 22-44 weeks for modules\nResources Needed: 5 developers\n\n----------------------------------------------------------------------\nGENERATING COMPREHENSIVE REPORT...\n----------------------------------------------------------------------\nâœ… RFP Feasibility Report generated successfully: /kaggle/working/rfp_feasibility_report_enhanced.pdf\n\n======================================================================\nâœ… ANALYSIS COMPLETE!\n======================================================================\nðŸ“Š Detailed report saved to: /kaggle/working/rfp_feasibility_report_enhanced.pdf\nðŸ“ˆ Total analysis time: ~10 seconds\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}