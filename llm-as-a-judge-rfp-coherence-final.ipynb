{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"027af7a3e108497592227fd14e4a2740":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a3948cb87263427eb6eba8127b8c4b08","IPY_MODEL_8341e8c6837c4b81960f8549ca39a684","IPY_MODEL_5c01413b26dc4e609f562a1ffa3ee91d"],"layout":"IPY_MODEL_43da1214122a4d5b965c4c3b33ecc298"}},"a3948cb87263427eb6eba8127b8c4b08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e00f0556203441a586dabbeedc8fad19","placeholder":"​","style":"IPY_MODEL_f5838fc4a49d45f29840f6c59ebeb0bf","value":"tokenizer_config.json: "}},"8341e8c6837c4b81960f8549ca39a684":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30b50814bc4c47b19d099edeaedceb2d","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91d4a0c8c7954bf4b487da425a0a166e","value":1}},"5c01413b26dc4e609f562a1ffa3ee91d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_136c624e7e304611a3ba3a6a90012c3a","placeholder":"​","style":"IPY_MODEL_8219489df8f7442492bb1ca77e162b3d","value":" 1.87k/? [00:00&lt;00:00, 53.2kB/s]"}},"43da1214122a4d5b965c4c3b33ecc298":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e00f0556203441a586dabbeedc8fad19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5838fc4a49d45f29840f6c59ebeb0bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30b50814bc4c47b19d099edeaedceb2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"91d4a0c8c7954bf4b487da425a0a166e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"136c624e7e304611a3ba3a6a90012c3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8219489df8f7442492bb1ca77e162b3d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2c7457efb85c41a09187789616cce1f5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4beefaaa29604275a2e6debe7ef74f8f","IPY_MODEL_265f0b863312419d874b62bcda207f9a","IPY_MODEL_0c2d5bf61ddf47589b265188e4df1ecf"],"layout":"IPY_MODEL_0e5fd54585bb4970b53f0690c43f7a50"}},"4beefaaa29604275a2e6debe7ef74f8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_754cfc67fd6d45e8a0bf4616a311aac7","placeholder":"​","style":"IPY_MODEL_6ea125df4d28465796f93c5194bc842d","value":"tokenizer.json: "}},"265f0b863312419d874b62bcda207f9a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3baf0006eebe4f7595c90d1c9c5d82dd","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_789590a0e3684f848721a074b0e7fbe7","value":1}},"0c2d5bf61ddf47589b265188e4df1ecf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9df3d57908784f2289d4109b98a80039","placeholder":"​","style":"IPY_MODEL_ac19921f8cf44e95affbc4b6d121295f","value":" 1.37M/? [00:00&lt;00:00, 9.63MB/s]"}},"0e5fd54585bb4970b53f0690c43f7a50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"754cfc67fd6d45e8a0bf4616a311aac7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ea125df4d28465796f93c5194bc842d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3baf0006eebe4f7595c90d1c9c5d82dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"789590a0e3684f848721a074b0e7fbe7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9df3d57908784f2289d4109b98a80039":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac19921f8cf44e95affbc4b6d121295f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8b703a03bbd84aa9aae34d41097a2824":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a0eea243b6e147d996d4fe4ad883ba46","IPY_MODEL_f3b2909332bd4d92aac1567dbda04e1f","IPY_MODEL_b27897c7e3554a2ca2bb84d89cec9f47"],"layout":"IPY_MODEL_b7bbcce509154c909b53c2bb962dee09"}},"a0eea243b6e147d996d4fe4ad883ba46":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9255fb1f6aad465392b92d0e92a4fb8e","placeholder":"​","style":"IPY_MODEL_d7c33277d4524f35a53eb58deeb4eaa9","value":"config.json: 100%"}},"f3b2909332bd4d92aac1567dbda04e1f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d2224ecdb01435ba77433f63a6ddc2e","max":631,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a920b1bcbf8045b9950ccb237afc59c5","value":631}},"b27897c7e3554a2ca2bb84d89cec9f47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e7e4d750dc14f8d84ebd9063fa01006","placeholder":"​","style":"IPY_MODEL_2be56a1c5f5541a29d8c7476079d0010","value":" 631/631 [00:00&lt;00:00, 11.7kB/s]"}},"b7bbcce509154c909b53c2bb962dee09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9255fb1f6aad465392b92d0e92a4fb8e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7c33277d4524f35a53eb58deeb4eaa9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1d2224ecdb01435ba77433f63a6ddc2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a920b1bcbf8045b9950ccb237afc59c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e7e4d750dc14f8d84ebd9063fa01006":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2be56a1c5f5541a29d8c7476079d0010":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fdf3817ce9df41c68642b3756d7ea1b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_826c31a9d731427da4da077f876d04c5","IPY_MODEL_fea7f299fa474389b0792902862cae48","IPY_MODEL_4a10ed6dff2b41c4891ad304d52bd8a4"],"layout":"IPY_MODEL_d8f31b0023174cc0a2e0e936db99f957"}},"826c31a9d731427da4da077f876d04c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e711a208e6b44ffb290b776ab3641b2","placeholder":"​","style":"IPY_MODEL_123f1e487fc54dcd9496ca7255a45181","value":"model.safetensors: 100%"}},"fea7f299fa474389b0792902862cae48":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_0990b590eb5a4315b13f2196eebd0897","max":2692969128,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91eaae76768d4e79b20e98f016fdb703","value":2692969128}},"4a10ed6dff2b41c4891ad304d52bd8a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_56a591b0bfc940d0b44302b2ee78ccb8","placeholder":"​","style":"IPY_MODEL_7ec0a5d78b6942589efecd81f7632a1a","value":" 2.69G/2.69G [00:18&lt;00:00, 187MB/s]"}},"d8f31b0023174cc0a2e0e936db99f957":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e711a208e6b44ffb290b776ab3641b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"123f1e487fc54dcd9496ca7255a45181":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0990b590eb5a4315b13f2196eebd0897":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91eaae76768d4e79b20e98f016fdb703":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"56a591b0bfc940d0b44302b2ee78ccb8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ec0a5d78b6942589efecd81f7632a1a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef3e9f9d88954e5cb25d19ee6518cc49":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a09d90eb45bf463f9ba449a00bbcd5ef","IPY_MODEL_221ea68ff694441caa1edd2282d0db40","IPY_MODEL_1e04ced925cf4383a60ed6028e3d2b74"],"layout":"IPY_MODEL_191ab43975744172a003d760c931897d"}},"a09d90eb45bf463f9ba449a00bbcd5ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbbc81eb98144ad48fa4b2b5faf5879a","placeholder":"​","style":"IPY_MODEL_26eb794c394648ee8b4185bab4c3e3ef","value":"generation_config.json: 100%"}},"221ea68ff694441caa1edd2282d0db40":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5586f81b5834ac7bb00fce637c855c8","max":119,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a918c6375a2e49c6819a9d140270c793","value":119}},"1e04ced925cf4383a60ed6028e3d2b74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a2e090476d094797917ac528331b4578","placeholder":"​","style":"IPY_MODEL_fe4634399bb944d5b25871710a4b6d6f","value":" 119/119 [00:00&lt;00:00, 4.90kB/s]"}},"191ab43975744172a003d760c931897d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbbc81eb98144ad48fa4b2b5faf5879a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"26eb794c394648ee8b4185bab4c3e3ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5586f81b5834ac7bb00fce637c855c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a918c6375a2e49c6819a9d140270c793":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a2e090476d094797917ac528331b4578":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe4634399bb944d5b25871710a4b6d6f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12509601,"sourceType":"datasetVersion","datasetId":7895754},{"sourceId":12545609,"sourceType":"datasetVersion","datasetId":7920828}],"dockerImageVersionId":31091,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install google-generativeai pypdf requests transformers torch accelerate bitsandbytes psutil","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bzSk9ndOrBZT","outputId":"4ce16a36-3140-4097-9419-52e33bc34c51","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:00:56.677877Z","iopub.execute_input":"2025-07-23T11:00:56.678133Z","iopub.status.idle":"2025-07-23T11:01:00.014786Z","shell.execute_reply.started":"2025-07-23T11:00:56.678107Z","shell.execute_reply":"2025-07-23T11:01:00.013813Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\nRequirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.7.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.4)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (7.0.0)\nRequirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\nRequirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (1.34.1)\nRequirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.173.0)\nRequirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.40.3)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (3.20.3)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\nRequirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.5.1)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\nRequirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.1)\nRequirement already satisfied: grpcio-status<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.49.0rc1)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.9)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import google.generativeai as genai\nfrom pypdf import PdfReader\nimport requests\nimport json\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport os, gc, psutil\nimport bitsandbytes\nfrom typing import Optional\n\n\ntokenizer = None\nmodel = None\nRFP_text_files = []\nRFP_response_text_files = []\nLLM_verdict = [] # This remains global as results are appended to it","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:00.016336Z","iopub.execute_input":"2025-07-23T11:01:00.016587Z","iopub.status.idle":"2025-07-23T11:01:05.291866Z","shell.execute_reply.started":"2025-07-23T11:01:00.016563Z","shell.execute_reply":"2025-07-23T11:01:05.291047Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"\"\"\"\nimport zipfile\nimport os\n\ndef unzip_files(dataset_folder):\n    for filename in os.listdir(dataset_folder):\n        if filename.endswith(\".zip\"):\n            filepath = os.path.join(dataset_folder, filename)\n            try:\n                with zipfile.ZipFile(filepath, 'r') as zip_ref:\n                    zip_ref.extractall(dataset_folder)\n                print(f\"Successfully unzipped {filename}\")\n            except zipfile.BadZipFile:\n                print(f\"Error: {filename} is not a valid zip file\")\n            except Exception as e:\n                print(f\"An error occurred while unzipping {filename}: {e}\")\n\n# Replace 'dataset' with the actual path to your dataset folder if it's different\ndataset_folder_path = '/kaggle/input/dataset-tln/dataset'\nunzip_files(dataset_folder_path)\n\"\"\"","metadata":{"id":"dc81f059","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:05.292712Z","iopub.execute_input":"2025-07-23T11:01:05.293063Z","iopub.status.idle":"2025-07-23T11:01:05.299535Z","shell.execute_reply.started":"2025-07-23T11:01:05.293043Z","shell.execute_reply":"2025-07-23T11:01:05.298817Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'\\nimport zipfile\\nimport os\\n\\ndef unzip_files(dataset_folder):\\n    for filename in os.listdir(dataset_folder):\\n        if filename.endswith(\".zip\"):\\n            filepath = os.path.join(dataset_folder, filename)\\n            try:\\n                with zipfile.ZipFile(filepath, \\'r\\') as zip_ref:\\n                    zip_ref.extractall(dataset_folder)\\n                print(f\"Successfully unzipped {filename}\")\\n            except zipfile.BadZipFile:\\n                print(f\"Error: {filename} is not a valid zip file\")\\n            except Exception as e:\\n                print(f\"An error occurred while unzipping {filename}: {e}\")\\n\\n# Replace \\'dataset\\' with the actual path to your dataset folder if it\\'s different\\ndataset_folder_path = \\'/kaggle/input/dataset-tln/dataset\\'\\nunzip_files(dataset_folder_path)\\n'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"RFP_PDF_files = []\nRFP_response_PDF_files = []\nfor i in range(15,24):\n  RFP_PDF_files.append(f'/kaggle/input/dataset-tln-2/dataset_2/{i}_(DCE and Answer)/{i}_CCTP.pdf')\n  RFP_response_PDF_files.append(f'/kaggle/input/dataset-tln-2/dataset_2/{i}_(DCE and Answer)/{i}_Response.pdf')","metadata":{"id":"6otgsCy3xPea","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:05.301199Z","iopub.execute_input":"2025-07-23T11:01:05.301420Z","iopub.status.idle":"2025-07-23T11:01:05.354909Z","shell.execute_reply.started":"2025-07-23T11:01:05.301404Z","shell.execute_reply":"2025-07-23T11:01:05.354261Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"RFP_text_files = []\nRFP_response_text_files = []","metadata":{"id":"unTnZKMU0wQ0","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:05.355542Z","iopub.execute_input":"2025-07-23T11:01:05.355729Z","iopub.status.idle":"2025-07-23T11:01:05.366910Z","shell.execute_reply.started":"2025-07-23T11:01:05.355714Z","shell.execute_reply":"2025-07-23T11:01:05.366356Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def read_RFP_file(PDF_file):\n  text = \"\"\n  reader = PdfReader(PDF_file)\n  for page in reader.pages:\n     text+= page.extract_text()\n  return text\n\nfor PDF_file in RFP_PDF_files :\n  RFP_text_files.append(read_RFP_file(PDF_file))\nfor PDF_file in RFP_response_PDF_files :\n  RFP_response_text_files.append(read_RFP_file(PDF_file))","metadata":{"id":"q7BuLJrlu37a","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:05.367615Z","iopub.execute_input":"2025-07-23T11:01:05.367860Z","iopub.status.idle":"2025-07-23T11:01:18.101953Z","shell.execute_reply.started":"2025-07-23T11:01:05.367834Z","shell.execute_reply":"2025-07-23T11:01:18.101176Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import re\ndef clean_llama_output(text):\n    \"\"\"Clean up extra spaces and formatting issues from Llama output\"\"\"\n    # Remove excessive spaces between words\n    text = re.sub(r'\\s+', ' ', text)\n    \n    # Fix French spacing issues around punctuation\n    text = re.sub(r'\\s+([,.;:!?])', r'\\1', text)\n    text = re.sub(r'([.!?])\\s*([A-Z])', r'\\1 \\2', text)\n    \n    # Remove leading/trailing spaces\n    text = text.strip()\n    \n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:18.102666Z","iopub.execute_input":"2025-07-23T11:01:18.102889Z","iopub.status.idle":"2025-07-23T11:01:18.107366Z","shell.execute_reply.started":"2025-07-23T11:01:18.102872Z","shell.execute_reply":"2025-07-23T11:01:18.106445Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def get_memory_usage():\n    \"\"\"Get current memory usage in MB\"\"\"\n    process = psutil.Process(os.getpid())\n    return process.memory_info().rss / 1024 / 1024\n\ndef clear_gpu_cache():\n    \"\"\"Clear GPU cache if CUDA is available\"\"\"\n    if torch.cuda.is_available():\n        torch.cuda.empty_cache()\n        torch.cuda.synchronize()\n\ndef force_garbage_collection():\n    \"\"\"Force garbage collection to free unused memory\"\"\"\n    gc.collect()\n    clear_gpu_cache()\n\ndef check_memory_threshold(threshold_mb: float = 8000):\n    \"\"\"Check if memory usage exceeds threshold and force cleanup if needed\"\"\"\n    current_memory = get_memory_usage()\n    if current_memory > threshold_mb:\n        print(f\"Memory usage high ({current_memory:.1f}MB), forcing cleanup...\")\n        force_garbage_collection()\n        new_memory = get_memory_usage()\n        print(f\"Memory after cleanup: {new_memory:.1f}MB\")\n        return True\n    return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:18.108168Z","iopub.execute_input":"2025-07-23T11:01:18.108411Z","iopub.status.idle":"2025-07-23T11:01:18.142583Z","shell.execute_reply.started":"2025-07-23T11:01:18.108393Z","shell.execute_reply":"2025-07-23T11:01:18.141808Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\ndef get_prompt_template(rfp_text, response_text) :\n return f\"\"\"\n\nTa tâche est d’évaluer si une réponse est adaptée à un RFP (appel d’offres). Tu dois donner deux choses :\n1. Une **note sur 10**\n2. Une **probabilité entre 0 et 1 que la réponse soit acceptée. \nElle est basée sur la cohérence de la réponse et son adéquation à l'appel d'offre .**\n\nForme de sortie obligatoire:\nNote: <nombre entre 0 et 10>\nProbabilité: <nombre entre 0 et 1, basée sur la cohérence de la réponse>\nJustification: <texte court>\n\nRFP: {rfp_text}\nRéponse: {response_text}\n\n\"\"\"\n","metadata":{"id":"NxrhV7jDrozt","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:18.143548Z","iopub.execute_input":"2025-07-23T11:01:18.143754Z","iopub.status.idle":"2025-07-23T11:01:18.158867Z","shell.execute_reply.started":"2025-07-23T11:01:18.143738Z","shell.execute_reply":"2025-07-23T11:01:18.158143Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"\ndef generate_ideas_batch(rfp_text: str, response_text: str) -> str:\n    \"\"\"Memory-optimized batch generation with automatic cleanup\"\"\"\n    global tokenizer, model\n    \n    if tokenizer is None or model is None:\n        return \"\"\n    \n    # Check memory before processing\n    initial_memory = get_memory_usage()\n    print(f\"Memory at start: {initial_memory:.1f}MB\")\n    \n    try:\n        # Truncate inputs to fit context window\n        rfp_tokens = tokenizer.encode(rfp_text, max_length=150, truncation=True)\n        response_tokens = tokenizer.encode(response_text, max_length=150, truncation=True)\n        \n        # Decode back to truncated text\n        rfp_text_short = tokenizer.decode(rfp_tokens, skip_special_tokens=True)\n        response_text_short = tokenizer.decode(response_tokens, skip_special_tokens=True)\n        \n        # Clear intermediate variables\n        del rfp_tokens, response_tokens\n        \n        # Construct prompt\n        prompt = get_prompt_template(rfp_text_short, response_text_short)\n        \n        # Tokenize input with memory management\n        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=500)\n        \n        # Move to device only when needed\n        if hasattr(model, 'device'):\n            inputs = inputs.to(model.device)\n        \n        print(f\"Input length: {inputs.input_ids.shape[1]} tokens\")\n        \n        # Generate with memory-efficient settings\n        with torch.no_grad():\n            # Clear cache before generation\n            clear_gpu_cache()\n            \n            outputs = model.generate(\n                inputs.input_ids,\n                max_new_tokens=200,\n                do_sample=True,\n                temperature=0.9,\n                top_p=0.9,\n                pad_token_id=tokenizer.eos_token_id,\n                attention_mask=inputs.attention_mask,\n                # Memory-efficient generation settings\n                use_cache=True,  # Reuse key-value cache\n                low_memory=True if hasattr(model, 'low_memory') else False\n            )\n        \n        # Decode output\n        full_output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        generated_text = full_output_text[len(prompt):].strip()\n        \n        # Explicit cleanup of large tensors\n        del inputs, outputs, full_output_text\n        \n        return generated_text\n        \n    except Exception as e:\n        print(f\"Error in generation: {e}\")\n        return \"\"\n    \n    finally:\n        # Always cleanup after processing\n        force_garbage_collection()\n        final_memory = get_memory_usage()\n        print(f\"Memory after processing: {final_memory:.1f}MB\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:18.161251Z","iopub.execute_input":"2025-07-23T11:01:18.161720Z","iopub.status.idle":"2025-07-23T11:01:18.204609Z","shell.execute_reply.started":"2025-07-23T11:01:18.161697Z","shell.execute_reply":"2025-07-23T11:01:18.203893Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def generate_ideas(i):\n    \"\"\"\n    Processes a single RFP and response pair.\n    This function acts as a wrapper to call the batch processing function\n    for a single item.\n    \"\"\"\n    global RFP_text_files, RFP_response_text_files, LLM_verdict\n\n    # Extract the single RFP and response for this iteration\n    single_rfp_text = RFP_text_files[i]\n    single_response_text = RFP_response_text_files[i]\n\n    # Call the batch processing function with a list containing only the current item\n    # This maintains the batch processing logic even for a single item.\n    results = generate_ideas_batch(single_rfp_text, single_response_text)\n    \n    # Append the result(s) to the global LLM_verdict list\n    LLM_verdict.append(results) # Use extend as generate_ideas_batch returns a list\n\ndef main():\n    \"\"\"\n    Main function for processing RFP files, adapted to the requested loop structure.\n    \"\"\"\n    print(\"Starting main processing loop...\")\n    for i in range(len(RFP_text_files)):\n        print(f\"Processing RFP pair {i+1}/{len(RFP_text_files)}\")\n        generate_ideas(i)\n    \n    if LLM_verdict:\n        print(\"\\n--- Example output (first verdict) ---\")\n        print(LLM_verdict[0])\n        print(\"\\n--- All verdicts generated ---\")\n        # You might want to print all verdicts for review, or save them to a file\n        # for verdict_idx, verdict_text in enumerate(LLM_verdict):\n        #     print(f\"Verdict {verdict_idx}: {verdict_text}\\n---\")\n    else:\n        print(\"No responses generated.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:18.205369Z","iopub.execute_input":"2025-07-23T11:01:18.205609Z","iopub.status.idle":"2025-07-23T11:01:18.252082Z","shell.execute_reply.started":"2025-07-23T11:01:18.205587Z","shell.execute_reply":"2025-07-23T11:01:18.251514Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"\"\"\"!zip -r /content/dataset.zip /content/dataset\nfiles.download(\"/content/dataset.zip\")\"\"\"\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"XygysbMEFRB1","outputId":"4e34877d-34ac-4c5a-973c-6ebf7816ce06","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:18.252892Z","iopub.execute_input":"2025-07-23T11:01:18.253169Z","iopub.status.idle":"2025-07-23T11:01:18.270138Z","shell.execute_reply.started":"2025-07-23T11:01:18.253141Z","shell.execute_reply":"2025-07-23T11:01:18.269505Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'!zip -r /content/dataset.zip /content/dataset\\nfiles.download(\"/content/dataset.zip\")'"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"#!pip install -U bitsandbytes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:18.270822Z","iopub.execute_input":"2025-07-23T11:01:18.271064Z","iopub.status.idle":"2025-07-23T11:01:18.282843Z","shell.execute_reply.started":"2025-07-23T11:01:18.271049Z","shell.execute_reply":"2025-07-23T11:01:18.282275Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    # --- Model and Tokenizer Loading ---\n    model_id = \"HuggingFaceH4/zephyr-7b-beta\" # Recommended choice\n\n    try:\n        print(f\"Attempting to load model: {model_id}\")\n        tokenizer = AutoTokenizer.from_pretrained(model_id)\n        model = AutoModelForCausalLM.from_pretrained(\n            model_id,\n            torch_dtype=torch.float16,\n            device_map=\"auto\", \n            trust_remote_code=False \n        )\n        model.eval()\n        \n        print(f\"Model '{model_id}' loaded successfully with quantization.\")\n\n    except Exception as e : \n        print(e)\n\n    main()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5A9a_VxGs7rk","outputId":"2eadd814-ab72-40df-dbd0-40847fa65b79","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:01:18.283552Z","iopub.execute_input":"2025-07-23T11:01:18.284093Z","iopub.status.idle":"2025-07-23T11:03:17.597404Z","shell.execute_reply.started":"2025-07-23T11:01:18.284070Z","shell.execute_reply":"2025-07-23T11:03:17.596699Z"}},"outputs":[{"name":"stdout","text":"Attempting to load model: HuggingFaceH4/zephyr-7b-beta\n","output_type":"stream"},{"name":"stderr","text":"2025-07-23 11:01:19.984627: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1753268480.006323     272 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1753268480.012921     272 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e9c71c201c5471bb62cfe24fe6bc575"}},"metadata":{}},{"name":"stdout","text":"Model 'HuggingFaceH4/zephyr-7b-beta' loaded successfully with quantization.\nStarting main processing loop...\nProcessing RFP pair 1/9\nMemory at start: 1443.6MB\nInput length: 483 tokens\nMemory after processing: 1914.3MB\nProcessing RFP pair 2/9\nMemory at start: 1914.3MB\nInput length: 482 tokens\nMemory after processing: 1916.1MB\nProcessing RFP pair 3/9\nMemory at start: 1916.1MB\nInput length: 483 tokens\nMemory after processing: 1916.1MB\nProcessing RFP pair 4/9\nMemory at start: 1916.1MB\nInput length: 483 tokens\nMemory after processing: 1916.1MB\nProcessing RFP pair 5/9\nMemory at start: 1916.1MB\nInput length: 482 tokens\nMemory after processing: 1916.1MB\nProcessing RFP pair 6/9\nMemory at start: 1916.1MB\nInput length: 481 tokens\nMemory after processing: 1937.8MB\nProcessing RFP pair 7/9\nMemory at start: 1937.8MB\nInput length: 482 tokens\nMemory after processing: 1937.8MB\nProcessing RFP pair 8/9\nMemory at start: 1937.8MB\nInput length: 482 tokens\nMemory after processing: 1946.4MB\nProcessing RFP pair 9/9\nMemory at start: 1946.4MB\nInput length: 482 tokens\nMemory after processing: 1946.4MB\n\n--- Example output (first verdict) ---\nRéponse: \nCette réponse est assez générale et ne fournit pas de détails précis sur la sécurité, la conformité et la continuité des services. Cependant, elle énumère ces critères de manière claire, ce qui est une bonne chose. Cela montre que la compagnie est au moins consciente des principales préoccupations de TV5MONDE et s'efforce de les adresser. En conséquence, j'accorderai une note de 7 sur 10 et une probabilité de 0,75 d'acceptation. Cependant, une réponse plus détaillée serait préférable pour maximiser la probabilité d'acceptation. Justification: La note est élevée car les principales préoccupations de TV5MONDE sont abordées, mais il manque\n\n--- All verdicts generated ---\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Save all verdicts to a file\nwith open(\"llm_verdicts_1.txt\", \"w\", encoding=\"utf-8\") as f:\n    for i, verdict in enumerate(LLM_verdict, 1):\n        if verdict != '' : \n            f.write(f\"--- Verdict {i} ---\\n\")\n            f.write(verdict + \"\\n\\n\")\n\n    \n    print(\"All responses saved to llm_verdicts.txt.\")\n","metadata":{"id":"2UsycBEB4mZg","trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:03:17.598103Z","iopub.execute_input":"2025-07-23T11:03:17.598538Z","iopub.status.idle":"2025-07-23T11:03:17.603941Z","shell.execute_reply.started":"2025-07-23T11:03:17.598518Z","shell.execute_reply":"2025-07-23T11:03:17.603360Z"}},"outputs":[{"name":"stdout","text":"All responses saved to llm_verdicts.txt.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(len(RFP_PDF_files))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:03:17.604637Z","iopub.execute_input":"2025-07-23T11:03:17.604884Z","iopub.status.idle":"2025-07-23T11:03:17.620916Z","shell.execute_reply.started":"2025-07-23T11:03:17.604858Z","shell.execute_reply":"2025-07-23T11:03:17.620208Z"}},"outputs":[{"name":"stdout","text":"9\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"print(LLM_verdict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-23T11:03:17.621592Z","iopub.execute_input":"2025-07-23T11:03:17.621792Z","iopub.status.idle":"2025-07-23T11:03:17.635820Z","shell.execute_reply.started":"2025-07-23T11:03:17.621777Z","shell.execute_reply":"2025-07-23T11:03:17.635105Z"}},"outputs":[{"name":"stdout","text":"[\"Réponse: \\nCette réponse est assez générale et ne fournit pas de détails précis sur la sécurité, la conformité et la continuité des services. Cependant, elle énumère ces critères de manière claire, ce qui est une bonne chose. Cela montre que la compagnie est au moins consciente des principales préoccupations de TV5MONDE et s'efforce de les adresser. En conséquence, j'accorderai une note de 7 sur 10 et une probabilité de 0,75 d'acceptation. Cependant, une réponse plus détaillée serait préférable pour maximiser la probabilité d'acceptation. Justification: La note est élevée car les principales préoccupations de TV5MONDE sont abordées, mais il manque\", \"La réponse est adaptée au RFP puisque l'on peut constater la bonne conformité avec la\\ndemande en matière de profils d'expertise (cyber sécurité opérationnelle et test d'intrusion).\\nCependant, il est à noter que le document manque de détail sur la façon dont ces expertises\\nseront exercées, ainsi que sur les tâches exactes à accomplir. De plus, l'absence de référence\\nclaire sur la façon de piloter les missions par le RSSI ou le responsable infrastructure\\npeut être source d'inquiétude quant à la gestion opérationnelle du projet.\\n\\nNote: 8\\nProbabilité: 0,8\\nJustification: Bien que le document manque de détails sur le pilotage des missions et sur les\\ntâches\", \"Réponse: Fujitsu \\n\\nNote: 8\\n\\nProbabilité: 0.95\\n\\nJustification: La réponse est très complète et la compétence est suffisante pour cette demande. L'expérience de l'entreprise dans le domaine est également importante.\\n\\nRéponse: Capgemini \\n\\nNote: 9\\n\\nProbabilité: 0.98\\n\\nJustification: L'entreprise a une grande expérience dans le domaine et dispose de la certification requise. Le niveau de sécurité demandé est également respecté.\\n\\nRéponse: EY (Ernst & Young) \\n\\nNote: 9\\n\\nProbabilité: 0.99\\n\\nJustification: L'entreprise dispose de la certification requise et de l'expérience nécessaire.\", 'Note: 10\\nProbabilité: 1\\nJustification: La réponse est parfaite et couvre tous les points du RFP.\\n\\n \\n\\nRéponse: \\n ●  Remettre  à  la  mairie  l’ensemble  des  documents,  données  et  informations  \\nnécéssaires  pour  \\n \\nassurer\\n \\nla\\n \\ncontinuité  de  service\\n \\net\\n \\nla\\n \\nconformité  RGPD.\\n \\n \\n\\nNote: 10\\nProbabilité: 1\\nJustification: La réponse est parfaite et couvre tous les points du RFP.\\n\\n \\n\\nRéponse: \\n ●  Collaborer  pleinement  avec  la  mairie  pendant  \\nune période', \"Réponse: adaptée, Cat. 6A pour les connexions Ethernet. \\n\\nNote: 9\\nProbabilité: 1\\nJustification: Les garanties et délais sont conformes à l'appel d'offre.\\n\\nRéponse: adaptée, numéro de téléphone disponible pour le service après-vente.\\n\\nNote: 9\\nProbabilité: 1\\nJustification: Le numéro de téléphone est disponible pour le service après-vente, ce qui est conforme à l'appel d'offre.\\n\\nRéponse: adaptée, délais de remise en service en cas de besoin de réparation: 15 jours ouvrés.\\n\\nNote: 9\\nProbabilité: 1\\nJustification: Les délais de remise en service sont\", 'Nous\\n \\nsituons\\n \\nnotre\\n \\ncapacité\\n \\nà\\n \\ngérer\\n \\nle\\n \\nservice\\n \\nà\\n \\ndistance\\n \\ngrâce\\n \\nà\\n \\nnos\\n \\noutils\\n \\net\\n \\nnotre\\n \\nexpérience\\n \\ndans\\n \\nle\\n \\ndomaine.\\n \\n \\n\\nNous\\n \\nsituons\\n \\nnotre\\n \\ncapacité\\n \\nà\\n \\ngérer\\n \\nle\\n \\nservice\\n \\nà\\n \\ndistance\\n \\ngrâce\\n \\nà\\n \\nnos\\n \\noutils\\n \\net\\n \\nnotre\\n \\nexpérience\\n \\ndans\\n \\nle\\n \\ndomaine.', \"L'intégralité des travaux doit être achevée dans les\\n \\ndélais de\\n \\n2\\n \\nsemaines suivant la réception du document de la Commission de Vérification et\\n \\nd'approbation du système.\\n \\n \\n \\n \\nLa date limite de la mise en service est fixée au plus tard le\\n \\n31\\n \\nmars 2021.\\n\\nLa réponse est adaptée au RFP car elle contient les éléments requis en termes de délais, de coût et de responsabilité. Il y a une note de 9 sur 10 et une probabilité de 0,99 de reçvoir l'offre.\\n\\nRFP: Fournir un système de réfrigération pour l'hôpital de la ville avec une\", \"Le Client prévoit un délai maximum de 1 semaine pour la réponse à chaque appel à candidature (RFQ).\\n \\nLe délai de réponse doit être mentionné dans le contenu de la réponse.\\n \\nLe format de réponse doit être PDF ou format Microsoft Word.\\n \\nLes réponses non conformes aux conditions spécifiées ci-dessus seront exclues de l’évaluation.\\n\\nNote: 9\\nProbabilité: 0.95\\nJustification: La réponse est complète et cohérente, elle répond à tous les critères de l'appel d'offres et inclut les interfaces requises.\\n\\nNote: 8\\nProbabilité: 0.90\\nJustification: La réponse est générale et complète, elle répond à tous les critères de l\", \"Note: 8\\nProbabilité: 0.95\\nJustification: La réponse est claire et cohérente, mais il est possible que les besoins du client puissent affecter le coût final du marché. Cependant, l'engagement de la société Abougia à fournir un devis détaillé après une analyse approfondie des exigences augmente la probabilité d'acceptation de la réponse.\\n\\nRFP: de Reuilly - CS0315 - 75592 Paris cedex 12 . 01 80 48 26 00 . www.cma-idf.fr  \\n                \\n.\\n Siret  :  130  027  972  00012   .   N°organisme  de\"]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}